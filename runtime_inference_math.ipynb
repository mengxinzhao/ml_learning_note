{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375b5de0",
   "metadata": {
    "id": "375b5de0"
   },
   "source": [
    "# Runtime Inference Acceleration æ•°å­¦åŸºç¡€\n",
    "\n",
    "- ä½œè€…ï¼šChatGPT + Vesper\n",
    "- ç‰ˆæœ¬ï¼šv0.1\n",
    "- ç”¨é€”ï¼š Runtime Inference Acceleration çš„æ•°å­¦åŸºç¡€ï¼Œè¡¥é½æ•°å­¦çŸ¥è¯†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd04212",
   "metadata": {
    "id": "9fd04212"
   },
   "source": [
    "# ç¬¬ 0 ç« ï¼šæ•´ä½“è§†å›¾ â€”â€” Runtime Inference çš„ 9 å¤§æ•°å­¦æ”¯æŸ±\n",
    "\n",
    "åœ¨çŽ°ä»£æŽ¨ç†ç³»ç»Ÿä¸­ï¼ˆLLMã€Transformerã€CNNã€è¯­éŸ³æ¨¡åž‹ç­‰ï¼‰ï¼Œæ¶‰åŠåˆ°çš„æ•°å­¦å¤§è‡´å¯ä»¥å½’çº³ä¸º 9 å¤§ç±»ï¼š\n",
    "\n",
    "1. **çº¿æ€§ä»£æ•°ï¼ˆLinear Algebraï¼‰**  \n",
    "   - çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ã€SVDã€ä½Žç§©åˆ†è§£ã€å·ç§¯è¡¨è¾¾\n",
    "2. **æ•°å€¼ä¼˜åŒ–ï¼ˆNumerical Optimizationï¼‰**  \n",
    "   - å‰ªæžã€é‡åŒ–ã€è’¸é¦èƒŒåŽçš„ä¼˜åŒ–ç›®æ ‡ä¸Žçº¦æŸ\n",
    "3. **è¿‘ä¼¼ç†è®ºï¼ˆApproximation Theoryï¼‰**  \n",
    "   - é‡åŒ–å™ªå£°å»ºæ¨¡ã€æ¿€æ´»å‡½æ•°è¿‘ä¼¼ã€cheap ops æ›¿ä»£\n",
    "4. **æ¦‚çŽ‡ä¸Žç»Ÿè®¡ï¼ˆProbability & Statisticsï¼‰**  \n",
    "   - KLã€æ¸©åº¦ç¼©æ”¾ã€åˆ†å¸ƒæ‹Ÿåˆã€åˆ†ä½æ•°å‰ªè£\n",
    "5. **ä¿¡æ¯è®ºï¼ˆInformation Theoryï¼‰**  \n",
    "   - ç†µã€ç¼–ç ã€åŽ‹ç¼©æžé™ã€rateâ€“distortion è§†è§’\n",
    "6. **ä¿¡å·å¤„ç†ä¸Žå·ç§¯æ•°å­¦ï¼ˆSignal Processingï¼‰**  \n",
    "   - FFTã€Winogradã€Toeplitz/Circulant ç»“æž„\n",
    "7. **è®¡ç®—å›¾ä¸Žå›¾è®ºï¼ˆComputational Graph & Graph Theoryï¼‰**  \n",
    "   - DAGã€å›¾é‡å†™ã€kernel fusionã€memory planning\n",
    "8. **æ•°å€¼ç¨³å®šæ€§ä¸Žå¤æ‚åº¦ï¼ˆNumerical Stability & Complexityï¼‰**  \n",
    "   - æµ®ç‚¹è¯¯å·®ã€softmax ç¨³å®šå†™æ³•ã€å¤æ‚åº¦åˆ†æž\n",
    "9. **ç¡¬ä»¶ç›¸å…³æ•°å­¦ï¼ˆHardware-Aware Mathï¼‰**  \n",
    "   - Roofline æ¨¡åž‹ã€tilingã€SIMD/FMAã€GEMM å†…æ ¸\n",
    "        |\n",
    "\n",
    "è¿™äº›æ¨¡å—ä¹‹é—´çš„å…³ç³»å¯ä»¥å¤§è‡´ç”¨ä¸€å¼ â€œå¿ƒæ™ºåœ°å›¾â€è¡¨ç¤ºï¼š\n",
    "\n",
    "```text\n",
    "              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "              â”‚ çº¿æ€§ä»£æ•° â”‚  â† å…³é”®ï¼šGEMM / SVD / Conv=MatMul\n",
    "              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "                   â”‚\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â–¼                  â–¼\n",
    "   æ•°å€¼ä¼˜åŒ–(å‰ªæž/é‡åŒ–)   è¿‘ä¼¼ç†è®º(æ¿€æ´»/é‡åŒ–è¯¯å·®)\n",
    "          â”‚                  â”‚\n",
    "          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "          â–¼        â–¼         â–¼\n",
    "       æ¦‚çŽ‡ç»Ÿè®¡  ä¿¡æ¯è®º   ä¿¡å·å¤„ç†(Conv/FFT)\n",
    "          â”‚                  â”‚\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                   â–¼\n",
    "          è®¡ç®—å›¾ & å›¾è®º (fusion, scheduling)\n",
    "                   â”‚\n",
    "                   â–¼\n",
    "     æ•°å€¼ç¨³å®šæ€§ & ç¡¬ä»¶æ•°å­¦ (FP16/FP8, Roofline, tiling)\n",
    "```\n",
    "\n",
    "> æœ¬ notebook åŽç»­ç« èŠ‚å°†æŒ‰ç…§è¿™ä¸ªç»“æž„å±•å¼€ã€‚  \n",
    "> ç¬¬ 1 ç« ä»Ž **çº¿æ€§ä»£æ•°** å¼€å§‹ï¼Œå› ä¸ºè¿™æ˜¯æŽ¨ç†åŠ é€Ÿä¸­æœ€æ ¸å¿ƒã€å‡ºçŽ°é¢‘çŽ‡æœ€é«˜çš„æ•°å­¦è¯­è¨€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72dc0f",
   "metadata": {
    "id": "da72dc0f"
   },
   "source": [
    "# ç¬¬ 1 ç« ï¼šçº¿æ€§ä»£æ•°ï¼ˆLinear Algebra for Runtime Inferenceï¼‰\n",
    "\n",
    "## 1.1 çº¿æ€§ä»£æ•°åœ¨æŽ¨ç†åŠ é€Ÿä¸­çš„è§’è‰²\n",
    "\n",
    "åœ¨æ·±åº¦å­¦ä¹ æŽ¨ç†ä¸­ï¼Œç»å¤§éƒ¨åˆ†â€œé‡è®¡ç®—â€éƒ½å¯ä»¥æŠ½è±¡ä¸ºï¼š\n",
    "\n",
    "- å‘é‡å†…ç§¯ï¼ˆdot productï¼‰\n",
    "- çŸ©é˜µâ€“å‘é‡ä¹˜æ³•ï¼ˆGEMVï¼‰\n",
    "- çŸ©é˜µâ€“çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰\n",
    "- å·ç§¯ç»å˜æ¢åŽå˜æˆçš„ GEMMï¼ˆim2col / Winogradï¼‰\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "\n",
    "- å…¨è¿žæŽ¥å±‚ï¼ˆFully Connectedï¼‰ï¼š  \n",
    "  $y = W x + b$\n",
    "- Transformer MLPï¼š  \n",
    "  $Y = \\sigma(X W_1 + b_1) W_2 + b_2$\n",
    "- è‡ªæ³¨æ„åŠ›ï¼ˆSelf-Attentionï¼‰ï¼š  \n",
    "  $Q = X W_Q, \\quad K = X W_K, \\quad V = X W_V$  \n",
    "  $A = \\text{softmax}(QK^\\top / \\sqrt{d_k})$  \n",
    "  $O = A V$\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "æŽ¨ç†åŠ é€Ÿåº“ï¼ˆcuBLASã€CUTLASSã€MKLã€QNNPACKã€TensorRT ç­‰ï¼‰çš„æ ¸å¿ƒä»»åŠ¡ï¼Œå°±æ˜¯ï¼š\n",
    "\n",
    "> è®©è¿™äº›çŸ©é˜µ/å‘é‡è¿ç®—åœ¨ç‰¹å®šç¡¬ä»¶ä¸Šå°½å¯èƒ½é«˜æ•ˆåœ°æ‰§è¡Œã€‚\n",
    "\n",
    "ç†è§£çº¿æ€§ä»£æ•° â†’ ç†è§£ï¼š\n",
    "\n",
    "- ä¸ºä»€ä¹ˆæ‰€æœ‰äººéƒ½åœ¨è¯´ GEMM\n",
    "- ä¸ºä»€ä¹ˆ low-rank / SVD / LoRA èƒ½å¤Ÿâ€œç™½å«–â€åŠ é€Ÿ\n",
    "- ä¸ºä»€ä¹ˆ Conv2d ç»å¸¸è¢«å˜æˆ GEMM\n",
    "- ä¸ºä»€ä¹ˆ Attention çš„ä¼˜åŒ–é›†ä¸­åœ¨ QKáµ€ / AV ä¸Š\n",
    "\n",
    "---\n",
    "\n",
    "## 1.2 ä»Žå†…ç§¯åˆ° GEMMï¼šæŽ¨ç†çš„åŸºæœ¬ç®—å­\n",
    "\n",
    "### 1.2.1 å†…ç§¯ï¼ˆdot productï¼‰\n",
    "\n",
    "ç»™å®šä¸¤ä¸ªå‘é‡ $a,b \\in \\mathbb{R}^d$ï¼Œå®ƒä»¬çš„å†…ç§¯ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\langle a, b \\rangle = \\sum_{i=1}^d a_i b_i\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™æ˜¯æœ€å°çš„â€œä¹˜â€“åŠ â€å•å…ƒã€‚\n",
    "\n",
    "**ã€ç¡¬ä»¶è§†è§’ã€‘**  \n",
    "çŽ°ä»£ CPU/GPU/NPU éƒ½æœ‰ **FMA (Fused Multiply-Add)** æŒ‡ä»¤ï¼š\n",
    "\n",
    "$$\n",
    "\\text{FMA}(a,b,c) = a \\times b + c\n",
    "$$\n",
    "\n",
    "\n",
    "dot product å¯ä»¥å†™æˆï¼š\n",
    "\n",
    "```text\n",
    "acc = 0\n",
    "for i in range(d):\n",
    "    acc = fma(a[i], b[i], acc)\n",
    "```\n",
    "\n",
    "- FMA æ˜¯çŸ©é˜µä¹˜æ³•çš„åº•å±‚åŽŸè¯­ï¼ˆprimitiveï¼‰\n",
    "- è¶Šèƒ½è®©ç¡¬ä»¶é•¿æ—¶é—´â€œåˆ· FMAâ€ï¼ŒæŽ¨ç†åžåè¶Šé«˜\n",
    "- æ•°å­¦ä¸Šçš„æ„ä¹‰ï¼š\n",
    "$\\text{round}\\big(\\text{round}(a\\times b) + c \\big)\n",
    "\\neq\n",
    "\\text{round}(a\\times b + c)$\n",
    "FMA ä½¿ç”¨å³è¾¹çš„ï¼ˆæ›´ç²¾ç¡®ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2.2 çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰\n",
    "\n",
    "GEMM çš„ä¸€èˆ¬å½¢å¼ï¼š\n",
    "\n",
    "$$\n",
    "C = \\alpha A B + \\beta C\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- $A \\in \\mathbb{R}^{M \\times K}$\n",
    "- $B \\in \\mathbb{R}^{K \\times N}$\n",
    "- $C \\in \\mathbb{R}^{M \\times N}$\n",
    "- $\\alpha, \\beta$ ä¸ºæ ‡é‡ï¼ˆå¸¸è§æƒ…å†µï¼š$\\alpha=1, \\beta=0$ï¼‰\n",
    "\n",
    "å±•å¼€å•ä¸ªå…ƒç´ ï¼š\n",
    "\n",
    "$$\n",
    "c_{ij} = \\alpha \\sum_{k=1}^K a_{ik} b_{kj} + \\beta c_{ij}^{\\text{(old)}}\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™å°±æ˜¯ï¼š**å¤šæ¬¡ FMA çš„äºŒç»´ç‰ˆæœ¬**ã€‚\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "- å…¨è¿žæŽ¥å±‚ = å¤šä¸ª GEMM\n",
    "- Attention = 2 ä¸ªå¤§ GEMMï¼ˆQKáµ€ å’Œ AVï¼‰+ è‹¥å¹²å°ç®—å­\n",
    "- Conv2d ç»è¿‡å˜æ¢åŽ = GEMM\n",
    "- æŽ¨ç†åŠ é€Ÿçš„å¤§å¤´ï¼Œå°±æ˜¯æŠŠä¸åŒç®—å­ç»Ÿä¸€æ˜ å°„åˆ°é«˜æ•ˆ GEMM å†…æ ¸ä¸Š\n",
    "\n",
    "\n",
    "å°ç»“\n",
    "| ç½‘ç»œç»„ä»¶            | æ•°å­¦å½¢å¼     | æœ€ç»ˆå˜æˆ          |\n",
    "| --------------- | -------- | ------------- |\n",
    "| å…¨è¿žæŽ¥å±‚ FC         | Wx + b   | GEMM          |\n",
    "| å·ç§¯ conv2d       | K * X    | im2col â†’ GEMM |\n",
    "| Attention QKáµ€   | QKáµ€      | GEMM          |\n",
    "| Attention AV    | AV       | GEMM          |\n",
    "| Transformer MLP | XWâ‚, XWâ‚‚ | GEMM          |\n",
    "| Embedding       | æŸ¥è¡¨       | é€‰è¡Œï¼ˆç±»ä¼¼ GEMMï¼‰   \n",
    "\n",
    "é™„ï¼š ä¸ºä»€ä¹ˆè¯´â€œEmbedding ç±»ä¼¼ GEMMâ€ï¼Ÿ\n",
    "\n",
    "è™½ç„¶ æ•°å­¦ä¸Š Embedding æ˜¯é€‰è¡Œï¼Œ\n",
    "ä½†å®ƒå¯ä»¥çœ‹æˆä¸€ä¸ªéžå¸¸ç¨€ç–çš„çŸ©é˜µä¹˜æ³•ã€‚\n",
    "ç»™ä¸€ä¸ª embedding matrixï¼ˆè¯å‘é‡çŸ©é˜µï¼‰\n",
    "$E \\in \\mathbb{R}^{V \\times D}$\n",
    "- V = vocabulary sizeï¼ˆå¦‚ 50kï¼‰\n",
    "\n",
    "- D = hidden dimensionï¼ˆå¦‚ 1024ï¼‰\n",
    "\n",
    "æ¯ä¸€è¡Œ $ð¸_i$ å°±æ˜¯ä¸€ä¸ª token çš„å‘é‡ã€‚å½“ä¸€ä¸ª token çš„ ID = i æ—¶ï¼Œembedding åšçš„äº‹æƒ…æ˜¯ï¼š$\\text{Embedding}(i) = E_{i}$\n",
    "æ²¡æœ‰ä¹˜æ³•ï¼Œæ²¡æœ‰çŸ©é˜µè¿ç®—ï¼Œæ‰€ä»¥ Embedding çš„ FLOPs ~ 0ï¼ˆå‡ ä¹Ž 0ï¼‰ã€‚\n",
    "çœŸæ­£çš„æˆæœ¬æ˜¯ï¼š\n",
    "\n",
    "- å†…å­˜è®¿é—®ï¼ˆmemory bandwidthï¼‰\n",
    "\n",
    "- éšæœºè®¿é—®ï¼ˆrandom accessï¼‰\n",
    "\n",
    "- cache missï¼ˆembedding layer å¾ˆå®¹æ˜“ miss cacheï¼‰\n",
    "\n",
    "å‡è®¾ token id = 3ï¼Œ è¿™æ—¶å¯ä»¥æž„é€ ä¸€ä¸ª size V çš„ one-hot å‘é‡ï¼š$x = [0,0,0,1,0,0,\\dots]^T \\in \\mathbb{R}^V$\n",
    "\n",
    "Embedding çš„è¾“å‡ºå°±æ˜¯ï¼š$y = x^T E \\in \\mathbb{R}^D$\n",
    "\n",
    "å±•å¼€æ¥çœ‹ï¼š$y = \\sum_{i=1}^V x_i E_i$\n",
    "\n",
    "ä½†å› ä¸ºåªæœ‰ä¸€ä¸ª $X_i = 1$ï¼Œå…¶ä½™å…¨æ˜¯ 0ï¼š $y = E_3$\n",
    "\n",
    "è¿™æœ¬è´¨ä¸Šæ˜¯ä¸€ç§ç‰¹æ®Šçš„ GEMMï¼š$Y = X E$\n",
    "å…¶ä¸­ X æ˜¯ batch ä¸ª one-hot å‘é‡ã€‚\n",
    "\n",
    "åªæ˜¯ï¼š\n",
    "\n",
    "X ä¸­ç»å¤§éƒ¨åˆ†å€¼æ˜¯ 0ï¼Œ X åªæœ‰ä¸€ä¸ª 1ï¼Œ æ‰€ä»¥çŸ©é˜µä¹˜æ³•é€€åŒ–æˆâ€œé€‰è¡Œâ€.\n",
    "\n",
    "è¿™ä¹ˆç†è§£çš„å¥½å¤„ï¼š\n",
    "Embedding ä»Žæ•°å­¦ä¸Šå¯ä»¥è§†ä¸º GEMM çš„ç‰¹ä¾‹ï¼ˆç¨€ç– GEMMï¼‰\n",
    "\n",
    "è¿™è®©æˆ‘ä»¬å¯ä»¥ï¼š\n",
    "\n",
    "- ä½¿ç”¨çŸ©é˜µè§‚ç‚¹åˆ†æžå®ƒ\n",
    "\n",
    "- ä½¿ç”¨ GEMM çš„ layoutã€tiling ç†è§£å…¶ä¼˜åŒ–\n",
    "\n",
    "- æŠŠ embedding ä¹Ÿå½“æˆä¸€ä¸ªâ€œçŸ©é˜µç®—å­â€ï¼Œå¯ä»¥èžåˆã€é‡åŒ–ã€cacheå‹å¥½åŒ–\n",
    "\n",
    "æ€»ç»“ä¸€ä¸‹ï¼ŒEmbedding çš„ç“¶é¢ˆä¸æ˜¯ç®—åŠ›ï¼ˆä¸æ˜¯ FMAï¼‰ï¼Œè€Œæ˜¯ï¼š\n",
    "\n",
    "- å†…å­˜å¸¦å®½ï¼ˆbandwidthï¼‰\n",
    "\n",
    "- éšæœºè®¿é—®ï¼ˆrandom access patternsï¼‰\n",
    "\n",
    "- cache line miss\n",
    "\n",
    "å› æ­¤ï¼š\n",
    "\n",
    "å¸¸è§çœ‹åˆ°ä¼˜åŒ–ç­–ç•¥æ˜¯ï¼š\n",
    "\n",
    "- æŠŠ embedding matrix rearrangeï¼ˆè¡ŒåŽ‹ç¼©ï¼‰\n",
    "\n",
    "- æŠŠå¸¸ç”¨ token æå‰æ”¾åœ¨ cache-friendly åŒºåŸŸ\n",
    "\n",
    "- æ›´å° embeddingï¼ˆé‡åŒ–ã€å‡å°‘ç»´åº¦ï¼‰\n",
    "\n",
    "- batching lookups\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2.3 å¼ é‡è¿ç®—ï¼šçº¿æ€§ä»£æ•°çš„å¤šç»´ç‰ˆæœ¬\n",
    "\n",
    "å¼ é‡ï¼ˆtensorï¼‰æœ¬è´¨å°±æ˜¯å¤šç»´æ•°ç»„ï¼Œå¸¸è§æ˜¯ rank-3 / rank-4ï¼š\n",
    "\n",
    "- rank-3ï¼š$B \\times T \\times D$ï¼ˆbatch Ã— seq_len Ã— hidden_dimï¼‰\n",
    "- rank-4ï¼š$B \\times C \\times H \\times W$ï¼ˆç”¨äºŽå·ç§¯ï¼‰\n",
    "\n",
    "å¼ é‡è¿ç®—ï¼ˆeinsumã€batched matmulï¼‰æœ€ç»ˆéƒ½ä¼šè¢«åˆ†è§£æˆï¼š\n",
    "\n",
    "- ä¸€å † reshape / transpose\n",
    "- è‹¥å¹²çŸ©é˜µä¹˜æ³•ï¼ˆbatched GEMMï¼‰\n",
    "- å† reshape å›žæƒ³è¦çš„å½¢çŠ¶\n",
    "\n",
    "> æ‰€ä»¥â€œå­¦çº¿æ€§ä»£æ•°â€ä¸ä»…æ˜¯å­¦çŸ©é˜µï¼Œè¿˜è¦å­¦ä¼š**å¦‚ä½•æŠŠé«˜ç»´å¼ é‡ reshape æˆçŸ©é˜µ**ä»¥ä¾¿ä½¿ç”¨é«˜æ•ˆ GEMMã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050fee9",
   "metadata": {
    "id": "1050fee9"
   },
   "source": [
    "## 1.3 ä½Žç§©è¿‘ä¼¼ï¼ˆLow-Rank Approximationï¼‰ä¸Ž SVD\n",
    "\n",
    "### 1.3.1 é—®é¢˜èƒŒæ™¯\n",
    "\n",
    "ç»™å®šä¸€ä¸ªå¤§çš„æƒé‡çŸ©é˜µ $W \\in \\mathbb{R}^{m \\times n}$ï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- Transformer MLP çš„æƒé‡ï¼ˆå¦‚ 4096 Ã— 11008ï¼‰\n",
    "- Attention ä¸­çš„æŠ•å½±çŸ©é˜µï¼ˆå¦‚ 4096 Ã— 4096ï¼‰\n",
    "\n",
    "åœ¨å¾ˆå¤šå®žé™…æ¨¡åž‹ä¸­ï¼Œ$W$ çš„â€œæœ‰æ•ˆç§©ï¼ˆeffective rankï¼‰â€è¿œå°äºŽ $\\min(m,n)$ï¼š\n",
    "- ä¹Ÿå°±æ˜¯è¯´ï¼Œâ€œä¿¡æ¯â€é›†ä¸­åœ¨å°‘æ•°å‡ ä¸ªæ–¹å‘ä¸Šã€‚\n",
    "\n",
    "è¿™æ—¶æˆ‘ä»¬å¸Œæœ›ç”¨ä¸€ä¸ªç§©ä¸º $k \\ll \\min(m,n)$ çš„çŸ©é˜µ $W_k$ æ¥è¿‘ä¼¼ $W$ï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\text{rank}(X) \\le k} \\ \\|W - X\\|_F\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™ä¸ªé—®é¢˜çš„è§£æžè§£ç”± **å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰** ç»™å‡ºã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.2 å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰çš„å½¢å¼\n",
    "\n",
    "$$\n",
    "W = U \\Sigma V^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "- $U \\in \\mathbb{R}^{m \\times m}$ï¼šåˆ—å‘é‡ä¸ºå·¦å¥‡å¼‚å‘é‡\n",
    "- $V \\in \\mathbb{R}^{n \\times n}$ï¼šåˆ—å‘é‡ä¸ºå³å¥‡å¼‚å‘é‡\n",
    "- $\\Sigma \\in \\mathbb{R}^{m \\times n}$ï¼šå¯¹è§’çº¿ä¸ºå¥‡å¼‚å€¼ $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r > 0$ï¼Œå…¶ä½™ä¸º 0\n",
    "\n",
    "æˆªæ–­åˆ°å‰ $k$ ä¸ªå¥‡å¼‚å€¼ï¼š\n",
    "\n",
    "$$\n",
    "W_k = U_k \\Sigma_k V_k^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "- $U_k \\in \\mathbb{R}^{m \\times k}$\n",
    "- $\\Sigma_k \\in \\mathbb{R}^{k \\times k}$\n",
    "- $V_k \\in \\mathbb{R}^{n \\times k}$\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªç§©ä¸º $k$ çš„çŸ©é˜µã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.3 æœ€ä¼˜ä½Žç§©è¿‘ä¼¼å®šç†ï¼ˆEckartâ€“Youngâ€“Mirskyï¼‰\n",
    "\n",
    "**å®šç†ï¼š**  \n",
    "åœ¨ Frobenius èŒƒæ•°ä¸‹ï¼Œç§©ä¸è¶…è¿‡ $k$ çš„çŸ©é˜µä¸­ç¦» $W$ æœ€è¿‘çš„æ˜¯ $W_k$ï¼š\n",
    "\n",
    "$$\n",
    "W_k = \\arg\\min_{\\text{rank}(X) \\le k} \\|W - X\\|_F\n",
    "$$\n",
    "\n",
    "\n",
    "è€Œè¯¯å·®å¤§å°åˆšå¥½ç­‰äºŽè¢«æˆªæŽ‰çš„å¥‡å¼‚å€¼çš„å¹³æ–¹å’Œï¼š\n",
    "\n",
    "$$\n",
    "\\|W - W_k\\|_F^2 = \\sum_{i=k+1}^r \\sigma_i^2\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€ç›´è§‚è§£é‡Šã€‘**  \n",
    "å¥‡å¼‚å€¼è¶Šå¤§ï¼Œå¯¹çŸ©é˜µâ€œèƒ½é‡â€çš„è´¡çŒ®è¶Šå¤§ï¼›æˆªæ–­åŽï¼Œä¸¢æŽ‰çš„èƒ½é‡æ°å¥½æ˜¯å¯¹åº”å¥‡å¼‚å€¼å¹³æ–¹çš„æ€»å’Œã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.4 ç”¨ä¸¤ä¸ªå°çŸ©é˜µå®žçŽ°ä½Žç§©è¿‘ä¼¼\n",
    "\n",
    "åœ¨å·¥ç¨‹ä¸­ï¼Œä¸ºäº†å‡å°‘ FLOPsï¼Œé€šå¸¸æŠŠ $W_k$ æ‹†æˆä¸¤ä¸ªæ›´å°çš„çŸ©é˜µç›¸ä¹˜ï¼š\n",
    "\n",
    "$$\n",
    "W_k = A B, \\quad A \\in \\mathbb{R}^{m \\times k}, \\ B \\in \\mathbb{R}^{k \\times n}\n",
    "$$\n",
    "\n",
    "\n",
    "ä¸€ç§å¸¸è§æž„é€ æ˜¯ï¼š\n",
    "\n",
    "$$\n",
    "A = U_k \\Sigma_k^{1/2}, \\quad B = \\Sigma_k^{1/2} V_k^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "äºŽæ˜¯ï¼š\n",
    "\n",
    "$$\n",
    "W x \\approx W_k x = A (B x)\n",
    "$$\n",
    "\n",
    "\n",
    "- åŽŸå§‹è®¡ç®—ï¼š$W x$ æ˜¯ä¸€ä¸ª $m \\times n$ çš„çŸ©é˜µâ€“å‘é‡ä¹˜æ³•ï¼Œå¤æ‚åº¦ $O(mn)$\n",
    "- åˆ†è§£åŽï¼š\n",
    "  - å…ˆç®— $z = B x$ï¼ˆç»´åº¦ $k$ï¼‰\n",
    "  - å†ç®— $A z$\n",
    "  - æ€»å¤æ‚åº¦ $O(kn + mk)$\n",
    "\n",
    "å¦‚æžœ $k \\ll \\min(m,n)$ï¼Œæ€»ä½“ FLOPs å¤§å¹…å‡å°‘ã€‚\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "- è¿™å°±æ˜¯å¾ˆå¤š **SVD-based compression / low-rank factorization / LoRA** å†…æ ¸çš„æ•°å­¦åŸºç¡€ã€‚\n",
    "- åœ¨æ¨¡åž‹éƒ¨ç½²æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æŸäº›å±‚è¢«æ›¿æ¢æˆä¸¤å±‚å°çš„ Linearï¼š`Linear(d_in â†’ k)` + `Linear(k â†’ d_out)`ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.5 æ–‡å­—å›¾ç¤ºï¼ˆçŸ©é˜µç»“æž„çš„å¯è§†åŒ–ï¼‰\n",
    "\n",
    "åŽŸå§‹çŸ©é˜µ $W$ï¼š\n",
    "\n",
    "```text\n",
    "W (mÃ—n)\n",
    "+------------------------+\n",
    "| â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ  |\n",
    "| â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ  |\n",
    "| â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ  |\n",
    "| â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ  |\n",
    "|         Â·Â·Â·            |\n",
    "+------------------------+\n",
    "```\n",
    "\n",
    "ä½Žç§©åˆ†è§£åŽï¼š\n",
    "\n",
    "```text\n",
    "A (mÃ—k)          B (kÃ—n)\n",
    "+------+       +------------------+\n",
    "| â–ˆ â–ˆ |       | â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ   |\n",
    "| â–ˆ â–ˆ |   x   | â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ â–ˆ   |\n",
    "| â–ˆ â–ˆ |       |        Â·Â·Â·        |\n",
    "| â–ˆ â–ˆ |       +------------------+\n",
    "+------+\n",
    "```\n",
    "\n",
    "æŽ¨ç†æ—¶ï¼š\n",
    "\n",
    "1. å…ˆè®¡ç®— $z = B x$ï¼ˆç»´åº¦ kï¼‰  \n",
    "2. å†è®¡ç®— $y = A z$\n",
    "\n",
    "å½“ k æ¯” m,n å°å¾ˆå¤šæ—¶ï¼Œè¿™æ˜¯æ˜¾è‘—çš„åŠ é€Ÿã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3.6 åœ¨æŽ¨ç†åŠ é€Ÿä¸­çš„å…¸åž‹ç”¨æ³•\n",
    "\n",
    "1. **MLP æƒé‡ä½Žç§©åˆ†è§£**  \n",
    "   - åŽŸå§‹ï¼š4096Ã—11008 çš„å·¨çŸ©é˜µ  \n",
    "   - åˆ†è§£ï¼š4096Ã—k å’Œ kÃ—11008ï¼Œk=1024 æˆ–æ›´å°  \n",
    "2. **LoRAï¼ˆLow-Rank Adaptationï¼‰**  \n",
    "   - æŠŠæ›´æ–°é‡ $\\Delta W$ å‚æ•°åŒ–ä¸º $A B$ï¼Œrank é€šå¸¸å¾ˆå°ï¼ˆå¦‚ 8ã€16ï¼‰  \n",
    "   - å¯¹éƒ¨ç½²æ¥è¯´ï¼ŒæŽ¨ç†æ—¶å¤šäº†ä¸¤å±‚å°çŸ©é˜µä¹˜æ³•\n",
    "3. **KV Cache åŽ‹ç¼© / æŠ•å½±**  \n",
    "   - ç”¨ä½Žç§©æ˜ å°„é™ä½Ž KV ç»´åº¦ï¼Œä»Žè€Œå‡å°‘å†…å­˜å’Œå¸¦å®½\n",
    "4. **ç»“æž„åŒ–å‰ªæžçš„æ›¿ä»£æ–¹æ¡ˆ**  \n",
    "   - ç›¸æ¯”ç›´æŽ¥ç¡¬å‰ªé€šé“ï¼Œä½Žç§©åˆ†è§£æ˜¯æ›´å¹³æ»‘çš„ç»´åº¦å‰Šå‡æ–¹å¼\n",
    "\n",
    "> åœ¨è¿™ç±»åšè¾¹ç¼˜æŽ¨ç†çš„åœºæ™¯ä¸­ï¼š  \n",
    "> - ä½ ä¼šå¸Œæœ›åœ¨ **ä¸å¤§å¹…é™ç²¾åº¦** çš„å‰æä¸‹ï¼Œ**æ˜¾è‘—å‡å°‘ MLP å’ŒæŠ•å½±å±‚çš„ FLOPs å’Œå‚æ•°é‡**ï¼Œä½Žç§©åˆ†è§£æ˜¯æœ€ä¸»æµçš„æ•°å­¦å·¥å…·ä¹‹ä¸€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787fdd01",
   "metadata": {
    "id": "787fdd01"
   },
   "source": [
    "## 1.4 çŸ©é˜µèŒƒæ•°ä¸Žè¯¯å·®åº¦é‡\n",
    "\n",
    "åœ¨åšä»»ä½•åŽ‹ç¼©ï¼ˆä½Žç§©ã€å‰ªæžã€é‡åŒ–ï¼‰æ—¶ï¼Œä½ éƒ½éœ€è¦ä¸€ä¸ªâ€œåº¦é‡æ ‡å‡†â€æ¥è¡¡é‡ï¼š\n",
    "\n",
    "- åŽ‹ç¼©å‰åŽçš„æƒé‡å·®å¼‚æœ‰å¤šå¤§ï¼Ÿ\n",
    "- è¿™ä¼šå¸¦æ¥å¤šå¤§çš„è¾“å‡ºè¯¯å·®ï¼Ÿ\n",
    "\n",
    "çŸ©é˜µèŒƒæ•°æä¾›äº†è¿™äº›åº¦é‡å·¥å…·ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4.1 Frobenius èŒƒæ•°ï¼ˆæ•´ä½“èƒ½é‡ï¼‰\n",
    "\n",
    "$$\n",
    "\\|W\\|_F = \\sqrt{\\sum_{i,j} w_{ij}^2}\n",
    "$$\n",
    "\n",
    "\n",
    "å¯¹åº”äºŽæŠŠçŸ©é˜µå½“æˆä¸€ä¸ªé•¿å‘é‡åŽçš„ $L_2$ èŒƒæ•°ã€‚\n",
    "\n",
    "- å®ƒè¡¡é‡æ•´ä½“â€œèƒ½é‡â€ï¼ˆenergyï¼‰\n",
    "- åœ¨ SVD ä¸­æœ‰éžå¸¸æ¼‚äº®çš„æ€§è´¨ï¼š\n",
    "\n",
    "$$\n",
    "\\|W\\|_F^2 = \\sum_{i=1}^r \\sigma_i^2\n",
    "$$\n",
    "\n",
    "\n",
    "è€Œå¯¹ä½Žç§©è¿‘ä¼¼ï¼š\n",
    "\n",
    "$$\n",
    "\\|W - W_k\\|_F^2 = \\sum_{i=k+1}^r \\sigma_i^2\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹åº”ç”¨ã€‘**  \n",
    "- å¯ä»¥é€šè¿‡å¥‡å¼‚å€¼å¿«é€Ÿä¼°è®¡åŽ‹ç¼©è¯¯å·®çš„ä¸Šç•Œ\n",
    "- å¯ä»¥æ¯”è¾ƒä¸åŒ $k$ å€¼ä¸‹çš„è¯¯å·®ï¼Œåš bitâ€“accuracy tradeoff\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4.2 è°±èŒƒæ•°ï¼ˆoperator norm / 2-èŒƒæ•°ï¼‰\n",
    "\n",
    "$$\n",
    "\\|W\\|_2 = \\sigma_{\\max}(W)\n",
    "$$\n",
    "\n",
    "\n",
    "- ç­‰äºŽæœ€å¤§çš„å¥‡å¼‚å€¼\n",
    "- åæ˜ ï¼š$W$ ä½œä¸ºçº¿æ€§ç®—å­èƒ½æŠŠå‘é‡æ”¾å¤§çš„æœ€å¤§æ¯”ä¾‹\n",
    "\n",
    "å…·ä½“æ¥è¯´ï¼š\n",
    "\n",
    "$$\n",
    "\\|W\\|_2 = \\max_{\\|x\\|_2 = 1} \\|W x\\|_2\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹æ„ä¹‰ã€‘**  \n",
    "- å¦‚æžœ $\\|W\\|_2$ éžå¸¸å¤§ï¼Œåˆ™å¯¹è¾“å…¥çš„å°æ‰°åŠ¨éžå¸¸æ•æ„Ÿ  \n",
    "**è§£é‡Š**ï¼šå½“çŸ©é˜µçš„è°±èŒƒæ•°ï¼ˆspectral normï¼‰ï¼Œå³ $|W|_2$ éžå¸¸å¤§æ—¶ï¼Œå®ƒæ„å‘³ç€è¿™ä¸ªçŸ©é˜µä½œä¸ºä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œèƒ½å¤Ÿå°†è¾“å…¥å‘é‡â€œæ”¾å¤§â€çš„æœ€å¤§æ¯”ä¾‹éžå¸¸å¤§ã€‚\n",
    "\n",
    "è°±èŒƒæ•°çš„å®šä¹‰æ˜¯ï¼š\n",
    "\n",
    "$$\n",
    "\\|W\\|_2 = \\max_{\\|x\\|_2 = 1} \\|W x\\|_2\n",
    "$$\n",
    "\n",
    "è¿™æ„å‘³ç€ï¼Œå¯¹äºŽä»»ä½•éžé›¶å‘é‡ $x$ï¼Œ\n",
    "\n",
    "$$|W x|_2 \\le |W|_2 |x|_2$$\n",
    "\n",
    "çŽ°åœ¨ï¼Œè€ƒè™‘ä¸€ä¸ªè¾“å…¥å‘é‡ $x_0$ å—åˆ°ä¸€ä¸ªå°æ‰°åŠ¨ $\\Delta x$ã€‚é‚£ä¹ˆï¼Œè¾“å‡ºçš„æ”¹å˜å°†æ˜¯ $W(x_0 + \\Delta x) - W x_0 = W \\Delta x$ã€‚\n",
    "\n",
    "è¾“å‡ºæ‰°åŠ¨çš„èŒƒæ•°æ˜¯ $|W \\Delta x|_2$ã€‚æ ¹æ®ä¸Šé¢çš„ä¸ç­‰å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š\n",
    "\n",
    "$$|W \\Delta x|_2 \\le |W|_2 |\\Delta x|_2$$\n",
    "\n",
    "å¦‚æžœ $|W|_2$ éžå¸¸å¤§ï¼Œå³ä½¿è¾“å…¥çš„æ‰°åŠ¨ $|\\Delta x|_2$ éžå¸¸å°ï¼Œç»è¿‡çŸ©é˜µ $W$ å˜æ¢åŽï¼Œè¾“å‡ºçš„æ‰°åŠ¨ $|W \\Delta x|_2$ ä¹Ÿä¼šè¢«æ”¾å¤§å¾ˆå¤šå€ã€‚è¿™æ„å‘³ç€åŽŸå§‹è¾“å…¥ä¸­å¾®å°çš„è¯¯å·®æˆ–å™ªå£°ï¼Œåœ¨ç»è¿‡è¿™ä¸ªçŸ©é˜µå±‚ä¹‹åŽï¼Œå¯èƒ½ä¼šè¢«æ˜¾è‘—æ”¾å¤§ï¼Œå¯¼è‡´è¾“å‡ºç»“æžœçš„å‰§çƒˆå˜åŒ–ã€‚\n",
    "\n",
    "æ€»ç»“æ¥è¯´ï¼š\n",
    "\n",
    "å¤§ $|W|_2$ æ„å‘³ç€å¼ºæ”¾å¤§æ•ˆåº”ï¼šçŸ©é˜µ $W$ æœ‰èƒ½åŠ›å°†æŸäº›æ–¹å‘ä¸Šçš„è¾“å…¥å‘é‡æ”¾å¤§å¾ˆå¤šå€ã€‚\n",
    "è¯¯å·®ä¼ æ’­ï¼šå½“è¾“å…¥å­˜åœ¨å°æ‰°åŠ¨æ—¶ï¼ˆæ¯”å¦‚é‡åŒ–è¯¯å·®ã€æµ®ç‚¹æ•°è¯¯å·®æˆ–ä¼ æ„Ÿå™¨å™ªå£°ï¼‰ï¼Œè¿™ä¸ªæ‰°åŠ¨ä¼šè¢« $|W|_2$ çš„å¤§å°æ‰€æ”¾å¤§ï¼Œä»Žè€Œå¯¼è‡´æœ€ç»ˆè¾“å‡ºçš„è¯¯å·®ä¹Ÿå¾ˆå¤§ã€‚\n",
    "åœ¨æŽ¨ç†ç³»ç»Ÿä¸­ï¼Œå°¤å…¶æ˜¯åœ¨é‡åŒ–æˆ–ä½Žç²¾åº¦è®¡ç®—æ—¶ï¼Œå¦‚æžœæ¨¡åž‹çš„æŸä¸ªæƒé‡çŸ©é˜µçš„è°±èŒƒæ•°è¿‡å¤§ï¼Œé‚£ä¹ˆè¯¥å±‚å°†å¯¹é‡åŒ–å™ªå£°ã€æ•°å€¼èˆå…¥è¯¯å·®éžå¸¸æ•æ„Ÿï¼Œå®¹æ˜“å¯¼è‡´ç²¾åº¦å¤§å¹…ä¸‹é™æˆ–è¾“å‡ºä¸ç¨³å®šã€‚å› æ­¤ï¼Œåœ¨æ¨¡åž‹è®¾è®¡æˆ–ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæœ‰æ—¶ä¼šé€šè¿‡æ­£åˆ™åŒ–ç­‰æ–¹å¼æ¥é™åˆ¶æƒé‡çš„è°±èŒƒæ•°ï¼Œä»¥æé«˜æ¨¡åž‹çš„é²æ£’æ€§å’Œæ•°å€¼ç¨³å®šæ€§ã€‚\n",
    "- åœ¨é‡åŒ–/å‰ªæžæ—¶ï¼Œè¿™ç§å±‚æ›´å®¹æ˜“å‡ºçŽ°æ•°å€¼ä¸ç¨³å®š / è¾“å‡ºæ¥å›žæŠ–åŠ¨  \n",
    "- æœ‰äº›é²æ£’æ€§åˆ†æžä¼šç”¨è°±èŒƒæ•°åš Lipschitz å¸¸æ•°çš„ä¸Šç•Œ\n",
    "\n",
    "**è§£é‡Š**ï¼š\n",
    "\n",
    "*ä»€ä¹ˆæ˜¯ Lipschitz å¸¸æ•°*ï¼š åœ¨æ•°å­¦ä¸­ï¼Œä¸€ä¸ªå‡½æ•° $f: X \\to Y$ æ˜¯ Lipschitz è¿žç»­çš„ï¼Œå¦‚æžœå­˜åœ¨ä¸€ä¸ªå¸¸æ•° $K \\ge 0$ï¼Œä½¿å¾—å¯¹äºŽ $X$ åŸŸä¸­çš„ä»»æ„ä¸¤ä¸ªç‚¹ $x_1$ å’Œ $x_2$ï¼Œéƒ½æœ‰ï¼š\n",
    "\n",
    "$$\\|f(x_1) - f(x_2)\\| \\le K \\|x_1 - x_2\\|$$\n",
    "è¿™ä¸ªå¸¸æ•° $K$ å°±è¢«ç§°ä¸ºè¯¥å‡½æ•°çš„ Lipschitz å¸¸æ•°ã€‚è¿™é‡Œçš„ $\\|\\cdot\\|$ è¡¨ç¤ºæŸç§èŒƒæ•°ï¼ˆä¾‹å¦‚å‘é‡çš„æ¬§å‡ é‡Œå¾—èŒƒæ•°æˆ–çŸ©é˜µçš„è°±èŒƒæ•°ï¼‰ã€‚\n",
    "\n",
    "*ç›´è§‚ç†è§£*ï¼š Lipschitz å¸¸æ•° $K$ ç»™å‡ºäº†å‡½æ•° â€œæœ€é™¡å³­â€ çš„ç¨‹åº¦ã€‚å®ƒé™åˆ¶äº†å‡½æ•°å€¼å˜åŒ–çš„é€ŸçŽ‡ï¼š\n",
    "\n",
    "å¦‚æžœ $K$å¾ˆå°ï¼Œå‡½æ•°æ˜¯â€œå¹³ç¼“â€çš„ï¼Œè¾“å‡ºçš„å˜åŒ–ä¸ä¼šæ¯”è¾“å…¥çš„å¾®å°å˜åŒ–å¤§å¤ªå¤šã€‚å®ƒåƒä¸€ä¸ªæ–œçŽ‡æœ‰é™çš„å‡½æ•°ã€‚\n",
    "å¦‚æžœ $K$å¾ˆå¤§ï¼Œå‡½æ•°å¯èƒ½æ˜¯â€œé™¡å³­â€çš„ï¼Œè¾“å‡ºçš„å˜åŒ–å¯èƒ½æ¯”è¾“å…¥çš„å¾®å°å˜åŒ–å¤§å¾ˆå¤šã€‚è¿™æ„å‘³ç€å‡½æ•°å¯¹è¾“å…¥çš„å°æ‰°åŠ¨éžå¸¸æ•æ„Ÿã€‚\n",
    "\n",
    "*æ•°å€¼ç¨³å®šæ€§ä¸Žè¯¯å·®ä¼ æ’­*ï¼šå¦‚æžœä¸€ä¸ªçŸ©é˜µï¼ˆå¯ä»¥çœ‹ä½œä¸€ä¸ªçº¿æ€§å‡½æ•°ï¼‰çš„è°±èŒƒæ•°å¾ˆå¤§ï¼Œé‚£ä¹ˆå®ƒä¼šå°†è¾“å…¥çš„å¾®å°è¯¯å·®æ”¾å¤§å¾ˆå¤šå€ã€‚ä¸€ä¸ªçº¿æ€§å‡½æ•° $f(x) = Wx$ çš„ Lipschitz å¸¸æ•°å°±æ˜¯å®ƒçš„è°±èŒƒæ•° $|W|_2$ã€‚\n",
    "å¯¹äºŽéžçº¿æ€§å‡½æ•°ï¼ˆå¦‚æ¿€æ´»å‡½æ•°ã€æ•´ä¸ªç¥žç»ç½‘ç»œï¼‰ï¼Œå…¶ Lipschitz å¸¸æ•°é™åˆ¶äº†è¾“å…¥å™ªå£°æˆ–é‡åŒ–è¯¯å·®åœ¨ç½‘ç»œä¸­ä¼ æ’­æ—¶çš„æœ€å¤§æ”¾å¤§å€æ•°ã€‚\n",
    "ä½Ž Lipschitz å¸¸æ•° çš„æ¨¡åž‹é€šå¸¸å…·æœ‰æ›´å¥½çš„ æ•°å€¼ç¨³å®šæ€§å’Œå¯¹æŠ—æ ·æœ¬çš„é²æ£’æ€§ã€‚\n",
    "\n",
    "*æ¨¡åž‹åŽ‹ç¼©ä¸Žé‡åŒ–*ï¼šåœ¨é‡åŒ–æˆ–å‰ªæžè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šå¯¹æ¨¡åž‹å‚æ•°å¼•å…¥å¾®å°çš„æ‰°åŠ¨ï¼ˆé‡åŒ–è¯¯å·®ï¼‰ã€‚å¦‚æžœæŸä¸€å±‚æˆ–æ•´ä¸ªæ¨¡åž‹çš„ Lipschitz å¸¸æ•°è¿‡å¤§ï¼Œè¿™äº›å¾®å°æ‰°åŠ¨å°±å¯èƒ½è¢«æ˜¾è‘—æ”¾å¤§ï¼Œå¯¼è‡´æ¨¡åž‹ç²¾åº¦æ€¥å‰§ä¸‹é™ã€‚\n",
    "å› æ­¤ï¼Œåœ¨è¿›è¡Œæ¨¡åž‹åŽ‹ç¼©æ—¶ï¼Œæœ‰æ—¶ä¼šå…³æ³¨ä¿æŒæˆ–é™åˆ¶æ¨¡åž‹çš„ Lipschitz å¸¸æ•°ï¼Œä»¥ç¡®ä¿åŽ‹ç¼©åŽçš„æ¨¡åž‹ä»ç„¶ç¨³å®šä¸”æ€§èƒ½è‰¯å¥½ã€‚åœ¨å®žè·µä¸­ï¼Œç›´æŽ¥è®¡ç®—å¤æ‚æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„ç²¾ç¡® Lipschitz å¸¸æ•°é€šå¸¸éžå¸¸å›°éš¾ï¼ˆNP-hardï¼‰ã€‚\n",
    "ä½†å¯ä»¥é€šè¿‡ä¸€äº›æ–¹æ³•æ¥ ä¼°è®¡å…¶ä¸Šç•Œ æˆ– æ­£åˆ™åŒ– æ¥é—´æŽ¥é™åˆ¶å®ƒï¼Œä¾‹å¦‚ï¼šè°±èŒƒæ•°æ­£åˆ™åŒ– (Spectral Normalization)ï¼šé™åˆ¶ç¥žç»ç½‘ç»œä¸­æƒé‡çŸ©é˜µçš„è°±èŒƒæ•°ï¼Œä»Žè€Œé™åˆ¶çº¿æ€§å±‚çš„ Lipschitz å¸¸æ•°ã€‚ æŸäº›æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUï¼‰æ˜¯ 1-Lipschitz çš„ï¼Œæœ‰åŠ©äºŽæŽ§åˆ¶ä¼ æ’­çš„æ”¾å¤§ã€‚Batch Normalization æˆ– Layer Normalization ä¹Ÿæœ‰åŠ©äºŽç¨³å®šæ¿€æ´»çš„åˆ†å¸ƒï¼Œé—´æŽ¥æŽ§åˆ¶å‡½æ•°çš„è¡Œä¸ºã€‚æ€»è€Œè¨€ä¹‹ï¼ŒLipschitz å¸¸æ•°æ˜¯è¡¡é‡å‡½æ•°å¹³æ»‘åº¦å’Œå¯¹è¾“å…¥æ‰°åŠ¨æ•æ„Ÿç¨‹åº¦çš„ä¸€ä¸ªé‡è¦æŒ‡æ ‡ã€‚\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4.3 $L_1$ å’Œ $L_0$ èŒƒæ•°ï¼ˆç¨€ç–æ€§ï¼‰\n",
    "\n",
    "- å…ƒç´ çº§ $L_1$ï¼š\n",
    "\n",
    "$$\n",
    "\\|W\\|_1 = \\sum_{i,j} |w_{ij}|\n",
    "$$\n",
    "\n",
    "\n",
    "- â€œ$L_0$â€ï¼ˆéžé›¶ä¸ªæ•°ï¼‰ï¼š\n",
    "\n",
    "$$\n",
    "\\|W\\|_0 = \\#\\{(i,j) : w_{ij} \\ne 0\\}\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- $L_0$ ç›´æŽ¥åº¦é‡â€œæœ‰å¤šå°‘å…ƒç´ è¢«ä¿ç•™/å‰ªæŽ‰â€ï¼Œä½†å¯¹åº”çš„ä¼˜åŒ–é—®é¢˜æ˜¯ NP-hard\n",
    "- é€šå¸¸ç”¨ $L_1$ ä½œä¸ºå‡¸è¿‘ä¼¼ï¼š\n",
    "\n",
    "$$\n",
    "L(W) + \\lambda \\|W\\|_1\n",
    "$$\n",
    "\n",
    "\n",
    "  è®­ç»ƒåŽå¾ˆå¤šå…ƒç´ è‡ªç„¶è¶‹è¿‘äºŽ 0ï¼Œæ–¹ä¾¿åšåŽå¤„ç†å‰ªæžã€‚\n",
    "\n",
    "**ã€å…·ä½“è§£é‡Šã€‘**\n",
    "1. $L_0$ èŒƒæ•°ï¼šç†æƒ³ä½†éš¾ä¼˜åŒ–\n",
    "å®šä¹‰ï¼š$\\|W\\|_0$ ä¸¥æ ¼æ¥è¯´ä¸æ˜¯ä¸€ä¸ªèŒƒæ•°ï¼Œå®ƒè¡¨ç¤ºçŸ©é˜µ $W$ ä¸­ éžé›¶å…ƒç´ çš„ä¸ªæ•°ã€‚\n",
    "ç›®æ ‡ï¼šåœ¨å‰ªæžä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æœ€å°åŒ–éžé›¶å…ƒç´ çš„æ•°é‡ï¼Œä»Žè€Œè®©æ¨¡åž‹å˜å¾—ç¨€ç–ï¼Œè¿™æ ·å¯ä»¥å‡å°‘å­˜å‚¨å’Œè®¡ç®—ã€‚æ‰€ä»¥ä¼˜åŒ–ç›®æ ‡å¯èƒ½æ˜¯è¿™æ ·çš„ï¼š\n",
    "$$\n",
    "\\min_{\\widehat{W}} \\; L(\\widehat{W}) \\;+\\; \\lambda \\,\\|\\widehat{W}\\|_{0}\n",
    "$$\n",
    "\n",
    "é—®é¢˜ï¼š$L_0$ èŒƒæ•°æ˜¯éžå‡¸ã€ä¸è¿žç»­çš„ï¼Œè¿™æ„å‘³ç€å®ƒæ²¡æœ‰è‰¯å¥½çš„æ•°å­¦æ€§è´¨ï¼Œå¯¼è‡´ä¼˜åŒ–é—®é¢˜æ˜¯ NP-hard çš„ï¼ˆå³è®¡ç®—ä¸Šéžå¸¸å›°éš¾ï¼Œæ²¡æœ‰é«˜æ•ˆçš„å…¨å±€æœ€ä¼˜è§£ç®—æ³•ï¼‰ã€‚ä½ æ— æ³•ç›´æŽ¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰åŸºäºŽæ¢¯åº¦çš„ä¼˜åŒ–æ–¹æ³•æ¥æœ€å°åŒ–å®ƒï¼Œå› ä¸ºå®ƒçš„æ¢¯åº¦å‡ ä¹Žå¤„å¤„ä¸ºé›¶æˆ–ä¸å­˜åœ¨ã€‚\n",
    "\n",
    "2. $L_1$ èŒƒæ•°ï¼šå‡¸ä¸”ä¿ƒè¿›ç¨€ç–æ€§\n",
    "å®šä¹‰ï¼š$\\|W\\|1$ è¡¨ç¤ºçŸ©é˜µ $W$ ä¸­æ‰€æœ‰å…ƒç´ çš„ ç»å¯¹å€¼ä¹‹å’Œï¼š\n",
    "$$\n",
    "\\|W\\|_1 = \\sum_{i,j} |w_{ij}|\n",
    "$$\n",
    "\n",
    "æ€§è´¨ï¼š\n",
    "\n",
    "å‡¸æ€§ï¼š$L_1$ èŒƒæ•°æ˜¯ä¸€ä¸ª å‡¸å‡½æ•°ã€‚è¿™æ„å‘³ç€å½“æˆ‘ä»¬å°†å®ƒä½œä¸ºæ­£åˆ™é¡¹åŠ å…¥æŸå¤±å‡½æ•°æ—¶ï¼Œæ•´ä¸ªä¼˜åŒ–é—®é¢˜ï¼ˆå¦‚æžœæ˜¯å‡¸æŸå¤±å‡½æ•°ï¼‰å°†ä»ç„¶æ˜¯å‡¸çš„ï¼Œæˆ–è€…è‡³å°‘æ˜¯æ›´å®¹æ˜“ä¼˜åŒ–çš„ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™åŠå…¶å˜ç§ï¼ˆä¾‹å¦‚æ¬¡æ¢¯åº¦ä¸‹é™ï¼Œå› ä¸º $|x|$ åœ¨ $x=0$ å¤„ä¸å¯å¯¼ï¼‰æ¥æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£æˆ–è¿‘ä¼¼æœ€ä¼˜è§£ã€‚\n",
    "\n",
    "ä¿ƒè¿›ç¨€ç–æ€§ï¼šè™½ç„¶ $L_1$ èŒƒæ•°ä¸ç›´æŽ¥ç»Ÿè®¡éžé›¶å…ƒç´ çš„ä¸ªæ•°ï¼Œä½†å®ƒæœ‰ä¸€ä¸ªéžå¸¸é‡è¦çš„æ€§è´¨ï¼šåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†æœ€å°åŒ– $\\sum |w_{ij}|$ï¼Œä¼˜åŒ–å™¨å€¾å‘äºŽå°†è®¸å¤šæƒé‡æŽ¨å‘ ç²¾ç¡®çš„é›¶ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªéžå¸¸å°ä½†éžé›¶çš„å€¼ã€‚è¿™æ˜¯å› ä¸º $|x|$ åœ¨ $x=0$ é™„è¿‘æœ‰ä¸€ä¸ªâ€œå°–ç‚¹â€ï¼Œè¿™ä½¿å¾—ä¼˜åŒ–å™¨åœ¨æŽ¥è¿‘é›¶æ—¶å—åˆ°æ›´å¤§çš„æƒ©ç½šï¼Œä»Žè€Œä¿ƒä½¿æƒé‡è·¨è¿‡é›¶ç‚¹ã€‚\n",
    "\n",
    "3. ä¸ºä»€ä¹ˆæ˜¯â€œå‡¸è¿‘ä¼¼â€ï¼Ÿ\n",
    "è¿‘ä¼¼ $L_0$ è¡Œä¸ºï¼šè™½ç„¶ $L_1$ ä¸ç­‰äºŽ $L_0$ï¼Œä½†å®ƒèƒ½æœ‰æ•ˆåœ°è¯±å¯¼ç¨€ç–æ€§ï¼Œä»Žè€Œåœ¨å®žè·µä¸­è¿‘ä¼¼è¾¾åˆ°æˆ‘ä»¬ç”¨ $L_0$ è¿½æ±‚çš„æ•ˆæžœï¼ˆå³å¾—åˆ°ä¸€ä¸ªæœ‰å¾ˆå¤šé›¶çš„æ¨¡åž‹ï¼‰ã€‚\n",
    "å¯ä¼˜åŒ–æ€§ï¼š $L_1$ æ˜¯å‡¸çš„ï¼Œè¿™ä½¿å¾—ä¼˜åŒ–é—®é¢˜å˜å¾—å¯è§£ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ•°å­¦ä¸Šæ›´å®¹æ˜“å¤„ç†çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…æ‰¾åˆ°ä¸€ä¸ªå¥½çš„è§£ã€‚æ‰€ä»¥ï¼Œå½“çœ‹åˆ°å‰ªæžçš„ä¼˜åŒ–ç›®æ ‡ä¸­åŒ…å« $L_1$ æ­£åˆ™é¡¹æ—¶ï¼Œæ¯”å¦‚ï¼š\n",
    "$$\n",
    "\\min_{\\widehat{W}} \\; L(\\widehat{W}) + \\lambda \\|\\widehat{W}\\|_1\n",
    "$$\n",
    "å®ƒçš„æ„æ€æ˜¯ï¼šæˆ‘ä»¬å¸Œæœ›åœ¨ä¿æŒæ¨¡åž‹ç²¾åº¦çš„åŒæ—¶ï¼ˆæœ€å°åŒ– $L(\\widehat{W})$ï¼‰ï¼Œä¹Ÿèƒ½è®©æ¨¡åž‹çš„æƒé‡å°½å¯èƒ½å°ï¼Œå¹¶ä¸”å€¾å‘äºŽé›¶ï¼ˆæœ€å°åŒ– $\\lambda |\\widehat{W}|_1$ï¼‰ï¼Œä»Žè€Œè¾¾åˆ°ç¨€ç–åŒ–çš„ç›®çš„ã€‚è¿™ç§æ–¹æ³•æ˜¯å®žè·µä¸­å®žçŽ°æ¨¡åž‹ç¨€ç–åŒ–ï¼ˆå°¤å…¶æ˜¯éžç»“æž„åŒ–å‰ªæžï¼‰éžå¸¸å¸¸è§ä¸”æœ‰æ•ˆçš„æ–¹å¼ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4.4 åœ¨å·¥ç¨‹ä¸­å¦‚ä½•å®žé™…ä½¿ç”¨è¿™äº›èŒƒæ•°ï¼Ÿ\n",
    "\n",
    "1. **åˆ¤æ–­æŸå±‚æ˜¯å¦é€‚åˆä½Žç§©åˆ†è§£**  \n",
    "   - è®¡ç®—å¥‡å¼‚å€¼ $\\{\\sigma_i\\}$ï¼Œçœ‹å‰ k ä¸ªæ˜¯å¦å·²ç»å åˆ°æ•´ä½“èƒ½é‡çš„ç»å¤§éƒ¨åˆ†ï¼š\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^k \\sigma_i^2}{\\sum_{i=1}^r \\sigma_i^2} \\approx 0.95 \\text{ æˆ–æ›´é«˜}\n",
    "$$\n",
    "\n",
    "\n",
    "2. **è®¾è®¡å‰ªæžç­–ç•¥**  \n",
    "   - è‹¥æŸå±‚æƒé‡çš„ $L_1$ åˆ†å¸ƒæžä¸å‡åŒ€ï¼ˆå¤§é‡æŽ¥è¿‘ 0 çš„å…ƒç´ ï¼‰ï¼Œè¯´æ˜Žå­˜åœ¨è‡ªç„¶ç¨€ç–æ€§ â†’ å¯ä»¥å®‰å…¨å‰ªæž\n",
    "   - å¯ä»¥å¯¹æ¯ä¸€è¡Œ/æ¯ä¸€åˆ—è®¡ç®— $L_1$ æˆ– $L_2$ normï¼Œä½œä¸ºâ€œé€šé“é‡è¦æ€§â€çš„æŒ‡æ ‡\n",
    "\n",
    "3. **é‡åŒ–æ•æ„Ÿæ€§åˆ†æž**  \n",
    "   - å¯¹äºŽè°±èŒƒæ•°è¾ƒå¤§çš„å±‚ï¼Œå¯ä»¥è€ƒè™‘ï¼š\n",
    "     - ä½¿ç”¨æ›´é«˜ bit çš„é‡åŒ–ï¼ˆä¾‹å¦‚ 8-bit è€Œä¸æ˜¯ 4-bitï¼‰\n",
    "     - æˆ–åšæ›´ç»†è‡´çš„ per-channel scaling æ¥å‡å°é‡åŒ–è¯¯å·®\n",
    "\n",
    "> æ€»ç»“ï¼šèŒƒæ•°å¸®åŠ©ä½ ä»Žâ€œæ‹è„‘è¢‹é€‰å±‚/é€‰ rank/é€‰ bitâ€  \n",
    "> å˜æˆâ€œæœ‰æŒ‡æ ‡ã€æœ‰ä¾æ®çš„å·¥ç¨‹å†³ç­–â€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fdf9a",
   "metadata": {},
   "source": [
    "### 1.4.5 ä¾‹å­\n",
    "ä¸‰ç±»èŒƒæ•°çš„å·¥ç¨‹å†³ç­–æ•´åˆä¾‹å­ã€‚\n",
    "å‡è®¾æœ‰ä¸€ä¸ª Transformer FFN å±‚ ð‘Š\n",
    "è®¡ç®—ç»“æžœå¦‚ä¸‹\n",
    "\n",
    "| æŒ‡æ ‡           | æ•°å€¼           | è§£é‡Š                |\n",
    "| ------------ | ------------ | ----------------- |\n",
    "| å¥‡å¼‚å€¼èƒ½é‡ E(128) | 96.3%        | å¾ˆé€‚åˆä½Žç§©åˆ†è§£ï¼ˆrank=128ï¼‰ |\n",
    "| å¹³å‡ L1 norm   | å¤§é‡è¡Œåœ¨ 0.01 ä»¥ä¸‹ | æœ‰ç¨€ç–æ€§ï¼Œå¯åšå‰ªæž         |\n",
    "| æœ€å¤§å¥‡å¼‚å€¼ï¼ˆè°±èŒƒæ•°ï¼‰   | 780          | é‡åŒ–æ•æ„Ÿï¼Œä¸è¦ç”¨å¤ªä½Ž bit    |\n",
    "\n",
    "æœ€ç»ˆå·¥ç¨‹å†³ç­–å¯èƒ½æ˜¯\n",
    "ðŸ”¹ ç¬¬ä¸€æ­¥ï¼šä½Žç§©åˆ†è§£\n",
    "\n",
    "æŠŠ 4096Ã—4096 é™åˆ° rank=128\n",
    "â†’ å‚æ•°ä»Ž 16M â†’ 1M\n",
    "â†’ FLOPs ä»Ž 33M â†’ 2M\n",
    "\n",
    "ðŸ”¹ ç¬¬äºŒæ­¥ï¼šç»“æž„åŒ–å‰ªæž\n",
    "\n",
    "ç”±äºŽ L1 åˆ†å¸ƒç¨€ç– â†’ åŽ»æŽ‰ 20% æ— ç”¨é€šé“\n",
    "â†’ é€šé“æ•°ä»Ž 4096 â†’ 3276\n",
    "\n",
    "ðŸ”¹ ç¬¬ä¸‰æ­¥ï¼šé‡åŒ–\n",
    "\n",
    "å› ä¸ºè°±èŒƒæ•°å¤§ â†’ ä¸èƒ½ç”¨ INT4\n",
    "âœ” é€‰ FP16 æˆ– INT8-per-channel\n",
    "\n",
    "æœ€ç»ˆæ•ˆæžœï¼š\n",
    "\n",
    "æ¨¡åž‹å¤§å°å‡å°‘çº¦ 16Ã— Ã— 1.25Ã— = 20Ã—\n",
    "\n",
    "FLOPs é™åˆ°åŽŸæ¥çš„ 1/10~1/15\n",
    "\n",
    "å»¶è¿Ÿæ˜¾è‘—é™ä½Žï¼Œæ²¡æœ‰æ˜Žæ˜¾ç²¾åº¦æŸå¤±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507a3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Analyzing layer: conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (64, 3, 7, 7)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 58\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (2.725, 2.836, 2.943)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 0.5254\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer1.0.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (64, 64, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 62\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (25.9, 26.52, 27.24)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.879\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer1.0.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (64, 64, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 62\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (25.85, 26.45, 26.94)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.843\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer1.1.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (64, 64, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 62\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (25.99, 26.37, 26.87)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.872\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer1.1.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (64, 64, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 62\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (25.8, 26.4, 27.07)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.826\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer2.0.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (128, 64, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 128\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 121\n",
      "  k (capped by 0.50*min_dim) = 64\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (18.57, 18.93, 19.24)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.459\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer2.0.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (128, 128, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 128\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 123\n",
      "  k (capped by 0.50*min_dim) = 64\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (37.32, 37.85, 38.33)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.882\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer2.0.downsample.0\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (128, 64, 1, 1)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 64\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 56\n",
      "  k (capped by 0.50*min_dim) = 32\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (5.622, 6.092, 6.589)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 2.348\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer2.1.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (128, 128, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 128\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 123\n",
      "  k (capped by 0.50*min_dim) = 64\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (37.35, 37.88, 38.33)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.882\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer2.1.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (128, 128, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 128\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 123\n",
      "  k (capped by 0.50*min_dim) = 64\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (37.23, 37.79, 38.37)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.857\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer3.0.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (256, 128, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 256\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 241\n",
      "  k (capped by 0.50*min_dim) = 128\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (26.36, 26.69, 27.07)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.462\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer3.0.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (256, 256, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 256\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 246\n",
      "  k (capped by 0.50*min_dim) = 128\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (53.02, 53.59, 54.23)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.876\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer3.0.downsample.0\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (256, 128, 1, 1)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 128\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 113\n",
      "  k (capped by 0.50*min_dim) = 64\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (8.255, 8.614, 9.036)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 2.376\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer3.1.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (256, 256, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 256\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 246\n",
      "  k (capped by 0.50*min_dim) = 128\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (53.09, 53.57, 54.14)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.876\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer3.1.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (256, 256, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 256\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 246\n",
      "  k (capped by 0.50*min_dim) = 128\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (53.01, 53.58, 54.12)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.876\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer4.0.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (512, 256, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 512\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 482\n",
      "  k (capped by 0.50*min_dim) = 256\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (37.57, 37.95, 38.33)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.468\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer4.0.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (512, 512, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 512\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 491\n",
      "  k (capped by 0.50*min_dim) = 256\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (75.46, 75.98, 76.53)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.882\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer4.0.downsample.0\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (512, 256, 1, 1)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 256\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 226\n",
      "  k (capped by 0.50*min_dim) = 128\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (11.94, 12.34, 12.76)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 2.399\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer4.1.conv1\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (512, 512, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 512\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 491\n",
      "  k (capped by 0.50*min_dim) = 256\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (75.6, 76.07, 76.6)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.88\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: layer4.1.conv2\n",
      "============================================================\n",
      "Layer: Conv2d, weight shape = (512, 512, 3, 3)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 512\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 491\n",
      "  k (capped by 0.50*min_dim) = 256\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (75.47, 76.03, 76.61)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.87\n",
      "  Recommended quant bits = 4-bit\n",
      "\n",
      ">>> Analyzing layer: fc\n",
      "============================================================\n",
      "Layer: Linear, weight shape = (1000, 512)\n",
      "--- Low-rank analysis ---\n",
      "  min(out_dim, in_dim)  = 512\n",
      "  target energy         = 0.980\n",
      "  k (reach target)      = 449\n",
      "  k (capped by 0.50*min_dim) = 256\n",
      "  Compression ratio     â‰ˆ 2.00x (in FLOPs/params)\n",
      "\n",
      "--- L1 sparsity / pruning analysis ---\n",
      "  L1 per-out quantiles  (10%,25%,50%) = (10.95, 11.12, 11.3)\n",
      "  Recommended prune ratio (by channels) â‰ˆ 0.0%\n",
      "\n",
      "--- Quantization sensitivity ---\n",
      "  Spectral norm ||W||_2 = 1.374\n",
      "  Recommended quant bits = 4-bit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def get_weight_2d(layer: nn.Module):\n",
    "    \"\"\"\n",
    "    flatten the weight of a layer into 2D matrix\n",
    "    \"\"\"\n",
    "    W = layer.weight.detach().float().clone()\n",
    "\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        # [out_features, in_features]\n",
    "        W2d = W  # already 2D\n",
    "    elif isinstance(layer, nn.Conv2d):\n",
    "        # [out_channels, in_channels, kh, kw] -> [out_channels, in_channels*kh*kw]\n",
    "        out_c, in_c, kh, kw = W.shape\n",
    "        W2d = W.view(out_c, in_c * kh * kw)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported layer type: {type(layer)}\")\n",
    "\n",
    "    return W2d\n",
    "\n",
    "\n",
    "def analyze_layer(layer: nn.Module,\n",
    "                  energy_target: float = 0.98,\n",
    "                  max_rank_ratio: float = 0.5,\n",
    "                  max_prune_ratio: float = 0.5):\n",
    "    \"\"\"\n",
    "    for a given layer,\n",
    "    - SVD analysis â†’ recommend low-rank\n",
    "    - L1 distribution analysis â†’ recommend pruning ratio (by output channels)\n",
    "    - Spectral norm analysis â†’ recommend quantization bits\n",
    "    \"\"\"\n",
    "    W2d = get_weight_2d(layer)                  # [out_dim, in_dim]\n",
    "    out_dim, in_dim = W2d.shape\n",
    "\n",
    "    # ===== 1. SVD & rank recommendation =====\n",
    "    # only need singular values, and skip U and V\n",
    "    # note: for very large matrices, consider using randomized\n",
    "    sigma = torch.linalg.svdvals(W2d)           # [min(out_dim, in_dim)]\n",
    "    sigma2 = sigma ** 2\n",
    "    total_energy = sigma2.sum()\n",
    "    cum_energy = torch.cumsum(sigma2, dim=0) / total_energy\n",
    "\n",
    "    # Find the smallest k such that cum_energy[k-1] >= energy_target\n",
    "    k_candidate = int((cum_energy >= energy_target).nonzero(as_tuple=True)[0][0].item() + 1)\n",
    "    \n",
    "    # Do not exceed max_rank_ratio * min_dim to prevent keeping too many components\n",
    "    max_rank = int(min(out_dim, in_dim) * max_rank_ratio)\n",
    "    k_recommended = min(k_candidate, max_rank)\n",
    "\n",
    "    # ===== 2. L1 distribution & pruning ratio recommendation (by output channels) =====\n",
    "    # compute L1 norm for each output channel\n",
    "    l1_per_out = W2d.abs().sum(dim=1)          # [out_dim]\n",
    "    l1_np = l1_per_out.cpu().numpy()\n",
    "    # compute several percentiles to sense sparsity\n",
    "    q10, q25, q50 = np.percentile(l1_np, [10, 25, 50])\n",
    "\n",
    "    # If the gap between the low percentile and the median is large,\n",
    "    # it indicates that the tail channels are not important and can be pruned.\n",
    "    # Simple heuristic: check if the 25% percentile is significantly smaller than the 50% percentile.\n",
    "    prune_ratio = 0.0\n",
    "    if q25 < 0.3 * q50:\n",
    "        # very sparse, can prune up to 30%\n",
    "        prune_ratio = min(0.3, max_prune_ratio)\n",
    "    elif q25 < 0.5 * q50:\n",
    "        # slightly sparse, can prune up to 15%\n",
    "        prune_ratio = min(0.15, max_prune_ratio)\n",
    "    else:\n",
    "        prune_ratio = 0.0  # ä¸å»ºè®®å‰ª\n",
    "\n",
    "    # ===== Spectral norm & quantization bits recommendation =====\n",
    "    spectral_norm = sigma.max().item()\n",
    "\n",
    "    # Very rough heuristic:\n",
    "    if spectral_norm < 5:\n",
    "        quant_bits = 4 \n",
    "    elif spectral_norm < 20:\n",
    "        quant_bits = 8 \n",
    "    else:\n",
    "        # Recommended minimally 8 bits (or even 16 bits) with per-channel scaling\n",
    "        quant_bits = 8  \n",
    "\n",
    "    # print results\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Layer: {layer.__class__.__name__}, weight shape = {tuple(layer.weight.shape)}\")\n",
    "    print(\"--- Low-rank analysis ---\")\n",
    "    print(f\"  min(out_dim, in_dim)  = {min(out_dim, in_dim)}\")\n",
    "    print(f\"  target energy         = {energy_target:.3f}\")\n",
    "    print(f\"  k (reach target)      = {k_candidate}\")\n",
    "    print(f\"  k (capped by {max_rank_ratio:.2f}*min_dim) = {k_recommended}\")\n",
    "    print(f\"  Compression ratio     â‰ˆ {min(out_dim, in_dim) / k_recommended:.2f}x (in FLOPs/params)\")\n",
    "\n",
    "    print(\"\\n--- L1 sparsity / pruning analysis ---\")\n",
    "    print(f\"  L1 per-out quantiles  (10%,25%,50%) = ({q10:.4g}, {q25:.4g}, {q50:.4g})\")\n",
    "    print(f\"  Recommended prune ratio (by channels) â‰ˆ {prune_ratio*100:.1f}%\")\n",
    "\n",
    "    print(\"\\n--- Quantization sensitivity ---\")\n",
    "    print(f\"  Spectral norm ||W||_2 = {spectral_norm:.4g}\")\n",
    "    print(f\"  Recommended quant bits = {quant_bits}-bit\")\n",
    "\n",
    "    return {\n",
    "        \"sigma\": sigma,\n",
    "        \"cum_energy\": cum_energy,\n",
    "        \"recommended_rank\": k_recommended,\n",
    "        \"recommended_prune_ratio\": prune_ratio,\n",
    "        \"spectral_norm\": spectral_norm,\n",
    "        \"recommended_quant_bits\": quant_bits,\n",
    "    }\n",
    "\n",
    "\n",
    "try:\n",
    "    from torchvision.models import resnet18\n",
    "    # load no pre-trained weights\n",
    "    model = resnet18(weights=None)  \n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Traverse all sub-modules\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "        print(f\"\\n>>> Analyzing layer: {name}\")\n",
    "        analyze_layer(module, energy_target=0.98, max_rank_ratio=0.5, max_prune_ratio=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa23b4",
   "metadata": {
    "id": "9faa23b4"
   },
   "source": [
    "## 1.5 å·ç§¯çš„çº¿æ€§ä»£æ•°è¡¨è¾¾ï¼šConv = MatMul\n",
    "\n",
    "å·ç§¯å±‚ï¼ˆConv2dï¼‰æ˜¯ CNN å’Œå¾ˆå¤šè§†è§‰æ¨¡åž‹çš„æ ¸å¿ƒã€‚  \n",
    "ä»Žæ•°å­¦ä¸Šï¼Œå®ƒæ˜¯ä¸€ä¸ªå¸¦æœ‰ç»“æž„çš„çº¿æ€§ç®—å­ï¼š\n",
    "\n",
    "$$\n",
    "y = K * x\n",
    "$$\n",
    "\n",
    "\n",
    "- $x$ï¼šè¾“å…¥ç‰¹å¾å›¾ï¼ˆå¦‚ $\\mathbb{R}^{C_{\\text{in}} \\times H \\times W}$ï¼‰  \n",
    "- $K$ï¼šå·ç§¯æ ¸ï¼ˆå¦‚ $\\mathbb{R}^{C_{\\text{out}} \\times C_{\\text{in}} \\times k_h \\times k_w}$ï¼‰\n",
    "\n",
    "é€šè¿‡é€‚å½“å±•å¼€å’Œé‡æŽ’ï¼Œå¯ä»¥æŠŠå®ƒæ”¹å†™ä¸º**çŸ©é˜µä¹˜æ³•**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5.1 im2colï¼šæŠŠå±€éƒ¨ patch å±•æˆåˆ—å‘é‡\n",
    "\n",
    "ä»¥å•é€šé“ã€kernel=2Ã—2ã€stride=1 ä¸ºä¾‹ï¼š\n",
    "\n",
    "è¾“å…¥ï¼š\n",
    "\n",
    "```text\n",
    "1 2 3\n",
    "4 5 6\n",
    "7 8 9\n",
    "```\n",
    "\n",
    "å·ç§¯æ ¸ï¼š\n",
    "\n",
    "```text\n",
    "k11 k12\n",
    "k21 k22\n",
    "```\n",
    "\n",
    "æ‰€æœ‰ 2Ã—2 patchï¼š\n",
    "\n",
    "1. ä¸Šå·¦ï¼š$\\{1,2,4,5\\}$\n",
    "2. ä¸Šå³ï¼š$\\{2,3,5,6\\}$\n",
    "3. ä¸‹å·¦ï¼š$\\{4,5,7,8\\}$\n",
    "4. ä¸‹å³ï¼š$\\{5,6,8,9\\}$\n",
    "\n",
    "æˆ‘ä»¬æŠŠæ¯ä¸ª patch æŒ‰å›ºå®šé¡ºåºå±•å¼€æˆåˆ—å‘é‡ï¼ˆä¹Ÿå°±æ˜¯ä»Žå·¦ä¸Šå¼€å§‹ï¼Œçª—å£å¤§å° 2Ã—2ï¼Œæ°´å¹³/åž‚ç›´å„æ»‘åŠ¨ä¸€æ­¥ï¼Œæžšä¸¾æ‰€æœ‰å¯èƒ½çš„ 2Ã—2 patchï¼‰ï¼š\n",
    "\n",
    "$$\n",
    "x_1 = [1,2,4,5]^\\top, \\quad\n",
    "x_2 = [2,3,5,6]^\\top, \\quad\n",
    "x_3 = [4,5,7,8]^\\top, \\quad\n",
    "x_4 = [5,6,8,9]^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "ç„¶åŽç»„æˆä¸€ä¸ªçŸ©é˜µ $X_{\\text{col}} = \\{x_1, x_2, x_3, x_4\\}$ï¼š\n",
    "\n",
    "$$\n",
    "X_{\\text{col}} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 4 & 5 \\\\\n",
    "2 & 3 & 5 & 6 \\\\\n",
    "4 & 5 & 7 & 8 \\\\\n",
    "5 & 6 & 8 & 9\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{4 \\times 4}\n",
    "$$\n",
    "\n",
    "\n",
    "å·ç§¯æ ¸ä¹Ÿå±•å¼€æˆå‘é‡ï¼š\n",
    "\n",
    "$$\n",
    "w = [k_{11}, k_{12}, k_{21}, k_{22}]\n",
    "$$\n",
    "\n",
    "\n",
    "åˆ™æ¯ä¸ªè¾“å‡ºä½ç½®ï¼š\n",
    "\n",
    "$$\n",
    "y_i = w x_i\n",
    "$$\n",
    "\n",
    "\n",
    "æ‰€æœ‰ä½ç½®ä¸€èµ·å†™æˆçŸ©é˜µå½¢å¼ï¼š\n",
    "\n",
    "$$\n",
    "y^\\top = w X_{\\text{col}}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5.2 å¤šé€šé“ / å¤šå·ç§¯æ ¸çš„æƒ…å†µ\n",
    "\n",
    "å¯¹äºŽä¸€èˆ¬æƒ…å†µï¼š\n",
    "\n",
    "- è¾“å…¥ï¼š$x \\in \\mathbb{R}^{C_{\\text{in}} \\times H \\times W}$\n",
    "- å·ç§¯æ ¸ï¼š$K \\in \\mathbb{R}^{C_{\\text{out}} \\times C_{\\text{in}} \\times k_h \\times k_w}$\n",
    "\n",
    "é€šè¿‡ im2colï¼š\n",
    "\n",
    "- ç”ŸæˆçŸ©é˜µ $X_{\\text{col}} \\in \\mathbb{R}^{(C_{\\text{in}} k_h k_w) \\times L}$  \n",
    "  å…¶ä¸­ L æ˜¯æ»‘çª—æ•°é‡ï¼ˆè¾“å‡ºç©ºé—´å°ºå¯¸çš„ä¹˜ç§¯ï¼‰\n",
    "- å·ç§¯æ ¸åŽ‹å¹³æˆçŸ©é˜µ $W \\in \\mathbb{R}^{C_{\\text{out}} \\times (C_{\\text{in}} k_h k_w)}$\n",
    "\n",
    "åˆ™å·ç§¯å¯ä»¥å†™æˆï¼š\n",
    "\n",
    "$$\n",
    "Y = W X_{\\text{col}}\n",
    "$$\n",
    "\n",
    "\n",
    "- $Y \\in \\mathbb{R}^{C_{\\text{out}} \\times L}$ï¼Œä¹‹åŽ reshape å›žè¾“å‡ºå°ºå¯¸\n",
    "\n",
    "**ã€æ ¸å¿ƒç»“è®ºã€‘**  \n",
    "> Conv2d ç»è¿‡ im2col å˜æ¢åŽï¼Œæœ¬è´¨å°±æ˜¯ä¸€ä¸ª GEMMã€‚\n",
    "\n",
    "---\n",
    "### 1.5.3 å¤šæ ¸å¤šé€šé“ä¾‹å­\n",
    "è®¾ï¼š\n",
    "- è¾“å…¥ç‰¹å¾å›¾ï¼š$x \\in \\mathbb{R}^{C_{\\text{in}} \\times H \\times W},\\quad\n",
    "C_{\\text{in}} = 2,\\ H=W=3$\n",
    "- å·ç§¯æ ¸ï¼š $K \\in \\mathbb{R}^{C_{\\text{out}} \\times C_{\\text{in}} \\times k_h \\times k_w},\\quad\n",
    "C_{\\text{out}} = 2,\\ k_h=k_w=2$\n",
    "- stride = 1, padding = 0\n",
    "- è¾“å‡ºç©ºé—´å°ºå¯¸ï¼š$H_{\\text{out}} = W_{\\text{out}} = 3-2+1 = 2$\n",
    "æ‰€ä»¥ä¸€å…± $L = H_{\\text{out}} \\cdot W_{\\text{out}} = 4$ ä¸ªè¾“å‡ºä½ç½®ã€‚\n",
    "---\n",
    "1. è¾“å…¥æ•°æ®ï¼ˆ2 ä¸ªé€šé“ï¼‰\n",
    "- ç¬¬ 1 ä¸ªé€šé“ï¼ˆc=0ï¼‰ï¼š\n",
    "$\\begin{array}{c} x^{(0)} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "- ç¬¬ 2 ä¸ªé€šé“ï¼ˆc=1ï¼‰ï¼š\n",
    "$\\begin{array}{c} x^{(1)} =\n",
    "\\begin{bmatrix}\n",
    "10 & 11 & 12 \\\\\n",
    "13 & 14 & 15 \\\\\n",
    "16 & 17 & 18\n",
    "\\end{bmatrix} \\end{array}$\n",
    "---\n",
    "2. å·ç§¯æ ¸ï¼ˆ2 ä¸ªè¾“å‡ºé€šé“ = 2 ä¸ª filterï¼‰\n",
    "æ¯ä¸ªå·ç§¯æ ¸å¯¹ä¸¤ä¸ªè¾“å…¥é€šé“éƒ½æœ‰è‡ªå·±çš„ 2Ã—2 kernelï¼š\n",
    "- ç¬¬ 1 ä¸ªè¾“å‡ºé€šé“ï¼ˆfilter 0ï¼‰ï¼š\n",
    "$\\begin{array}{c} K^{(0,0)} =\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "K^{(0,1)} =\n",
    "\\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22}\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "- ç¬¬ 2 ä¸ªè¾“å‡ºé€šé“ï¼ˆfilter 1ï¼‰ï¼š\n",
    "$\\begin{array}{c} K^{(1,0)} =\n",
    "\\begin{bmatrix}\n",
    "c_{11} & c_{12} \\\\\n",
    "c_{21} & c_{22}\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "K^{(1,1)} =\n",
    "\\begin{bmatrix}\n",
    "d_{11} & d_{12} \\\\\n",
    "d_{21} & d_{22}\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "è¿™é‡Œ $(0,0)$  è¡¨ç¤ºï¼šè¾“å‡ºé€šé“ 0ï¼Œå¯¹è¾“å…¥é€šé“ 0 çš„ kernelï¼Œ $(0,1)$ è¡¨ç¤ºï¼šè¾“å‡ºé€šé“ 0ï¼Œå¯¹è¾“å…¥é€šé“ 1 çš„ kernelï¼Œä¾æ­¤ç±»æŽ¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "3. ç”¨ im2col å±•å¼€å¤šé€šé“ patch â†’ åˆ—å‘é‡\n",
    "è¾“å‡ºç©ºé—´æ˜¯ 2Ã—2ï¼Œæ‰€ä»¥æœ‰ 4 ä¸ªæ»‘çª—ä½ç½®ï¼š\n",
    "\n",
    "- å·¦ä¸Šï¼šè¦†ç›–è¾“å…¥åæ ‡ (0:2, 0:2)\n",
    "\n",
    "- å³ä¸Šï¼šè¦†ç›– (0:2, 1:3)\n",
    "\n",
    "- å·¦ä¸‹ï¼šè¦†ç›– (1:3, 0:2)\n",
    "\n",
    "- å³ä¸‹ï¼šè¦†ç›– (1:3, 1:3)\n",
    "\n",
    "å¯¹æ¯ä¸ªä½ç½®ï¼Œæˆ‘ä»¬è¦ä»Ž ä¸¤ä¸ªé€šé“ å„å–ä¸€ä¸ª 2Ã—2 patchï¼Œç„¶åŽå…¨éƒ¨æ‘Šå¹³æŽ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªé•¿åº¦ä¸º $C_{\\text{in}} \\cdot k_h \\cdot k_w = 2 \\cdot 2 \\cdot 2 = 8$ çš„åˆ—å‘é‡ã€‚\n",
    "\n",
    "ðŸ”¹ ä½ç½® 1ï¼šå·¦ä¸Š patchï¼ˆtop-leftï¼‰\n",
    "- é€šé“ 0 çš„ 2Ã—2 patchï¼š\n",
    "$\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "4 & 5\n",
    "\\end{bmatrix}$\n",
    "- é€šé“ 1 çš„ 2Ã—2 patchï¼š\n",
    "$\\begin{bmatrix}\n",
    "10 & 11 \\\\\n",
    "13 & 14\n",
    "\\end{bmatrix}$\n",
    "\n",
    "æŒ‰å›ºå®šé¡ºåºï¼ˆæ¯”å¦‚ï¼šé€šé“é¡ºåºä¼˜å…ˆï¼Œæ¯ä¸ª patch æŒ‰è¡Œå±•å¹³ï¼‰æ‘Šå¹³å¹¶æ‹¼æŽ¥ï¼š\n",
    "$\\begin{array}{c} x_{\\text{col},1} =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 2 \\\\ 4 \\\\ 5 \\\\ 10 \\\\ 11 \\\\ 13 \\\\ 14\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{8} \\end{array}$\n",
    "\n",
    "ðŸ”¹ ä½ç½® 2ï¼šå³ä¸Š patchï¼ˆtop-rightï¼‰\n",
    "- é€šé“ 0ï¼š$\\begin{bmatrix} 2 & 3 \\\\ 5 & 6 \\end{bmatrix}$\n",
    "- é€šé“ 1ï¼š$\\begin{bmatrix} 11 & 12 \\\\ 14 & 15 \\end{bmatrix}$\n",
    "å±•å¼€ï¼š\n",
    "$\\begin{array}{c} x_{\\text{col},2} =\n",
    "\\begin{bmatrix}\n",
    "2 \\\\ 3 \\\\ 5 \\\\ 6 \\\\ 11 \\\\ 12 \\\\ 14 \\\\ 15\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "ðŸ”¹ ä½ç½® 3ï¼šå·¦ä¸‹ patchï¼ˆbottom-leftï¼‰\n",
    "- é€šé“ 0ï¼š$\\begin{bmatrix} 4 & 5 \\\\ 7 & 8 \\end{bmatrix}$\n",
    "- é€šé“ 1ï¼š$\\begin{bmatrix} 13 & 14 \\\\ 16 & 17 \\end{bmatrix}$\n",
    "å±•å¼€ï¼š\n",
    "$\\begin{array}{c} x_{\\text{col},3} =\n",
    "\\begin{bmatrix}\n",
    "4 \\\\ 5 \\\\ 7 \\\\ 8 \\\\ 13 \\\\ 14 \\\\ 16 \\\\ 17\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "ðŸ”¹ä½ç½® 4ï¼šå³ä¸‹ patchï¼ˆbottom-rightï¼‰\n",
    "- é€šé“ 0ï¼š$\\begin{bmatrix} 5 & 6 \\\\ 8 & 9 \\end{bmatrix}$\n",
    "- é€šé“ 1ï¼š$\\begin{bmatrix} 14 & 15 \\\\ 17 & 18 \\end{bmatrix}$\n",
    "å±•å¼€ï¼š\n",
    "$\\begin{array}{c} x_{\\text{col},4} =\n",
    "\\begin{bmatrix}\n",
    "5 \\\\ 6 \\\\ 8 \\\\ 9 \\\\ 14 \\\\ 15 \\\\ 17 \\\\ 18\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "ðŸ”¹ ç»„åˆæˆ $X_{\\text{col}}$ æŠŠ 4 ä¸ªåˆ—å‘é‡æ‹¼åœ¨ä¸€èµ·ï¼š\n",
    "$\\begin{array}{c} X_{\\text{col}} =\n",
    "\\begin{bmatrix}\n",
    "1  & 2  & 4  & 5  \\\\\n",
    "2  & 3  & 5  & 6  \\\\\n",
    "4  & 5  & 7  & 8  \\\\\n",
    "5  & 6  & 8  & 9  \\\\\n",
    "10 & 11 & 13 & 14 \\\\\n",
    "11 & 12 & 14 & 15 \\\\\n",
    "13 & 14 & 16 & 17 \\\\\n",
    "14 & 15 & 17 & 18\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{8 \\times 4} \\end{array}$\n",
    "\n",
    "---\n",
    "4ã€‚ å·ç§¯æ ¸å±•å¹³æˆçŸ©é˜µ Wï¼ˆå¤šå·ç§¯æ ¸ â†’ å¤šè¡Œï¼‰\n",
    "æ¯ä¸ªè¾“å‡ºé€šé“çš„ filter æ˜¯ ä¸¤ä¸ª 2Ã—2 çš„ kernelï¼ˆå¯¹åº” 2 ä¸ªè¾“å…¥é€šé“ï¼‰ï¼Œæˆ‘ä»¬ä¹ŸæŠŠå®ƒä»¬å±•å¹³å¹¶æ‹¼æŽ¥ï¼š\n",
    "- å¯¹è¾“å‡ºé€šé“ 0ï¼ˆfilter 0ï¼‰ï¼š\n",
    "$\\begin{array}{c} w^{(0)} =\n",
    "\\begin{bmatrix}\n",
    "a_{11} \\\\ a_{12} \\\\ a_{21} \\\\ a_{22} \\\\\n",
    "b_{11} \\\\ b_{12} \\\\ b_{21} \\\\ b_{22}\n",
    "\\end{bmatrix}^\\top \\end{array}$\tâ€‹\n",
    "- å¯¹è¾“å‡ºé€šé“ 1ï¼ˆfilter 1ï¼‰ï¼š\n",
    "$\\begin{array}{c} w^{(1)} =\n",
    "\\begin{bmatrix}\n",
    "c_{11} \\\\ c_{12} \\\\ c_{21} \\\\ c_{22} \\\\\n",
    "d_{11} \\\\ d_{12} \\\\ d_{21} \\\\ d_{22}\n",
    "\\end{bmatrix}^\\top \\end{array}$\n",
    "\n",
    "- è¿™æ ·ç»„åˆæˆçŸ©é˜µ$W$ï¼š\n",
    "$\\begin{array}{c} W =\n",
    "\\begin{bmatrix}\n",
    "w^{(0)} \\\\\n",
    "w^{(1)}\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{2 \\times 8} \\end{array}$\n",
    "---\n",
    "\n",
    "5. ç»Ÿä¸€æˆä¸€ä¸ªçŸ©é˜µä¹˜æ³•ï¼šY = W X_col\n",
    "çŽ°åœ¨å·ç§¯è¿ç®—å¯ä»¥å†™æˆï¼š$Y = W X_{\\text{col}}$\n",
    "\n",
    "- $W \\in \\mathbb{R}^{C_{\\text{out}} \\times (C_{\\text{in}} k_h k_w)} = \\mathbb{R}^{2 \\times 8}$\n",
    "- $X_{\\text{col}} \\in \\mathbb{R}^{(C_{\\text{in}} k_h k_w) \\times L} = \\mathbb{R}^{8 \\times 4}$\n",
    "- $Y \\in \\mathbb{R}^{C_{\\text{out}} \\times L} = \\mathbb{R}^{2 \\times 4}$\n",
    "å…¶ä¸­ï¼š\n",
    "- ç¬¬ 1 è¡Œå¯¹åº”è¾“å‡ºé€šé“ 0 åœ¨æ‰€æœ‰ 4 ä¸ªç©ºé—´ä½ç½®çš„è¾“å‡º\n",
    "- ç¬¬ 2 è¡Œå¯¹åº”è¾“å‡ºé€šé“ 1\n",
    "- å†æŠŠæ¯ä¸€è¡Œ reshape å›ž 2Ã—2ï¼Œå°±å¾—åˆ°æ ‡å‡†çš„ 2Ã—2 feature mapï¼š$Y^{(c)} \\in \\mathbb{R}^{2 \\times 2},\\quad c=0,1$\n",
    "\n",
    "### 1.5.4 åœ¨æŽ¨ç†åŠ é€Ÿä¸­çš„æ„ä¹‰\n",
    "\n",
    "1. **é‡ç”¨é«˜æ€§èƒ½ GEMM å†…æ ¸**  \n",
    "   - ä¸éœ€è¦ä¸ºæ¯ç§å·ç§¯å½¢çŠ¶å†™å…¨æ–°çš„ kernel  \n",
    "   - åªéœ€å®žçŽ° im2colï¼ˆæˆ–æ›´é«˜çº§çš„å˜æ¢ï¼‰+ è°ƒç”¨ GEMM\n",
    "2. **ç»Ÿä¸€ä¼˜åŒ–ç›®æ ‡**  \n",
    "   - GEMM çš„ tilingã€å‘é‡åŒ–ã€cache åˆ©ç”¨ä¸€æ—¦å†™å¥½ï¼ŒConv ä¹Ÿèƒ½äº«å—\n",
    "3. **æ›´å®¹æ˜“åšé‡åŒ–/å‰ªæž**  \n",
    "   - æƒé‡åœ¨ im2col å½¢å¼ä¸‹å°±æ˜¯ä¸€ä¸ªçŸ©é˜µ Wï¼Œæ–¹ä¾¿ per-channel / per-row é‡åŒ–å’Œå‰ªæž\n",
    "\n",
    "> åœ¨é«˜æ€§èƒ½æŽ¨ç†åº“ä¸­ï¼ŒConv2d çš„å®žçŽ°é€šå¸¸è¦ä¹ˆï¼š  \n",
    "> - èµ° im2col + GEMM è·¯çº¿ï¼Œ  \n",
    "> - è¦ä¹ˆèµ°ä¸“é—¨çš„ convolution kernelï¼Œä½†å…¶å†…éƒ¨ä»ç„¶å›´ç»•â€œå—çŸ©é˜µä¹˜æ³•â€çš„æ€æƒ³è®¾è®¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697c201c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conv shape: torch.Size([1, 3, 4, 4])\n",
      "x_unfold shape: torch.Size([1, 18, 16])\n",
      "y_im2col shape: torch.Size([1, 3, 4, 4])\n",
      "max |y_conv - y_im2col| = 0.0\n",
      "âœ… Conv2d == im2col + matmul (within numerical tolerance)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ======================\n",
    "# 1. å®šä¹‰ä¸€ä¸ªç®€å•çš„ Conv2d\n",
    "# ======================\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "\n",
    "conv = nn.Conv2d(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    padding=padding,\n",
    "    bias=True,\n",
    ")\n",
    "\n",
    "# æž„é€ è¾“å…¥ï¼šbatch_size=1, C=2, H=W=4\n",
    "x = torch.randn(1, in_channels, 4, 4)\n",
    "\n",
    "# ç”¨ nn.Conv2d ç›´æŽ¥ç®—ä¸€éï¼ˆæ ‡å‡†å®žçŽ°ï¼‰\n",
    "y_conv = conv(x)  # å½¢çŠ¶ [1, out_channels, H_out, W_out]\n",
    "print(\"y_conv shape:\", y_conv.shape)\n",
    "\n",
    "# ======================================\n",
    "# 2. ç”¨ im2col + matmul æ‰‹å·¥å®žçŽ°åŒæ ·çš„å·ç§¯\n",
    "# ======================================\n",
    "\n",
    "# unfold ç›¸å½“äºŽ im2colï¼š\n",
    "# x_unfold: [N, C_in * k_h * k_w, L]\n",
    "# å…¶ä¸­ L = H_out * W_out\n",
    "x_unfold = F.unfold(\n",
    "    x,\n",
    "    kernel_size=kernel_size,\n",
    "    dilation=1,\n",
    "    padding=padding,\n",
    "    stride=stride,\n",
    ")\n",
    "# å–ä¸€ä¸‹å±•å¼€åŽçš„å°ºå¯¸\n",
    "N, K, L = x_unfold.shape  # K = C_in * k_h * k_w\n",
    "print(\"x_unfold shape:\", x_unfold.shape)  # [N, K, L]\n",
    "\n",
    "# å·ç§¯æ ¸æƒé‡ï¼š [C_out, C_in, k_h, k_w] -> [C_out, K]\n",
    "W = conv.weight.view(out_channels, -1)  # [C_out, C_in * k_h * k_w]\n",
    "b = conv.bias                           # [C_out]\n",
    "\n",
    "# å¯¹æ¯ä¸ª batch ç‹¬ç«‹åšçŸ©é˜µä¹˜æ³•ï¼š\n",
    "# å¯¹æŸä¸ªæ ·æœ¬ nï¼š\n",
    "#   x_unfold[n]: [K, L]\n",
    "#   è¾“å‡º feature: [C_out, L] = W @ x_unfold[n] + b\n",
    "y_im2col_list = []\n",
    "for n in range(N):\n",
    "    # [C_out, L] = [C_out, K] @ [K, L]\n",
    "    y_n = W @ x_unfold[n]  # [C_out, L]\n",
    "    # åŠ  biasï¼šåœ¨ç¬¬ 0 ç»´ broadcast\n",
    "    y_n = y_n + b.view(-1, 1)  # [C_out, L]\n",
    "    y_im2col_list.append(y_n)\n",
    "\n",
    "# å †å›ž batch ç»´ï¼š [N, C_out, L]\n",
    "y_im2col = torch.stack(y_im2col_list, dim=0)\n",
    "\n",
    "# å°† L å±•å›ž H_out, W_out\n",
    "H_out = y_conv.shape[2]\n",
    "W_out = y_conv.shape[3]\n",
    "y_im2col = y_im2col.view(N, out_channels, H_out, W_out)\n",
    "\n",
    "print(\"y_im2col shape:\", y_im2col.shape)\n",
    "\n",
    "# ============================\n",
    "# 3. å¯¹æ¯” nn.Conv2d ä¸Ž im2col+matmul\n",
    "# ============================\n",
    "\n",
    "diff = (y_conv - y_im2col).abs().max().item()\n",
    "print(\"max |y_conv - y_im2col| =\", diff)\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"âœ… Conv2d == im2col + matmul (within numerical tolerance)\")\n",
    "else:\n",
    "    print(\"âš ï¸ there is a discrepancy between Conv2d and im2col + matmul!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987bac1",
   "metadata": {},
   "source": [
    "## 1.6 Attention çš„çº¿æ€§ä»£æ•°ç»“æž„\n",
    "\n",
    "ä»¥å•å¤´ self-attention ä¸ºä¾‹ï¼ˆä¸è€ƒè™‘ bias & maskï¼‰ï¼š\n",
    "\n",
    "$$\n",
    "Q = X W_Q,\\quad\n",
    "K = X W_K,\\quad\n",
    "V = X W_V \\\\\n",
    "A = \\text{softmax}\\left(\\frac{Q K^\\top}{\\sqrt{d_k}}\\right) \\\\\n",
    "O = A V\n",
    "$$\n",
    "\n",
    "\n",
    "- $X \\in \\mathbb{R}^{T \\times d_{\\text{model}}}$ï¼šè¾“å…¥åºåˆ—\n",
    "- $W_Q, W_K, W_V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$\n",
    "- $Q,K,V \\in \\mathbb{R}^{T \\times d_k}$\n",
    "- $A \\in \\mathbb{R}^{T \\times T}$\n",
    "- $O \\in \\mathbb{R}^{T \\times d_v}$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "1. $Q = X W_Q$ æ˜¯ä¸€ä¸ª GEMMï¼ˆ$T \\times d_{\\text{model}}$ ä¹˜ $d_{\\text{model}} \\times d_k$ï¼‰\n",
    "2. $K = X W_K$ã€$V = X W_V$ åŒç†\n",
    "3. $QK^\\top$ æ˜¯ä¸€ä¸ª **éžå¸¸å¤§çš„ GEMM**ï¼ˆ$T \\times d_k$ ä¹˜ $d_k \\times T$ï¼‰\n",
    "4. $A V$ åˆæ˜¯ä¸€ä¸ª GEMMï¼ˆ$T \\times T$ ä¹˜ $T \\times d_v$ï¼‰\n",
    "- ${d_{\\text{model}}}$: æ¨¡åž‹çš„éšè—ç»´åº¦ï¼Œæ¯ä¸ª token çš„å‘é‡é•¿åº¦ï¼ˆTransformer ä¸»é€šé“ç»´åº¦ï¼‰ã€‚\n",
    "- ${d_k}$: å•ä¸ªæ³¨æ„åŠ›å¤´çš„ Query/Key æŠ•å½±ç»´åº¦ï¼ˆé€šå¸¸ ${d_{\\text{model}}}$ / num_headsï¼‰ã€‚\n",
    "- ${d_v}$: Value æŠ•å½±ç»´åº¦ï¼ˆå¸¸è®¾æˆå’Œ ${d_k}$ ç›¸ç­‰ï¼‰ã€‚\n",
    "- ${T}$: åºåˆ—é•¿åº¦ï¼ˆæ—¶é—´æ­¥æ•°/ token æ•°\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "- Attention ä¸­çœŸæ­£â€œè´µâ€çš„åœ°æ–¹å°±æ˜¯ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•ï¼š$QK^\\top$ å’Œ $A V$\n",
    "- softmax æœ¬èº« FLOPs ä¸å¤šï¼Œä½†å­˜åœ¨æ•°å€¼ç¨³å®šæ€§çš„æŒ‘æˆ˜ï¼ˆç¬¬ 8 ç« å±•å¼€ï¼‰\n",
    "- æ‰€æœ‰å¯¹ Attention çš„åŠ é€Ÿï¼ˆå¦‚ FlashAttentionã€å„ç§ kernel fusionï¼‰æœ¬è´¨éƒ½æ˜¯ï¼š\n",
    "  - å‡å°‘æ˜¾å­˜è¯»å†™\n",
    "  - æ”¹å–„è®¿é—®æ¨¡å¼\n",
    "  - åœ¨ä¸æ˜¾å¼æž„é€  $T \\times T$ çŸ©é˜µçš„å‰æä¸‹ï¼Œå®žçŽ°ç­‰ä»·çš„çº¿æ€§ä»£æ•°è¿ç®—\n",
    "\n",
    "> ä¸€æ—¦ç«™åœ¨â€œçº¿æ€§ä»£æ•°â€è§†è§’çœ‹ Attentionï¼Œå°±æ›´å®¹æ˜“ç†è§£å„ç§åŠ é€Ÿè®ºæ–‡çš„æ€è·¯ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 1.7 Embeddingï¼šæŸ¥è¡¨ = é€‰è¡Œ = ç¨€ç– GEMM\n",
    "\n",
    "Embedding çŸ©é˜µï¼š$E \\in \\mathbb{R}^{V \\times D}$\n",
    "\n",
    "- Vï¼šè¯è¡¨å¤§å°\n",
    "- Dï¼šéšå±‚ç»´åº¦ / embedding ç»´åº¦\n",
    "\n",
    "ç»™å®š token id = iï¼ŒEmbedding çš„ä½œç”¨å°±æ˜¯ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Embedding}(i) = E_i\n",
    "$$\n",
    "\n",
    "\n",
    "å³ï¼š**ä»ŽçŸ©é˜µ E ä¸­é€‰å–ç¬¬ i è¡Œ**ã€‚\n",
    "\n",
    "å¦‚æžœæž„é€ ä¸€ä¸ª one-hot å‘é‡ $x \\in \\mathbb{R}^V$ï¼š\n",
    "\n",
    "$$\n",
    "x_j = \\begin{cases}\n",
    "1, & j = i \\\\\n",
    "0, & \\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "åˆ™ï¼š\n",
    "\n",
    "$$\n",
    "y = x^\\top E = E_i\n",
    "$$\n",
    "\n",
    "\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼š\n",
    "\n",
    "> Embedding åœ¨æ•°å­¦ä¸Šç­‰ä»·äºŽï¼š**one-hot å‘é‡ä¹˜ embedding çŸ©é˜µçš„çŸ©é˜µä¹˜æ³•ï¼ˆä¸€ä¸ªæžå…¶ç¨€ç–çš„ GEMMï¼‰**ã€‚\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- å¯¹ Embedding æ¥è¯´ï¼Œç®—åŠ›ï¼ˆFMAï¼‰å‡ ä¹Žä¸æž„æˆç“¶é¢ˆï¼Œå› ä¸ºæ²¡æœ‰å¤§è§„æ¨¡ä¹˜åŠ \n",
    "- çœŸæ­£çš„ç“¶é¢ˆæ˜¯ï¼š\n",
    "  - å†…å­˜è®¿é—®ï¼ˆéšæœºè®¿é—® E çš„ä¸åŒè¡Œï¼‰\n",
    "  - cache å‘½ä¸­çŽ‡\n",
    "  - å¸¦å®½\n",
    "\n",
    "è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆï¼š  \n",
    "> å·¨å¤§è¯è¡¨çš„ LLMï¼Œåœ¨éƒ¨ç½²æ—¶ç»å¸¸æ˜¯ â€œembedding å’Œ LM head å¾ˆåƒå¸¦å®½â€ï¼›  \n",
    "> è€Œä¸­é—´å±‚ï¼ˆGEMMï¼‰åˆ™æ›´åƒè®¡ç®—ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 1.8 æ•°æ®å¸ƒå±€ï¼ˆMemory Layoutï¼‰ä¸Žçº¿æ€§ä»£æ•°\n",
    "\n",
    "çŸ©é˜µåœ¨å†…å­˜ä¸­å¯ä»¥æœ‰ä¸¤ç§å¸¸è§å¸ƒå±€ï¼š\n",
    "\n",
    "- row-majorï¼ˆè¡Œä¼˜å…ˆï¼ŒC-styleï¼‰\n",
    "- column-majorï¼ˆåˆ—ä¼˜å…ˆï¼ŒFortran/BLAS-styleï¼‰\n",
    "\n",
    "é™„ï¼š\n",
    "BLASï¼ˆBasic Linear Algebra Subprogramsï¼‰æ˜¯å¯†é›†çº¿æ€§ä»£æ•°çš„æ ‡å‡† API è§„èŒƒï¼Œä¸€ç»„åŸºç¡€ç®—å­åº“æŽ¥å£ï¼š\n",
    "\n",
    "- Level 1/2/3ï¼šå‘é‡è¿ç®—ã€çŸ©é˜µâ€‘å‘é‡ã€çŸ©é˜µâ€‘çŸ©é˜µï¼ˆGEMM åœ¨ Level 3ï¼‰ã€‚\n",
    "- ä¸åŒå¹³å°æœ‰ä¸åŒå®žçŽ°ï¼šOpenBLAS/BLISã€MKLã€Apple Accelerateã€cuBLAS ç­‰ï¼Œæä¾›é«˜åº¦ä¼˜åŒ–çš„å†…æ ¸ã€‚\n",
    "\n",
    "å¯¹äºŽ $A \\in \\mathbb{R}^{M \\times K}$ï¼š\n",
    "\n",
    "- row-majorï¼šåŒä¸€è¡Œçš„å…ƒç´ è¿žç»­å­˜æ”¾\n",
    "- column-majorï¼šåŒä¸€åˆ—çš„å…ƒç´ è¿žç»­å­˜æ”¾\n",
    "\n",
    "è¿™ä¼šå½±å“ï¼š\n",
    "\n",
    "- è¿žç»­è®¿é—®çš„æ–¹å‘ï¼ˆstride=1ï¼‰\n",
    "- ç¼“å­˜å±€éƒ¨æ€§ï¼ˆcache localityï¼‰\n",
    "- æ˜¯å¦å®¹æ˜“è¢« SIMD å‘é‡åŒ–\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- å¾ˆå¤š GEMM å†…æ ¸ä¼šè¦æ±‚ A/B/C çŸ©é˜µé‡‡ç”¨ç‰¹å®šå¸ƒå±€ï¼ˆå¦‚ A row-majorï¼ŒB col-majorï¼‰ï¼Œä»¥ä¾¿ï¼š\n",
    "  - åœ¨ inner-k loop ä¸­è¿žç»­è®¿é—®æ•°æ®\n",
    "  - åˆ©ç”¨ç¡¬ä»¶çš„å‘é‡åŠ è½½æŒ‡ä»¤ï¼ˆå¦‚ `ld1q`ã€`vmovaps` ç­‰ï¼‰\n",
    "- è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ åœ¨ kernel ä»£ç ä¸­ä¼šçœ‹åˆ°å¤§é‡ transpose / layout transformï¼Œå®ƒä»¬æœ¬è´¨æ˜¯ä¸ºçº¿æ€§ä»£æ•°è¿ç®—åˆ›å»ºâ€œæ›´å‹å¥½çš„ memory layoutâ€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 1.9 å°ç»“ï¼šçº¿æ€§ä»£æ•°æ˜¯ Runtime Inference çš„å…±åŒè¯­è¨€\n",
    "\n",
    "æœ¬ç« æ ¸å¿ƒç»“è®ºï¼š\n",
    "\n",
    "1. **æŽ¨ç†çš„å¤§éƒ¨åˆ† FLOPs éƒ½æ¥è‡ª GEMMï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰**  \n",
    "   - å…¨è¿žæŽ¥ / MLP / Attention projection / Conv2d (im2col) ç­‰\n",
    "2. **ä½Žç§©è¿‘ä¼¼ï¼ˆSVDï¼‰æ˜¯æœ€é‡è¦çš„åŽ‹ç¼©æ•°å­¦ä¹‹ä¸€**  \n",
    "   - é€šè¿‡ rank-k è¿‘ä¼¼ï¼ŒæŠŠå¤§çŸ©é˜µæ‹†æˆä¸¤ä¸ªå°çŸ©é˜µä¹˜æ³•\n",
    "3. **çŸ©é˜µèŒƒæ•°ç»™å‡ºåº¦é‡åŽ‹ç¼©è¯¯å·®çš„å·¥å…·**  \n",
    "   - Frobeniusã€è°±èŒƒæ•°ã€L1/L0\n",
    "4. **Convã€Attentionã€Embedding éƒ½å¯ä»¥åœ¨â€œçŸ©é˜µè§†è§’â€ä¸‹ç»Ÿä¸€çœ‹å¾…**\n",
    "5. **æ•°æ®å¸ƒå±€ä¸Žçº¿æ€§ä»£æ•°ç´§å¯†ç›¸å…³**  \n",
    "   - Row-major / col-major / tiling å†³å®šæ˜¯å¦èƒ½é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶\n",
    "\n",
    "> æŽ¥ä¸‹æ¥å‡ ç« ä¼šåœ¨è¿™ä¸ªåŸºç¡€ä¸Šï¼Œç»§ç»­å¼•å…¥ï¼š  \n",
    "> - ä¸ºä½•è¿™äº›çŸ©é˜µè¦è¢«â€œä¼˜åŒ–â€ï¼ˆæ•°å€¼ä¼˜åŒ–ç« èŠ‚ï¼‰  \n",
    "> - ä¸ºä½•æˆ‘ä»¬æ•¢äºŽç”¨ç²—ç³™çš„è¿‘ä¼¼ï¼ˆè¿‘ä¼¼ç†è®ºç« èŠ‚ï¼‰  \n",
    "> - å¦‚ä½•åœ¨æ¦‚çŽ‡/ä¿¡æ¯è®ºæ¡†æž¶ä¸‹ç†è§£åŽ‹ç¼©ä¸Žé‡åŒ–  \n",
    "> - å¦‚ä½•ç»“åˆç¡¬ä»¶ç‰¹æ€§çœŸæ­£åšåˆ°â€œè·‘æ»¡â€æŽ¨ç†èŠ¯ç‰‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ba67f",
   "metadata": {
    "id": "143ba67f"
   },
   "source": [
    "# ç¬¬ 2 ç« ï¼šæ•°å€¼ä¼˜åŒ–ï¼ˆOptimization for Pruning, Quantization & Distillationï¼‰\n",
    "\n",
    "æœ¬ç« ç›®æ ‡ï¼šç†è§£å‰ªæžã€é‡åŒ–ã€è’¸é¦ç­‰æ“ä½œèƒŒåŽçš„â€œä¼˜åŒ–é—®é¢˜â€è§†è§’ã€‚  \n",
    "ä½ ä¸éœ€è¦æˆä¸ºä¼˜åŒ–ç†è®ºä¸“å®¶ï¼Œä½†éœ€è¦ï¼š\n",
    "\n",
    "- çœ‹æ‡‚å¸¸è§æŸå¤±å‡½æ•°ä¸Žæ­£åˆ™é¡¹çš„å½¢å¼\n",
    "- ç†è§£ L0/L1 ç¨€ç–åŒ–ã€é‡åŒ–å‚æ•°ä¼˜åŒ–çš„å¤§è‡´æ€è·¯\n",
    "- çŸ¥é“å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆç²¾åº¦ vs å»¶è¿Ÿï¼‰çš„å…¸åž‹å†™æ³•\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 å‰ªæžï¼ˆPruningï¼‰çš„ä¼˜åŒ–è§†è§’\n",
    "\n",
    "### 2.1.1 åŸºæœ¬ç›®æ ‡\n",
    "\n",
    "ç»™å®šè®­ç»ƒå¥½çš„æƒé‡ $W$ã€æŸå¤±å‡½æ•° $L(W)$ï¼Œå‰ªæžå¸Œæœ›ï¼š\n",
    "\n",
    "- å¤§é‡å…ƒç´ å˜ä¸º 0ï¼ˆç¨€ç–ï¼‰\n",
    "- æŸå¤±/ç²¾åº¦å˜åŒ–å°½é‡å°\n",
    "\n",
    "å¯ä»¥å½¢å¼åŒ–ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\hat{W}} L(\\hat{W}) + \\lambda \\|\\hat{W}\\|_0\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- è¿™é‡Œ $L$ æ˜¯æ¨¡åž‹çš„æŸå¤±å‡½æ•°ï¼ˆè®­ç»ƒæ—¶ç”¨çš„ç›®æ ‡å‡½æ•°ï¼‰ï¼Œåœ¨æƒé‡ä¸º $\\hat{W}$ æ—¶çš„æŸå¤±å€¼\n",
    "- $\\|\\hat{W}\\|_0$ï¼šéžé›¶å…ƒç´ ä¸ªæ•°ï¼ˆç¨€ç–æ€§åº¦é‡ï¼‰\n",
    "- $\\lambda$ï¼šæƒè¡¡â€œç²¾åº¦ vs ç¨€ç–åº¦â€çš„è¶…å‚æ•°\n",
    "\n",
    "è¿™ä¸ªé—®é¢˜ä¸€èˆ¬æ˜¯ NP-hardï¼Œå¸¸è§è¿‘ä¼¼æ–¹å¼æœ‰ï¼š\n",
    "\n",
    "1. ç”¨ $L_1$ èŒƒæ•°æ›¿ä»£ $L_0$ï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\hat{W}} L(\\hat{W}) + \\lambda \\|\\hat{W}\\|_1\n",
    "$$\n",
    "\n",
    "\n",
    "2. å…ˆæ­£å¸¸è®­ç»ƒï¼Œå†åšåŸºäºŽæŸç§ saliency çš„åŽå¤„ç†å‰ªæžï¼š\n",
    "   - æŒ‰æƒé‡ç»å¯¹å€¼å¤§å°å‰ªæŽ‰å°å€¼\n",
    "   - æŒ‰ Hessian è¿‘ä¼¼ï¼ˆå¦‚ OBS/OBDï¼‰è®¡ç®—æ•æ„Ÿåº¦\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.2  HessiançŸ©é˜µ & saliency score\n",
    "åŽè®­ç»ƒå‰ªæžï¼ˆpost-training pruningï¼‰æ ¸å¿ƒæ˜¯\n",
    "\n",
    "- è¿™æ¡è¾¹ï¼ˆæŸä¸ª weightï¼‰åˆ æŽ‰ä¼šä¸ä¼šä¼¤å®³ lossï¼Ÿ\n",
    "\n",
    "- å“ªä¸ªé€šé“æ›´é‡è¦ï¼Ÿ\n",
    "\n",
    "- å“ªå±‚è¯¥å¤šå‰ªï¼Ÿå“ªå±‚ä¸èƒ½ä¹±åŠ¨ï¼Ÿj z\n",
    "\n",
    "ðŸ”· 1. ä»€ä¹ˆæ˜¯ Hessianï¼Ÿ\n",
    "Hessian æ˜¯ loss å¯¹å‚æ•°çš„äºŒé˜¶å¯¼æ•°çŸ©é˜µï¼š\n",
    "$$H = \\nabla^2_{W} L(W)$$\n",
    "æ›´ç²¾ç¡®åœ°ï¼š\n",
    "- å¦‚æžœæ¨¡åž‹å‚æ•°æ˜¯$$W \\in \\mathbb{R}^n$$ï¼Œ åˆ™ Hessian æ˜¯ï¼š$$H \\in \\mathbb{R}^{n \\times n}$$\n",
    "å…¶ä¸­æ¯ä¸ªå…ƒç´ ï¼š $$H_{ij} = \\frac{\\partial^2 L}{\\partial W_i \\partial W_j}$$\n",
    "ä»£è¡¨ loss å¯¹ä¸¤ä¸ª weight çš„äºŒé˜¶ç›¸äº’å½±å“ã€‚\n",
    "\n",
    "ðŸ”· 2. ä¸ºä»€ä¹ˆ Hessian ä¸Žå‰ªæžæœ‰å…³ï¼Ÿ\n",
    "\n",
    "é—®é¢˜ï¼š\n",
    "å¦‚æžœæŠŠæŸä¸ª weightä»Ž $w_i$->0, loss ä¼šå˜å¤šå°‘ï¼Ÿ\n",
    "å¦‚æžœä½ ç›´æŽ¥çœ‹$|w_i|$,åªèƒ½çŸ¥é“å®ƒâ€œå¤§å°â€ï¼Œä¸çŸ¥é“ï¼š\n",
    "- è¿™ä¸ªæƒé‡å¯¹ loss çš„æ•æ„Ÿåº¦å¦‚ä½•\n",
    "\n",
    "- æ¢å¥è¯è¯´ï¼Œå®ƒæ˜¯ä¸æ˜¯â€œå…³é”®è·¯å¾„â€ä¸Šçš„é‡è¦å‚æ•°ï¼Ÿ\n",
    "\n",
    "ç®€å•ç»å¯¹å€¼æ˜¯**ç²—ç³™ä»£ç†**ã€‚Hessian åˆ™è¡¡é‡äº†ï¼š**æ”¹å˜ä¸€ä¸ªæƒé‡ï¼Œä¼šè®© loss å¢žå¤§å¤šå°‘**, æ›´ç²¾ç¡®ã€‚\n",
    "\n",
    "ðŸ”¥ 3. ç”¨äºŒé˜¶æ³°å‹’å±•å¼€ä¼°è®¡â€œå‰ªæŽ‰æŸä¸ª weight ä¼šå¸¦æ¥å¤šå°‘æŸå¤±å¢žåŠ â€ï¼Ÿ\n",
    "å‡è®¾æˆ‘ä»¬è¦æŠŠç¬¬$i$ä¸ª weightä»Žå½“å‰$w_i$è®¾ç½®æˆ 0ï¼š\n",
    "$$\\Delta w_i = -w_i$$\n",
    "loss çš„å˜åŒ–ï¼ˆç”¨äºŒé˜¶æ³°å‹’å±•å¼€ï¼‰ï¼š\n",
    "$$\\Delta L \\approx \n",
    "\\frac{\\partial L}{\\partial w_i}\\Delta w_i + \\frac{1}{2} H_{ii} (\\Delta w_i)^2$$\n",
    "ä½†ï¼š\n",
    "- åœ¨è®­ç»ƒå®Œçš„ç‚¹, æ¢¯åº¦$\\partial L/\\partial w_i \\approx 0$ï¼ˆå› ä¸ºè®­ç»ƒæ”¶æ•›ï¼‰\n",
    "- æ‰€ä»¥å‰©ä¸‹ï¼š$$\\Delta L \\approx \\frac{1}{2} H_{ii} w_i^2$$\n",
    "\n",
    "è‡³æ­¤ **saliency score** = $H_{ii} w_i^2$\n",
    "è¿™æ¯”å•çœ‹$|w_i|$æ›´æœ‰æ„ä¹‰\n",
    "\n",
    "ðŸ”· ç›´è§‰çš„è§£é‡Š\n",
    "- æ³°å‹’å±•å¼€è¯´ï¼š\n",
    "â€œåœ¨ä¸€ä¸ªç‚¹é™„è¿‘ï¼Œå‡½æ•°çš„å˜åŒ– â‰ˆ ä¸€é˜¶ï¼ˆæ–œçŽ‡ï¼‰ + äºŒé˜¶ï¼ˆå¼¯æ›²ç¨‹åº¦ï¼‰ã€‚â€\n",
    "\n",
    "- åœ¨å·²ç»è®­ç»ƒå¥½çš„ç‚¹ï¼š\n",
    "ä¸€é˜¶å¯¼ï¼ˆæ–œçŽ‡ï¼‰æŽ¥è¿‘ 0ï¼Œæ‰€ä»¥å˜åŒ–ä¸»è¦é äºŒé˜¶å¯¼å†³å®šã€‚\n",
    "\n",
    "- å¯¹äºŽå‰ªæžï¼š\n",
    "ä½ æŠŠ$w_i$æ”¹æˆ 0ï¼Œç›¸å½“äºŽåœ¨å‚æ•°ç©ºé—´é‡Œæ²¿ç€ç¬¬ i ä¸ªåæ ‡æ–¹å‘ï¼Œèµ°äº†ä¸€ä¸ªæ­¥é•¿ $-w_i$\n",
    "æŸå¤±å¢žåŠ  â‰ˆ å¼¯æ›²ç¨‹åº¦ Ã— ä½ èµ°çš„è·ç¦»çš„å¹³æ–¹ã€‚\n",
    "\tâ€‹\n",
    "- â€œå¼¯æ›²ç¨‹åº¦â€åœ¨è¿™ä¸ªæ–¹å‘å°±æ˜¯ Hessian çš„å¯¹è§’çº¿å…ƒç´  $H_{ii}$\n",
    " - å¦‚æžœè¿™ä¸ªæ–¹å‘ä¸Šå¼¯å¾—å¾ˆåŽ‰å®³ï¼ˆH å¤§ï¼‰ï¼Œè¯´æ˜Žå¯¹è¿™ä¸ªå‚æ•°å¾ˆæ•æ„Ÿï¼Œä¸èƒ½ä¹±å‰ªã€‚\n",
    " - å¦‚æžœè¿™ä¸ªæ–¹å‘å‡ ä¹Žæ˜¯å¹³çš„ï¼ˆH å°ï¼‰ï¼Œå³ä½¿ $w_i$ä¸ä¸ºé›¶ï¼Œä¹Ÿå¯ä»¥å¤§èƒ†å‰ª\n",
    "\n",
    "æ‰€ä»¥ï¼š\n",
    "- åªçœ‹$|w_i|$ â†’ åªæ˜¯çœ‹è¿™ä¸ªå‚æ•°â€œå¤§ä¸å¤§â€ã€‚\n",
    "- çœ‹$H_{ii} w_i^2$ â†’ çœ‹â€œåˆ æŽ‰å®ƒé€ æˆ loss ä¸Šå‡æœ‰å¤šå¤§â€ï¼Œè¿™æ˜¯æ›´åˆç†çš„â€œé‡è¦æ€§â€åº¦é‡ã€‚\n",
    "\n",
    "ðŸ”· 4. OBSï¼ˆOptimal Brain Surgeonï¼‰ä¸Ž OBDï¼ˆOptimal Brain Damageï¼‰\n",
    "è¿™æ˜¯ 1990 å¹´ä»£çš„ç»å…¸å‰ªæžæ–¹æ³•ï¼š\n",
    "\n",
    "ðŸŸ¦ OBDï¼ˆOptimal Brain Damageï¼‰\n",
    "\n",
    "å®ƒä½¿ç”¨å¯¹è§’ Hessianï¼š\n",
    "$$\\text{saliency}_i = \\frac{1}{2} H_{ii} w_i^2$$\n",
    "ç›´è§‰ï¼š\n",
    "* å¦‚æžœ $H_{ii}$å¾ˆå¤§ â†’ è¯¥weight éžå¸¸æ•æ„Ÿ\n",
    "* å°±ç®—å®ƒå¾ˆå°ï¼Œä¹Ÿä¸èƒ½è½»æ˜“åˆ \n",
    "* å¦‚æžœ $H_{ii}$ å¾ˆå° â†’ è¿™ä¸ª weight ä¸é‡è¦\n",
    "* å¯ä»¥å®‰å…¨å‰ªæŽ‰\n",
    "\n",
    "ç¼ºç‚¹ï¼šå¿½ç•¥ Hessian çš„ off-diagonalï¼ˆè·¨ weight ç›¸å…³æ€§ï¼‰ã€‚\n",
    "\n",
    "ðŸŸ© OBSï¼ˆOptimal Brain Surgeonï¼‰\n",
    "OBS æ›´ç²¾ç¡®ï¼š\n",
    "$$\\text{saliency}_i = \n",
    "\\frac{1}{2} \\frac{w_i^2}{(H^{-1})_{ii}}$$\n",
    "\n",
    "OBS ä½¿ç”¨é€† Hessianï¼Œè€ƒè™‘æ‰€æœ‰ weight ä¹‹é—´çš„ç›¸äº’å½±å“ï¼Œç†è®ºä¸Šæ›´å‡†ç¡®ï¼š\n",
    "\n",
    "- å¦‚æžœ weight èƒ½è¢«å…¶ä»–å‚æ•°è¡¥å¿ï¼ˆHessian inverse åæ˜ ç›¸å…³æ€§ï¼‰ï¼Œå®ƒæ›´é€‚åˆåˆ \n",
    "- ä½†è®¡ç®— Hessian inverse å¤ªè´µï¼ŒçŽ°ä»£å¾ˆå°‘ç”¨å…¨é‡ OBSã€‚\n",
    "\n",
    "ðŸ”¥ 5. å·¥ç¨‹åšæ³•ï¼ˆPruning-aware methodsï¼‰\n",
    "çœŸå®žå·¥ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸å¯èƒ½ç®—çœŸæ­£çš„ Hessianï¼ˆå¤ªå¤§ï¼‰ï¼Œä½†å¯ä»¥ï¼š\n",
    "\n",
    "âœ” è¿‘ä¼¼å¯¹è§’çº¿ï¼š\n",
    "- ç”¨ Fisher ä¿¡æ¯çŸ©é˜µå¯¹è§’çº¿\n",
    "- ç”¨ Hutchinson estimator\n",
    "- ç”¨æ¢¯åº¦å¹³æ–¹çš„ moving average , ç±»ä¼¼ Adam çš„ $v_t$ ï¼Œè¿™å°±æŠŠ Hessian ä¼°è®¡å˜æˆå¯è®­ç»ƒã€å¯éƒ¨ç½²çš„ä¸œè¥¿ã€‚\n",
    "æ­¤å¤„\n",
    "$H_{ii} \\approx \\mathbb{E}[g_i^2]$ï¼Œ \n",
    "\n",
    "$g_i = \\frac{\\partial L}{\\partial w_i}$\n",
    "è¿™ä¸ªæ¢¯åº¦éšç€ batch è€Œå˜åŒ–ï¼Œå› ä¸º loss æ˜¯åŸºäºŽ mini-batch æ±‚å‡ºæ¥çš„ï¼Œæ‰€ä»¥é€šå¸¸ç”¨ï¼š\n",
    "$$\\mathbb{E}[g_i^2] = \\text{over minibatches }$$\n",
    "æ¢å¥è¯è¯´ï¼š\n",
    "\n",
    "- æ¯ä¸ª batch ä¼šç®—ä¸€æ¬¡æ¢¯åº¦ $g = \\nabla L$\n",
    "- å–å®ƒçš„å¹³æ–¹ $g_i^2$\n",
    "- å†å¯¹ batch æ±‚æœŸæœ›ï¼ˆå¹³å‡ï¼‰\n",
    "\n",
    "å°±å¾—åˆ°äº†å¯¹è§’çº¿ Hessian çš„ä¼°è®¡ã€‚\n",
    "\n",
    "ðŸ“Œ ä¸ºä»€ä¹ˆæ¢¯åº¦å¹³æ–¹å¯ä»¥è¿‘ä¼¼ Hessian å¯¹è§’çº¿ï¼Ÿ\n",
    "åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ **Cross-Entropy loss + Softmax** çš„æ¨¡åž‹ï¼Œï¼ˆå…¶ä»–çš„ä¸ä¸€å®šå¯¹ï¼Œæ¯”å¦‚MSEï¼ˆå¹³æ–¹è¯¯å·®å›žå½’ï¼‰ï¼‰é‡Œï¼š\n",
    "$$H_{ii} \\approx \\mathbb{E}[g_i^2]$$\n",
    "åŽŸå› æ˜¯ï¼š\n",
    "1. Hessian = äºŒé˜¶å˜åŒ–çŽ‡ï¼›Fisher ä¿¡æ¯ = æ¢¯åº¦æ–¹å·®\n",
    "å¯¹æ•°ä¼¼ç„¶æ¡ä»¶ä¸‹ï¼Œæœ‰æ•°å­¦å®šç†ï¼ˆCramerâ€“Rao + Information Equalityï¼‰ï¼š\n",
    "$$\\mathbb{E}[ \\nabla^2 L ] = \\mathbb{E}[ g g^\\top ]$$\n",
    "å–å¯¹è§’çº¿ï¼š\n",
    "$$H_{ii} \\approx \\mathbb{E}[g_i^2]$$\n",
    "æ¢å¥è¯è¯´ï¼š\n",
    "**æ¢¯åº¦çš„æ–¹å·® = äºŒé˜¶æ›²çŽ‡ï¼ˆHessian å¯¹è§’çº¿**\n",
    "\n",
    "ðŸ“Œ å·¥ç¨‹ä¸Šå¦‚ä½•è®¡ç®—$E[g_i^2]$?\n",
    "```code\n",
    "hessian_diag[i] += grad[i]**2\n",
    "count += 1\n",
    "...\n",
    "hessian_diag /= count\n",
    "```\n",
    "è¿™å°±æ˜¯ Hessian å¯¹è§’çº¿çš„æ— åä¼°è®¡ã€‚\n",
    "\n",
    "ðŸ“Œ ç›´è§‰çš„è§£é‡Š\n",
    "- æ¢¯åº¦æ˜¯â€œæŸå¤±å¯¹å‚æ•°çš„ä¸€é˜¶ååº”â€\n",
    "\n",
    "- æ¢¯åº¦å¹³æ–¹çš„æœŸæœ›å°±æ˜¯â€œæŸå¤±åœ¨è¿™ä¸ªæ–¹å‘ä¸Šçš„æ³¢åŠ¨å¼ºåº¦â€\n",
    "\n",
    "- æ³¢åŠ¨å¼ºè¯´æ˜Žâ€œè¿™ä¸ªæ–¹å‘ä¸Š loss å¾ˆé™¡â€ â†’ Hessian å¤§\n",
    "\n",
    "- æ³¢åŠ¨å¼±è¯´æ˜Žâ€œè¿™ä¸ªæ–¹å‘å¹³ç¼“â€ â†’ Hessian å°\n",
    "æ‰€ä»¥ï¼š\n",
    "$H_{ii} \\approx E[g_i^2]$\n",
    "---\n",
    "\n",
    "#### 2.1.2.1 äºŒé˜¶æ³°å‹’å±•å¼€è¯¦ç»†æŽ¨å¯¼\n",
    "çŽ°åœ¨å‚æ•°æ˜¯å‘é‡ï¼š $W = (w_1, w_2, \\dots, w_n)^\\top$\n",
    "loss æ˜¯ $L(W)$\n",
    "åœ¨ç‚¹ ð‘Š é™„è¿‘åšäºŒé˜¶æ³°å‹’å±•å¼€ï¼š\n",
    "$$L(W + \\Delta W)\n",
    "\\approx\n",
    "L(W)\n",
    "+ \\nabla L(W)^\\top \\Delta W\n",
    "+ \\frac{1}{2} \\Delta W^\\top H \\Delta W$$\n",
    "\n",
    "è¿™é‡Œï¼š\n",
    "- $\\nabla L(W)$æ˜¯æ¢¯åº¦å‘é‡ï¼ˆé•¿åº¦ nï¼‰\n",
    "- $H = \\nabla^2 L(W)$ æ˜¯ Hessian çŸ©é˜µï¼ˆnÃ—n\n",
    "\n",
    "çŽ°åœ¨ **æˆ‘ä»¬åªåŠ¨ç¬¬ i ä¸ªå‚æ•°ï¼ŒæŠŠå®ƒå˜æˆ 0**\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼š\n",
    "- åŽŸæ¥ï¼š$w_i$\n",
    "- å‰ªæžåŽï¼š$w_i^{\\text{new}} = 0$\n",
    "æ‰€ä»¥ï¼š\n",
    "$$\\Delta W = W_{\\text{new}} - W_{\\text{old}}\n",
    "= (0,\\dots,0, -w_i, 0,\\dots,0)^\\top\n",
    "= -w_i e_i$$\n",
    "\n",
    "ä»£å…¥æ³°å‹’å±•å¼€å…¬å¼\n",
    "$$\\Delta L\n",
    "= L(W + \\Delta W) - L(W)\n",
    "\\approx \\nabla L(W)^\\top \\Delta W + \\frac{1}{2} \\Delta W^\\top H \\Delta W$$\n",
    "\n",
    "æ¢¯åº¦å‘é‡ï¼š\n",
    "$\\begin{array}{c} \\nabla L(W) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial L}{\\partial w_1} \\\\\n",
    "\\frac{\\partial L}{\\partial w_2} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial w_n}\n",
    "\\end{bmatrix} \\end{array}$\n",
    "\n",
    "\n",
    "æŠŠ $\\Delta W = -w_i e_i$ä»£è¿›åŽ»ï¼š\n",
    "- ä¸€é˜¶é¡¹ï¼š\n",
    "$$\\nabla L(W)^\\top \\Delta W\n",
    "= \\nabla L(W)^\\top (-w_i e_i)\n",
    "= -w_i \\frac{\\partial L}{\\partial w_i}$$\n",
    "\n",
    "- äºŒé˜¶é¡¹\n",
    "$$\\Delta W^\\top H \\Delta W\n",
    "= (-w_i e_i)^\\top H (-w_i e_i)\n",
    "= w_i^2 \\, e_i^\\top H e_i$$\n",
    "ä½†ï¼š\n",
    "$$e_i^\\top H e_i = H_{ii}$$\n",
    "æ‰€ä»¥ï¼š\n",
    "$$\\Delta W^\\top H \\Delta W = w_i^2 H_{ii}$$\n",
    "äºŽæ˜¯ï¼š\n",
    "$$\\Delta L \\approx -w_i \\frac{\\partial L}{\\partial w_i}\n",
    "+ \\frac{1}{2} w_i^2 H_{ii}$$\n",
    "\n",
    "**å†æ¬¡ä½¿ç”¨â€œåœ¨æ”¶æ•›ç‚¹æ¢¯åº¦ â‰ˆ 0â€**, åœ¨è®­ç»ƒå¥½çš„å‚æ•°$W^\\star$é™„è¿‘ï¼š\n",
    "$$\\frac{\\partial L}{\\partial w_i}(W^\\star) \\approx 0$$\n",
    "äºŽæ˜¯ï¼š\n",
    "$$\\Delta L \\approx \\frac{1}{2} H_{ii} w_i^2$$\n",
    "è¿™å°±æ˜¯**OBDï¼ˆOptimal Brain Damageï¼‰ä¸­çš„ saliency**: $\\text{saliency}_i = \\frac{1}{2} H_{ii} w_i^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0471f81",
   "metadata": {},
   "source": [
    "#### 2.1.2.2 pytorch CrossEntropy ä¸‹çš„ Hessian å¯¹è§’çº¿ vs E[gÂ²]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28d6de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained loss: 0.33923059701919556\n",
      "Trained theta: [ 1.3182789 -1.9975102  0.4114626]\n",
      "\n",
      "True Hessian diagonal H_ii:\n",
      "tensor([0.0965, 0.0759, 0.1324])\n",
      "\n",
      "Estimated Hessian diagonal via E[g^2]:\n",
      "tensor([0.0015, 0.0012, 0.0014])\n",
      "\n",
      "Absolute diff |H_ii - E[g_i^2]|:\n",
      "tensor([0.0949, 0.0747, 0.1310])\n",
      "\n",
      "Relative diff |H_ii - E[g_i^2]| / |H_ii|:\n",
      "tensor([0.9839, 0.9840, 0.9891])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import hessian\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ===========================\n",
    "# 1. æž„é€ ä¸€ä¸ªå°çš„ logistic å›žå½’æ¨¡åž‹\n",
    "#    y âˆˆ {0,1}, p = sigmoid(xW + b)\n",
    "# ===========================\n",
    "\n",
    "in_dim = 2\n",
    "\n",
    "N = 500\n",
    "X = torch.randn(N, in_dim)\n",
    "\n",
    "# çœŸå®žå‚æ•°ï¼ˆåªç”¨äºŽç”Ÿæˆæ•°æ®ï¼‰\n",
    "true_theta = torch.tensor([2.0, -3.0, 0.5])  # [w1, w2, b]\n",
    "true_W = true_theta[:in_dim].view(in_dim, 1) # [2,1]\n",
    "true_b = true_theta[in_dim:].view(1)         # [1]\n",
    "\n",
    "logits = X @ true_W + true_b            # [N,1]\n",
    "probs = torch.sigmoid(logits)           # [N,1]\n",
    "y = torch.bernoulli(probs).view(-1).long()  # è½¬æˆ int labels [N]\n",
    "\n",
    "# æˆ‘ä»¬åŒæ ·ç”¨ä¸€ç»´å‚æ•°å‘é‡ theta = [w1, w2, b] æ¥ä¼˜åŒ–\n",
    "theta = torch.randn(in_dim + 1, requires_grad=True)\n",
    "\n",
    "def unpack_theta(th):\n",
    "    W = th[:in_dim].view(in_dim, 1)   # [2,1]\n",
    "    b = th[in_dim:].view(1)           # [1]\n",
    "    return W, b\n",
    "\n",
    "def loss_fn(theta, X, y):\n",
    "    W, b = unpack_theta(theta)        # W: [2,1], b: [1]\n",
    "    logits = X @ W + b                # [N,1]\n",
    "    logits = logits.view(-1, 1)\n",
    "    # Binary cross entropy with logits\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, y.float().view(-1, 1))\n",
    "    return loss\n",
    "\n",
    "# ç®€å•è®­ç»ƒä¸€ä¸‹ï¼Œè®© theta æŽ¥è¿‘â€œæ”¶æ•›ç‚¹â€\n",
    "optim = torch.optim.SGD([theta], lr=0.1)\n",
    "\n",
    "for step in range(300):\n",
    "    optim.zero_grad()\n",
    "    loss = loss_fn(theta, X, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(\"Trained loss:\", loss_fn(theta, X, y).item())\n",
    "print(\"Trained theta:\", theta.detach().numpy())\n",
    "\n",
    "# ==========================================\n",
    "# 2. è®¡ç®—â€œçœŸÂ·Hessian å¯¹è§’çº¿â€ï¼šH_ii\n",
    "# ==========================================\n",
    "\n",
    "def loss_only_theta(th):\n",
    "    return loss_fn(th, X, y)\n",
    "\n",
    "H = hessian(loss_only_theta, theta)   # [P,P], P = in_dim+1=3\n",
    "H_diag_true = torch.diag(H).detach()\n",
    "\n",
    "print(\"\\nTrue Hessian diagonal H_ii:\")\n",
    "print(H_diag_true)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ç”¨å¤š batch çš„æ¢¯åº¦å¹³æ–¹å¹³å‡ E[g^2] è¿‘ä¼¼ H_ii\n",
    "# ==========================================\n",
    "\n",
    "num_batches = 100\n",
    "batch_size = 64\n",
    "\n",
    "g2_accum = torch.zeros_like(theta)\n",
    "\n",
    "for _ in range(num_batches):\n",
    "    idx = torch.randint(0, N, (batch_size,))\n",
    "    Xb = X[idx]\n",
    "    yb = y[idx]\n",
    "\n",
    "    loss_b = loss_fn(theta, Xb, yb)\n",
    "    grad_theta = torch.autograd.grad(loss_b, theta, retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "    g2_accum += grad_theta.detach() ** 2\n",
    "\n",
    "H_diag_est = g2_accum / num_batches\n",
    "\n",
    "print(\"\\nEstimated Hessian diagonal via E[g^2]:\")\n",
    "print(H_diag_est)\n",
    "\n",
    "# ==========================================\n",
    "# 4. å¯¹æ¯”ä¸¤è€…\n",
    "# ==========================================\n",
    "\n",
    "abs_diff = (H_diag_true - H_diag_est).abs()\n",
    "rel_diff = abs_diff / (H_diag_true.abs() + 1e-8)\n",
    "\n",
    "print(\"\\nAbsolute diff |H_ii - E[g_i^2]|:\")\n",
    "print(abs_diff)\n",
    "\n",
    "print(\"\\nRelative diff |H_ii - E[g_i^2]| / |H_ii|:\")\n",
    "print(rel_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e84fb8",
   "metadata": {},
   "source": [
    "### 2.1.3 è¡¥ï¼šFisher ä¿¡æ¯çŸ©é˜µ\n",
    "Fisher ä¿¡æ¯çŸ©é˜µï¼ˆFisher Information Matrix, FIMï¼‰ è¡¡é‡çš„æ˜¯ï¼š\n",
    "\n",
    "æ¨¡åž‹å¯¹å‚æ•°å˜åŒ–çš„æ•æ„Ÿåº¦\n",
    "\n",
    "æˆ–\n",
    "\n",
    "ç”¨å‚æ•°åŽ»è§£é‡Šæ•°æ®æ—¶ï¼Œä¸ç¡®å®šæ€§æœ‰å¤šå°\n",
    "\n",
    "â€œä¿¡æ¯è¶Šå¤§ â†’ å‚æ•°è¶Šé‡è¦ï¼Œä¸èƒ½åŠ¨â€\n",
    "â€œä¿¡æ¯è¶Šå° â†’ å‚æ•°ä¸é‡è¦ï¼Œå¯ä»¥å‰ª / é‡åŒ–å¾—æ›´æ¿€è¿›â€\n",
    "\n",
    "---\n",
    "1. Fisher ä¿¡æ¯çŸ©é˜µçš„æ­£å¼å®šä¹‰\n",
    "ç»™å®šæ¨¡åž‹çš„å¯¹æ•°ä¼¼ç„¶ï¼ˆlog-likelihoodï¼‰ï¼š$\\log p_\\theta(x)$\n",
    "\n",
    "Fisher ä¿¡æ¯çŸ©é˜µå®šä¹‰ä¸ºï¼š\n",
    "$$F(\\theta) = \\mathbb{E}\\left[ \\left( \\nabla_\\theta \\log p_\\theta(x) \\right)\n",
    "       \\left( \\nabla_\\theta \\log p_\\theta(x) \\right)^\\top \\right]$$\n",
    "\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼š\n",
    "\n",
    "- å…ˆå¯¹ log-likelihood æ±‚æ¢¯åº¦ï¼ˆscore functionï¼‰\n",
    "\n",
    "- å†æ±‚å®ƒä¸Žè‡ªèº«çš„å¤–ç§¯\n",
    "\n",
    "- å†åœ¨æ•°æ®åˆ†å¸ƒä¸Šå–æœŸæœ›\n",
    "\n",
    "---\n",
    "2. æ·±åº¦å­¦ä¹ é‡Œæ›´å¸¸ç”¨çš„è¡¨è¾¾\n",
    "å½“æˆ‘ä»¬ç”¨ CrossEntropy Loss æ—¶ï¼š\n",
    "$$L(\\theta) = -\\log p_\\theta(y|x)$$\n",
    "æ¢¯åº¦å°±æ˜¯ï¼š\n",
    "$$g = \\nabla_\\theta L = - \\nabla_\\theta \\log p_\\theta(y|x)$$\n",
    "äºŽæ˜¯ Fisher ä¿¡æ¯çŸ©é˜µç­‰ä»·äºŽï¼š\n",
    "$$F(\\theta) = \\mathbb{E}[g\\, g^\\top]$$\n",
    "\n",
    "å¯¹è§’çº¿å°±æ˜¯ï¼š\n",
    "$$F_{ii} = \\mathbb{E}[g_i^2]$$\n",
    "ä¹Ÿå°±æ˜¯\n",
    "$$H_{ii} \\approx \\mathbb{E}[g_i^2]$$\n",
    "\n",
    "---\n",
    "3. ä¸ºä»€ä¹ˆ Fisher ä¿¡æ¯çŸ©é˜µåœ¨æ·±åº¦å­¦ä¹ ä¸­å¾ˆé‡è¦ï¼Ÿ\n",
    "Fisher ä¿¡æ¯å‘Šè¯‰æˆ‘ä»¬ï¼š\n",
    "\n",
    "å¦‚æžœå‚æ•° Î¸ å‘ç”Ÿå¾®å°å˜åŒ–ï¼Œæ¨¡åž‹é¢„æµ‹ä¼šæœ‰å¤šå¤§æ³¢åŠ¨ï¼Ÿ\n",
    "\n",
    "æ¢å¥è¯è¯´ï¼š\n",
    "- $F_{ii}$ å¤§ â†’ å‚æ•°éžå¸¸â€œæ•æ„Ÿâ€ â†’ å¾ˆé‡è¦ â†’ ä¸å®œå‰ª\n",
    "- $F_{ii}$å° â†’ å‚æ•°åŸºæœ¬ä¸èµ·ä½œç”¨ â†’ å¯ä»¥å‰ª / å¯ä»¥ä½Ž bit é‡åŒ– \n",
    "\n",
    "æ‰€ä»¥ï¼š\n",
    "\n",
    "âœ” Fisher ä¿¡æ¯å¯ç”¨äºŽå‰ªæžï¼ˆpruning saliencyï¼‰\n",
    "\n",
    "âœ” å¯ç”¨äºŽé‡åŒ–ï¼ˆquantization sensitivityï¼‰\n",
    "\n",
    "âœ” å¯ç”¨äºŽç¡®å®šå“ªäº›å±‚çš„ rank è¦ä¸‹è°ƒï¼ˆlow-rank SVDï¼‰\n",
    "\n",
    "âœ” å¯ç”¨äºŽ LayerNorm / Whitening çš„ç¨³å®šæ€§åˆ†æž\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103a11ca",
   "metadata": {},
   "source": [
    "### 2.1.4 ç»“æž„åŒ–å‰ªæžï¼ˆchannel/head pruningï¼‰\n",
    "\n",
    "å¯ä»¥æŠŠé€šé“å‰ªæžå†™æˆï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\theta, m} \\ L(\\theta \\odot m) + \\lambda \\|m\\|_0\n",
    "$$\n",
    "\n",
    "\n",
    "- $\\theta$ï¼šåŽŸå§‹å‚æ•°\n",
    "- $m$ï¼šmaskï¼ŒæŒ‰é€šé“/å—ä¸ºå•ä½å– 0 æˆ– 1\n",
    "- $\\odot$ï¼šé€å…ƒç´ æˆ–é€é€šé“ä¹˜æ³•\n",
    "\n",
    "é€šå¸¸ä¼šï¼š\n",
    "\n",
    "1. è®­ç»ƒä¸€ä¸ªå¸¦æœ‰å¯å¾®è¿‘ä¼¼ mask çš„æ¨¡åž‹ï¼ˆå¦‚ç”¨ sigmoid/Concrete distributionï¼‰\n",
    "2. åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸åŽ‹ç¼©æŸäº›é€šé“çš„æƒé‡\n",
    "3. æœ€åŽå°†æŽ¥è¿‘ 0 çš„é€šé“ç¡¬å‰ªæŽ‰\n",
    "\n",
    "> æœ¬è´¨ä»ç„¶æ˜¯â€œå¸¦ç¨€ç–çº¦æŸçš„ä¼˜åŒ–é—®é¢˜â€ï¼Œåªæ˜¯ä½œç”¨å¯¹è±¡ä»Žå•ä¸ªå…ƒç´ æå‡åˆ°äº†â€œç»“æž„åŒ–å—â€ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c262a7f",
   "metadata": {},
   "source": [
    "## 2.2 é‡åŒ–ï¼ˆQuantizationï¼‰çš„ä¼˜åŒ–è§†è§’\n",
    "\n",
    "### 2.2.1 ç®€å•çš„ uniform quantization\n",
    "\n",
    "è€ƒè™‘å¯¹æƒé‡é›†åˆ $\\{w_i\\}$ åšå¯¹ç§°å‡åŒ€é‡åŒ–ï¼Œbit å®½ä¸º bï¼š\n",
    "\n",
    "- é‡åŒ–çº§åˆ«ï¼š$q_i \\in \\{-Q,\\dots,Q\\}$ï¼Œå…¶ä¸­ $Q = 2^{b-1}-1$\n",
    "- ç¼©æ”¾å› å­ï¼ˆscaleï¼‰ï¼š$s > 0$\n",
    "- é‡åŒ–/åé‡åŒ–è¿‡ç¨‹ï¼š\n",
    "\n",
    "$$\n",
    "q_i = \\text{round}(w_i / s), \\quad\n",
    "  \\hat{w}_i = s \\cdot q_i\n",
    "$$\n",
    "\n",
    "\n",
    "å…¸åž‹ç›®æ ‡æ˜¯æœ€å°åŒ–é‡åŒ–è¯¯å·®ï¼š\n",
    "\n",
    "$$\n",
    "\\min_s \\sum_i (w_i - \\hat{w}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™å®žé™…ä¸Šæ˜¯ä¸€ä¸ªä¸€ç»´å‡¸ä¼˜åŒ–é—®é¢˜ã€‚\n",
    "\n",
    "å·¥ç¨‹ä¸Šå¸¸è§ heuristicsï¼š\n",
    "\n",
    "- ç›´æŽ¥å–ï¼š\n",
    "\n",
    "$$\n",
    "s = \\frac{\\max_i |w_i|}{Q}\n",
    "$$\n",
    "\n",
    "\n",
    "- æˆ–å–æŸä¸ªåˆ†ä½æ•°ï¼ˆå¦‚ 99.9%ï¼‰æ›¿ä»£ maxï¼Œé˜²æ­¢ outlier è¿‡å¤§ï¼š\n",
    "\n",
    "$$\n",
    "s = \\frac{\\text{quantile}_{p}(|w_i|)}{Q}\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€è¦ç‚¹ã€‘**  \n",
    "ä½ éœ€è¦çŸ¥é“ï¼š\n",
    "\n",
    "- é‡åŒ–å‚æ•°ï¼ˆscale/zero-pointï¼‰å¯ä»¥é€šè¿‡æœ€å°äºŒä¹˜æ„ä¹‰ä¸‹çš„ä¼˜åŒ–æ±‚å¾—\n",
    "- å·¥ç¨‹å®žçŽ°ä¸­ç”¨ histogram + æœç´¢ / heuristics åšè¿‘ä¼¼æ±‚è§£\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2.2 LSQï¼ˆLearned Step Size Quantizationï¼‰æ€æƒ³\n",
    "\n",
    "æ›´è¿›ä¸€æ­¥ï¼Œå¯ä»¥æŠŠ scale $s$ å½“æˆå¯å­¦ä¹ å‚æ•°ï¼Œè®©åå‘ä¼ æ’­ç›´æŽ¥ä¼˜åŒ–ï¼š\n",
    "\n",
    "- å®šä¹‰ä¸€ä¸ªâ€œä¼ªé‡åŒ–â€ç®—å­ï¼ˆç”¨ STE é€¼è¿‘æ¢¯åº¦ï¼‰\n",
    "- åœ¨è®­ç»ƒ/å¾®è°ƒæ—¶ joint optimize $W$ å’Œ $s$\n",
    "\n",
    "å½¢å¼ä¸Šï¼š\n",
    "\n",
    "$$\n",
    "\\min_{W,s} L(\\text{Quantize}(W; s))\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™ç§æ–¹æ³•ä½¿å¾—é‡åŒ–å‚æ•°é’ˆå¯¹å½“å‰ä»»åŠ¡/æ•°æ®é›†è‡ªé€‚åº”åœ°æ”¶æ•›åˆ°è¾ƒå¥½çš„å€¼ï¼Œä»Žè€Œæå‡ä½Ž bit é‡åŒ–çš„ç²¾åº¦ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 çŸ¥è¯†è’¸é¦ï¼ˆDistillationï¼‰çš„ä¼˜åŒ–è§†è§’\n",
    "\n",
    "ç»™å®š teacher æ¨¡åž‹ $T$ å’Œ student æ¨¡åž‹ $S$ï¼š\n",
    "\n",
    "- Teacher è¾“å‡ºï¼š$p^T$\n",
    "- Student è¾“å‡ºï¼š$p^S$\n",
    "\n",
    "å¸¸è§çš„ distillation lossï¼š\n",
    "\n",
    "$$\n",
    "L_{\\text{distill}} = \\alpha \\cdot \\text{CE}(y, p^S)\n",
    "+ (1 - \\alpha) \\cdot T^2 \\cdot \\text{KL}\\big(\\sigma(z^T/T) \\,\\|\\, \\sigma(z^S/T)\\big)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- CEï¼šäº¤å‰ç†µ\n",
    "- KLï¼šKL æ•£åº¦\n",
    "- $T$ï¼šæ¸©åº¦ï¼ˆtemperatureï¼‰\n",
    "- $\\sigma$ï¼šsoftmax\n",
    "\n",
    "ä»Žä¼˜åŒ–è§’åº¦çœ‹ï¼š\n",
    "\n",
    "- è¿™æ˜¯ä¸€ä¸ªå¸¦æœ‰ä¸¤éƒ¨åˆ†æŸå¤±çš„ç›®æ ‡å‡½æ•°\n",
    "- ä½ åœ¨â€œç²¾ç¡®æ‹Ÿåˆ ground-truth æ ‡ç­¾â€å’Œâ€œæ¨¡ä»¿ teacher çš„è½¯åˆ†å¸ƒâ€ä¹‹é—´åšæƒè¡¡\n",
    "\n",
    "**ã€ä¸ŽæŽ¨ç†åŠ é€Ÿçš„å…³ç³»ã€‘**  \n",
    "- Student æ¨¡åž‹é€šå¸¸æ›´å°ã€æ›´æµ…ã€ç»´åº¦æ›´ä½Ž\n",
    "- åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²æ—¶ä¼šå¤§å¹…é™ä½Žå»¶è¿Ÿä¸Žå†…å­˜å ç”¨\n",
    "- ä½ è¦ç†è§£ï¼šè’¸é¦å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§â€œåœ¨ teacher çš„å‡½æ•°ç©ºé—´é™„è¿‘å¯»æ‰¾æµ…ç½‘ç»œé€¼è¿‘â€çš„ä¼˜åŒ–è¿‡ç¨‹\n",
    "\n",
    "---\n",
    "\n",
    "## 2.4 å¤šç›®æ ‡ä¼˜åŒ–ï¼šç²¾åº¦ vs å»¶è¿Ÿ vs å†…å­˜\n",
    "\n",
    "åœ¨åšéƒ¨ç½²æ—¶ï¼Œä½ ä¸ä¼šåªå…³å¿ƒ lossï¼Œè¿˜ä¼šå…³å¿ƒï¼š\n",
    "\n",
    "- latencyï¼ˆæŽ¨ç†å»¶è¿Ÿï¼‰\n",
    "- memoryï¼ˆæ˜¾å­˜ / DRAM å ç”¨ï¼‰\n",
    "- throughputï¼ˆQPSï¼‰\n",
    "\n",
    "å¯ä»¥å°†è¿™äº›çº³å…¥ä¼˜åŒ–ç›®æ ‡ï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\quad \\alpha \\cdot \\text{Error}(\\theta)\n",
    "+ \\beta \\cdot \\text{Latency}(\\theta)\n",
    "+ \\gamma \\cdot \\text{Memory}(\\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- $\\theta$ï¼šæ¨¡åž‹ç»“æž„ + é‡åŒ–é…ç½® + å‰ªæžç­–ç•¥ ç­‰\n",
    "- $\\text{Latency}(\\theta)$ï¼šé€šè¿‡ profile æˆ– analytical model ä¼°è®¡\n",
    "- $\\text{Memory}(\\theta)$ï¼šç”±å‚æ•°é‡ã€activationã€KV cache å†³å®š\n",
    "\n",
    "å·¥ç¨‹å®žçŽ°ä¸­å¸¸è§ç®€åŒ–ï¼š\n",
    "\n",
    "- å›ºå®šæŸä¸ª latency/memory ä¸Šé™ä½œä¸ºçº¦æŸï¼š\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\text{Error}(\\theta)\n",
    "  \\quad \\text{s.t.} \\quad \\text{Latency}(\\theta) \\le L_{\\max}, \\\n",
    "  \\text{Memory}(\\theta) \\le M_{\\max}\n",
    "$$\n",
    "\n",
    "\n",
    "- æˆ–æŠŠ latency/memory è½¬æ¢ä¸ºæ­£åˆ™é¡¹åŠ å…¥ loss\n",
    "\n",
    "> é‡è¦çš„æ˜¯ï¼šä½ è¦èƒ½æŠŠâ€œéƒ¨ç½²éœ€æ±‚â€ç¿»è¯‘æˆæ•°å­¦ä¸Šçš„â€œç›®æ ‡ + çº¦æŸâ€ï¼Œè¿™æ ·æ‰èƒ½ç”¨ä¼˜åŒ–å·¥å…·ç³»ç»Ÿåœ°è®¾è®¡ç®—æ³•ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 2.5 æœ¬ç« å°ç»“\n",
    "\n",
    "æœ¬ç« é‡ç‚¹ï¼š\n",
    "\n",
    "1. å‰ªæžå¯ä»¥çœ‹ä½œå¸¦ $L_0/L_1$ ç¨€ç–çº¦æŸçš„ä¼˜åŒ–é—®é¢˜\n",
    "2. é‡åŒ–å¯ä»¥é€šè¿‡æœ€å°åŒ–é‡åŒ–è¯¯å·®çš„ä¼˜åŒ–é—®é¢˜ç¡®å®š scale/zero-pointï¼Œè¿›ä¸€æ­¥å¯é€šè¿‡è®­ç»ƒ joint optimize\n",
    "3. è’¸é¦æ˜¯ä¸€ä¸ªè”åˆæœ€å°åŒ– CE å’Œ KL çš„å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜\n",
    "4. éƒ¨ç½²æ—¶çš„ç²¾åº¦ã€å»¶è¿Ÿã€å†…å­˜å¯ä»¥ç»Ÿä¸€æœ¬ä¸ºå¤šç›®æ ‡/å¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜\n",
    "\n",
    "> åœ¨åŽç»­ç« èŠ‚ä¸­ï¼Œè¿™äº›ä¼˜åŒ–ç›®æ ‡ä¼šä¸Žè¿‘ä¼¼ç†è®ºã€æ¦‚çŽ‡ç»Ÿè®¡ã€ç¡¬ä»¶æ¨¡åž‹ç»“åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€å¥—å®Œæ•´çš„æŽ¨ç†åŠ é€Ÿæ€ç»´ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13525d76",
   "metadata": {
    "id": "13525d76"
   },
   "source": [
    "# ç¬¬ 3 ç« ï¼šè¿‘ä¼¼ç†è®ºï¼ˆApproximation Theory for Quantization & Cheap Opsï¼‰\n",
    "\n",
    "è¿‘ä¼¼ç†è®ºå›žç­”çš„é—®é¢˜æ˜¯ï¼š\n",
    "\n",
    "> â€œåœ¨å…è®¸ä¸€å®šè¯¯å·®çš„å‰æä¸‹ï¼Œå¦‚ä½•ç”¨æ›´ç®€å•çš„å‡½æ•° / æ›´ç²—çš„ç²¾åº¦æ¥é€¼è¿‘åŽŸå‡½æ•°ï¼Ÿâ€\n",
    "\n",
    "åœ¨æŽ¨ç†åŠ é€Ÿä¸­ä¸»è¦åº”ç”¨äºŽï¼š\n",
    "\n",
    "- é‡åŒ–è¯¯å·®å»ºæ¨¡\n",
    "- æ¿€æ´»å‡½æ•°è¿‘ä¼¼ï¼ˆGELU/SiLU/tanh ç­‰ï¼‰\n",
    "- ç”¨å¤šé¡¹å¼ / åˆ†æ®µçº¿æ€§å‡½æ•°æ›¿ä»£å¤æ‚ç®—å­\n",
    "- approximate computingï¼ˆä¾‹å¦‚ç”¨ cheap ops æ›¿æ¢ expensive opsï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 å‡åŒ€é‡åŒ–çš„è¯¯å·®æ¨¡åž‹\n",
    "\n",
    "è€ƒè™‘æ­¥é•¿ä¸º $\\Delta$ çš„å‡åŒ€é‡åŒ–ï¼š\n",
    "\n",
    "$$\n",
    "\\hat{w} = Q(w) = \\Delta \\cdot \\text{round}\\Big(\\frac{w}{\\Delta}\\Big)\n",
    "$$\n",
    "\n",
    "\n",
    "å®šä¹‰é‡åŒ–è¯¯å·®ï¼š\n",
    "\n",
    "$$\n",
    "e = w - \\hat{w}\n",
    "$$\n",
    "\n",
    "\n",
    "åœ¨å¾ˆå¤šå‡è®¾ä¸‹ï¼ˆä¿¡å·åœ¨æ¯ä¸ªé‡åŒ–åŒºé—´å†…åˆ†å¸ƒæ¯”è¾ƒâ€œå‡åŒ€â€ï¼‰ï¼Œå¯ä»¥è¿‘ä¼¼è®¤ä¸ºï¼š\n",
    "\n",
    "- $e$ åœ¨ $[-\\Delta/2, \\Delta/2]$ ä¸Šå‡åŒ€åˆ†å¸ƒ\n",
    "- å³ï¼š$e \\sim \\mathcal{U}(-\\Delta/2, \\Delta/2)$\n",
    "\n",
    "äºŽæ˜¯ï¼š\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[e] \\approx 0, \\quad\n",
    "\\mathbb{E}[e^2] = \\text{Var}(e) \\approx \\frac{\\Delta^2}{12}\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹æ„ä¹‰ã€‘**  \n",
    "- é‡åŒ–æ­¥é•¿ $\\Delta$ è¶Šå¤§ â†’ è¯¯å·®æ–¹å·®è¶Šå¤§\n",
    "- å¯¹æŸå±‚ä½¿ç”¨æ›´ä½Ž bitï¼ˆæ›´å°‘çº§åˆ«ï¼‰æ—¶ï¼Œå¯ä»¥ä¼°ç®—å™ªå£°èƒ½é‡ï¼š$\\sigma_e^2 \\approx \\Delta^2/12$\n",
    "\n",
    "è¿™ä¸ºâ€œæŒ‰å±‚åŠ¨æ€é€‰æ‹© bit å®½â€æä¾›äº†ç†è®ºä¾æ®ï¼š\n",
    "\n",
    "- å¯¹æ›´æ•æ„Ÿçš„å±‚ä½¿ç”¨å° $\\Delta$ï¼ˆæ›´å¤š bitï¼‰\n",
    "- å¯¹ä¸æ•æ„Ÿçš„å±‚ä½¿ç”¨å¤§ $\\Delta$ï¼ˆæ›´å°‘ bitï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 æ¿€æ´»å‡½æ•°çš„è¿‘ä¼¼ï¼šä»¥ GELU ä¸ºä¾‹\n",
    "\n",
    "GELU å®šä¹‰ï¼š\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ $\\Phi(x)$ æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ CDFï¼š\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^x e^{-t^2/2} \\, dt\n",
    "$$\n",
    "\n",
    "\n",
    "ç›´æŽ¥è®¡ç®— CDF éžå¸¸æ˜‚è´µï¼Œå› æ­¤å¸¸ç”¨è¿‘ä¼¼ï¼š\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) \\approx 0.5 x \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}}(x + 0.044715 x^3)\\right]\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "è¿›ä¸€æ­¥ï¼Œå¯ä»¥å°† tanh åˆè¿‘ä¼¼ä¸ºä¸€ä¸ªå¤šé¡¹å¼æˆ–åˆ†æ®µçº¿æ€§å‡½æ•°ï¼Œä½¿æ•´ä½“è®¡ç®—åªåŒ…å«ï¼š\n",
    "\n",
    "- åŠ æ³•\n",
    "- ä¹˜æ³•\n",
    "- å°‘é‡è¡¨æŸ¥\n",
    "\n",
    "**ã€è¿‘ä¼¼ç†è®ºè§†è§’ã€‘**  \n",
    "\n",
    "- åœ¨ä¸€ä¸ªæœ‰é™åŒºé—´ $[a,b]$ ä¸Šï¼Œç”¨å¤šé¡¹å¼ $P_n(x)$ é€¼è¿‘ä¸€ä¸ªå¹³æ»‘å‡½æ•° $f(x)$ æ˜¯å¯è¡Œçš„ï¼š\n",
    "\n",
    "$$\n",
    "\\|f - P_n\\|_{\\infty, [a,b]} \\to 0 \\quad \\text{(å½“ n â†’ âˆž æ—¶)}\n",
    "$$\n",
    "\n",
    "\n",
    "- å¯¹åº”åˆ°å·¥ç¨‹ä¸­ï¼Œå°±æ˜¯é€‰å–ä¸€ä¸ªå¤šé¡¹å¼é˜¶æ•° nï¼Œä½¿å¾—ï¼š\n",
    "  - é€¼è¿‘è¯¯å·®è¶³å¤Ÿå°ï¼ˆç²¾åº¦è¦æ±‚ï¼‰\n",
    "  - è®¡ç®—ä»£ä»·è¶³å¤Ÿä½Žï¼ˆä¹˜æ³•/åŠ æ³•æ¬¡æ•°ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 å¤šé¡¹å¼è¿‘ä¼¼çš„æž„é€ ï¼ˆæœ€å°äºŒä¹˜ + Chebyshevï¼‰\n",
    "\n",
    "ç»™å®šå‡½æ•° $f(x)$ï¼Œå¸Œæœ›åœ¨åŒºé—´ $[a,b]$ ä¸Šç”¨å¤šé¡¹å¼ï¼š\n",
    "\n",
    "$$\n",
    "P_n(x) = \\sum_{k=0}^n c_k x^k\n",
    "$$\n",
    "\n",
    "\n",
    "æ¥é€¼è¿‘å®ƒã€‚\n",
    "\n",
    "å¸¸è§æ–¹æ³•ï¼š\n",
    "\n",
    "1. **æœ€å°äºŒä¹˜æ‹Ÿåˆ**ï¼ˆç¦»æ•£ç‚¹ï¼‰ï¼š\n",
    "   - åœ¨åŒºé—´å†…é‡‡æ ·è‹¥å¹²ç‚¹ $x_i$ï¼Œæœ€å°åŒ–ï¼š\n",
    "\n",
    "$$\n",
    "\\sum_i (f(x_i) - P_n(x_i))^2\n",
    "$$\n",
    "\n",
    "\n",
    "   - è¿™ä¼šå¯¼è‡´ä¸€ä¸ªçº¿æ€§æœ€å°äºŒä¹˜é—®é¢˜æ±‚ $\\{c_k\\}$\n",
    "\n",
    "2. **Chebyshev é€¼è¿‘**ï¼ˆå‡åŒ€æœ€å¤§è¯¯å·®æœ€å°ï¼‰ï¼š\n",
    "   - ç”¨ Chebyshev å¤šé¡¹å¼ä½œä¸ºåŸºå‡½æ•°\n",
    "   - åœ¨ç†è®ºä¸Šèƒ½æä¾›æ›´å¥½çš„æœ€å¤§è¯¯å·®ç•Œ\n",
    "\n",
    "**ã€å¯¹æŽ¨ç†å·¥ç¨‹å¸ˆçš„è¦æ±‚ã€‘**  \n",
    "- ä¸éœ€è¦ä¼šæ‰‹æŽ¨ Chebyshev å¤šé¡¹å¼\n",
    "- éœ€è¦çŸ¥é“ï¼š\n",
    "  - æ¿€æ´»å‡½æ•°/ç‰¹æ®Šå‡½æ•°çš„è¿‘ä¼¼æ¥è‡ªâ€œå¤šé¡¹å¼æ‹Ÿåˆâ€æˆ–â€œæœ‰ç†å‡½æ•°æ‹Ÿåˆâ€\n",
    "  - é˜¶æ•°è¶Šé«˜ã€åŸºå‡½æ•°è¶Šå¤æ‚ â†’ ç²¾åº¦è¶Šå¥½ï¼Œä½†è®¡ç®—ä¹Ÿè¶Šè´µ\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Approximate Computingï¼šç”¨â€œæ›´ä¾¿å®œâ€çš„ç®—å­æ›¿ä»£\n",
    "\n",
    "å…¸åž‹æ€è·¯ï¼š\n",
    "\n",
    "- ç”¨ shift æ›¿ä»£ä¹˜æ³•ï¼ˆå½“ç³»æ•°æŽ¥è¿‘ $2^k$ æ—¶ï¼‰\n",
    "- ç”¨ LUTï¼ˆæŸ¥è¡¨ï¼‰æ›¿ä»£å¤æ‚å‡½æ•°ï¼ˆå¦‚ exp / log / erfï¼‰\n",
    "- ç”¨ piecewise linear æ›¿ä»£ smooth éžçº¿æ€§ï¼ˆå¦‚ ReLU6, HardSwish ç­‰ï¼‰\n",
    "\n",
    "è¿™éƒ½å¯ä»¥çœ‹ä½œæ˜¯ï¼š\n",
    "\n",
    "> åœ¨å…è®¸ä¸€å®šè¯¯å·®çš„å‰æä¸‹ï¼Œç”¨â€œæ›´ä¾¿å®œçš„ç®—å­ç»„åˆâ€è¿‘ä¼¼åŽŸå‡½æ•°ã€‚\n",
    "\n",
    "**ã€ä¸Žä½ çš„å·¥ä½œå…³ç³»ã€‘**  \n",
    "\n",
    "- åœ¨è®¾è®¡è‡ªå®šä¹‰ kernel æ—¶ï¼Œä½ å¯ä»¥ï¼š\n",
    "  - é€šè¿‡æ•°å­¦è¿‘ä¼¼æŠŠå¤æ‚ç®—å­åˆ†è§£æˆâ€œmul+add+max+shift+table lookupâ€\n",
    "  - åˆ©ç”¨ç¡¬ä»¶å¯¹è¿™äº›åŸºæœ¬ç®—å­çš„é«˜é€Ÿæ”¯æŒ\n",
    "- åœ¨è¯„ä¼°è¿‘ä¼¼æ—¶ï¼Œä½ éœ€è¦æœ‰ï¼š\n",
    "  - å®šæ€§ç›´è§‰ï¼šè¯¯å·®å¯¹ä¸‹æ¸¸çš„å½±å“ï¼ˆä¾‹å¦‚æ¿€æ´»è¾“å‡ºèŒƒå›´å˜çª„/å˜å®½ï¼‰\n",
    "  - ç®€å•å®šé‡å·¥å…·ï¼šæœ€å¤§è¯¯å·®ã€L2 è¯¯å·®ç­‰\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 æœ¬ç« å°ç»“\n",
    "\n",
    "1. è¿‘ä¼¼ç†è®ºä¸ºé‡åŒ–è¯¯å·®æä¾›äº†å™ªå£°æ¨¡åž‹ï¼ˆä¾‹å¦‚ $\\Delta^2/12$ï¼‰\n",
    "2. æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ GELUï¼‰çš„å·¥ç¨‹å®žçŽ°å¹¿æ³›ä¾èµ–å¤šé¡¹å¼/æœ‰ç†å‡½æ•°è¿‘ä¼¼\n",
    "3. Approximate computing æœ¬è´¨æ˜¯â€œç”¨æ›´ä¾¿å®œçš„å‡½æ•°æ—é€¼è¿‘åŽŸå‡½æ•°æ—â€\n",
    "4. ä½œä¸ºæŽ¨ç†åŠ é€Ÿå·¥ç¨‹å¸ˆï¼Œä½ éœ€è¦ï¼š\n",
    "   - çœ‹æ‡‚â€œè¯¯å·® vs è®¡ç®—ä»£ä»·â€çš„ tradeoff\n",
    "   - åœ¨éƒ¨ç½²æ—¶åˆç†é€‰æ‹©è¿‘ä¼¼ç­‰çº§ï¼Œè€Œä¸æ˜¯â€œç›²ç›®è¿½æ±‚ä½Žè¯¯å·®â€æˆ–â€œç›²ç›®çœç®—åŠ›â€\n",
    "\n",
    "åŽç»­ç« èŠ‚ï¼Œä¼šç”¨æ¦‚çŽ‡/ä¿¡æ¯è®ºçš„è§†è§’è¿›ä¸€æ­¥ç†è§£è¿™äº›è¯¯å·®æ˜¯å¦‚ä½•åœ¨ç³»ç»Ÿä¸­ä¼ æ’­çš„ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220a4dc",
   "metadata": {
    "id": "9220a4dc"
   },
   "source": [
    "# ç¬¬ 4 ç« ï¼šæ¦‚çŽ‡ä¸Žç»Ÿè®¡ï¼ˆProbability & Statistics for Runtime Inferenceï¼‰\n",
    "\n",
    "æœ¬ç« é‡ç‚¹ï¼š\n",
    "\n",
    "- é‡åŒ–å’Œå‰ªæžä¸­çš„â€œåˆ†å¸ƒè§†è§’â€\n",
    "- è’¸é¦å’Œæ¸©åº¦ç¼©æ”¾ä¸­çš„ KL/äº¤å‰ç†µ\n",
    "- é€šè¿‡åˆ†ä½æ•°ã€ç›´æ–¹å›¾é€‰æ‹© clipping é˜ˆå€¼\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 è¾“å‡ºåˆ†å¸ƒä¸Ž KL æ•£åº¦\n",
    "\n",
    "### 4.1.1 äº¤å‰ç†µä¸Ž KL\n",
    "\n",
    "ç»™å®šçœŸå®žåˆ†å¸ƒ $p$ ä¸Žæ¨¡åž‹åˆ†å¸ƒ $q$ï¼š\n",
    "\n",
    "- äº¤å‰ç†µï¼š\n",
    "\n",
    "$$\n",
    "H(p, q) = - \\sum_i p_i \\log q_i\n",
    "$$\n",
    "\n",
    "\n",
    "- KL æ•£åº¦ï¼š\n",
    "\n",
    "$$\n",
    "\\text{KL}(p\\|q) = \\sum_i p_i \\log \\frac{p_i}{q_i}\n",
    "$$\n",
    "\n",
    "\n",
    "äºŒè€…å…³ç³»ï¼š\n",
    "\n",
    "$$\n",
    "H(p, q) = H(p) + \\text{KL}(p\\|q)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ $H(p)$ ä¸Žå‚æ•°æ— å…³ï¼Œä¼˜åŒ–æ—¶å¸¸ç›´æŽ¥æœ€å°åŒ–äº¤å‰ç†µã€‚\n",
    "\n",
    "åœ¨è’¸é¦ä¸­ï¼Œteacher åˆ†å¸ƒ $p^T$ï¼Œstudent åˆ†å¸ƒ $p^S$ï¼š\n",
    "\n",
    "$$\n",
    "L_{\\text{KD}} = \\text{KL}(p^T \\| p^S)\n",
    "$$\n",
    "\n",
    "\n",
    "åæ˜  student åœ¨å¤šå¤§ç¨‹åº¦ä¸Šâ€œæ¨¡ä»¿â€äº† teacher çš„è¾“å‡ºåˆ†å¸ƒã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1.2 æ¸©åº¦ï¼ˆTemperatureï¼‰\n",
    "\n",
    "logits $z$ ç»è¿‡ softmaxï¼š\n",
    "\n",
    "$$\n",
    "p_i = \\frac{e^{z_i/T}}{\\sum_j e^{z_j/T}}\n",
    "$$\n",
    "\n",
    "\n",
    "- $T=1$ï¼šå¸¸è§„ softmax\n",
    "- $T>1$ï¼šåˆ†å¸ƒå˜å¹³æ»‘ï¼ˆâ€œè½¯æ ‡ç­¾â€ï¼‰\n",
    "- $T<1$ï¼šåˆ†å¸ƒå˜æ›´å°–é”\n",
    "\n",
    "åœ¨è’¸é¦ä¸­é€šå¸¸ç”¨ $T>1$ï¼š\n",
    "\n",
    "- Teacher è¾“å‡ºå˜å¾—æ›´â€œè½¯â€ï¼ŒåŒ…å«æ›´å¤šç±»åˆ«é—´ç›¸å¯¹å…³ç³»ä¿¡æ¯\n",
    "- Student æ›´å®¹æ˜“å­¦ä¹ åˆ° teacher çš„â€œæš—çŸ¥è¯†â€ï¼ˆdark knowledgeï¼‰\n",
    "\n",
    "**ã€ä¸Žä½ çš„å·¥ä½œå…³ç³»ã€‘**  \n",
    "- åœ¨è¾¹ç¼˜éƒ¨ç½² Distilled æ¨¡åž‹æ—¶ï¼Œä½ åº”å½“ç†è§£ï¼š\n",
    "  - student çš„è¡Œä¸ºä¸ä»…æ‹Ÿåˆ hard labelï¼Œä¹Ÿæ‹Ÿåˆäº† teacher æä¾›çš„ soft label\n",
    "  - åœ¨æŸäº›åˆ†å¸ƒ shift åœºæ™¯ä¸­ï¼Œè’¸é¦è¿‡çš„æ¨¡åž‹å¯èƒ½æ›´é²æ£’\n",
    "\n",
    "---\n",
    "\n",
    "## 4.2 é‡åŒ–ä¸­çš„ç»Ÿè®¡è§†è§’ï¼šç›´æ–¹å›¾ä¸Žåˆ†ä½æ•°\n",
    "\n",
    "åœ¨é€‰æ‹©é‡åŒ–é˜ˆå€¼ï¼ˆclipping rangeï¼‰æ—¶ï¼Œå¸¸è§çš„åšæ³•æ˜¯ï¼š\n",
    "\n",
    "1. æ”¶é›†ä¸€æ®µæ—¶é—´çš„ activations / weights\n",
    "2. ç”»ç›´æ–¹å›¾ï¼ˆhistogramï¼‰\n",
    "3. å†³å®šï¼š\n",
    "   - æ˜¯å¦ä½¿ç”¨å¯¹ç§°é‡åŒ–ï¼ˆsymmetricï¼‰\n",
    "   - æ˜¯å¦ clip ä¾‹å¦‚ top 0.1% çš„ outliers\n",
    "\n",
    "### 4.2.1 åˆ†ä½æ•°å‰ªè£ï¼ˆpercentile clippingï¼‰\n",
    "\n",
    "ä¾‹å¦‚è®¾ç½®ï¼š\n",
    "\n",
    "$$\n",
    "\\alpha = \\text{quantile}_{p}(|x|)\n",
    "$$\n",
    "\n",
    "\n",
    "ç„¶åŽå°†èŒƒå›´è£å‰ªåˆ° $[- \\alpha, \\alpha]$ï¼Œå†åœ¨è¯¥èŒƒå›´å†…åšå‡åŒ€é‡åŒ–ã€‚\n",
    "\n",
    "è¿™æ ·åšçš„ç†ç”±æ˜¯ï¼š\n",
    "\n",
    "- æžå°‘æ•°éžå¸¸å¤§çš„ outlier ä¼šæžå¤§æ”¾å¤§ scaleï¼Œä»Žè€Œè®©å¤§éƒ¨åˆ†å€¼è¢«æŒ¤åŽ‹åˆ°æžç»†çš„ quantization bin\n",
    "- å°† outlier è£å‰ªæŽ‰é€šå¸¸å¯¹æœ€ç»ˆæ€§èƒ½å½±å“ä¸å¤§ï¼Œæœ‰æ—¶ç”šè‡³æœ‰æ­£åˆ™åŒ–æ•ˆæžœ\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2.2 KL-based threshold é€‰æ‹©\n",
    "\n",
    "éƒ¨åˆ†æ¡†æž¶ï¼ˆä¾‹å¦‚æ—©æœŸçš„ TensorRT / TensorFlow é‡åŒ–æ–¹æ¡ˆï¼‰ä¼šï¼š\n",
    "\n",
    "- å°è¯•å¤šä¸ªä¸åŒçš„ clipping threshold\n",
    "- å¯¹æ¯ä¸ªé˜ˆå€¼ï¼Œå°†åŽŸå§‹ç›´æ–¹å›¾ä¸Žé‡åŒ–åŽé‡å»ºçš„ç›´æ–¹å›¾æ¯”è¾ƒ\n",
    "- é€‰æ‹©ä½¿ KL(p\\|q) æœ€å°çš„é˜ˆå€¼\n",
    "\n",
    "**ã€æœ¬è´¨ã€‘**  \n",
    "é€šè¿‡ KL æ¥è¡¡é‡åˆ†å¸ƒå½¢çŠ¶çš„å˜åŒ–ï¼Œé¿å…é‡åŒ–å¯¼è‡´åˆ†å¸ƒä¸¥é‡â€œç•¸å˜â€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 4.3 ç»Ÿè®¡ç¨³å¥æ€§ï¼ˆRobust Statisticsï¼‰\n",
    "\n",
    "åœ¨æŽ¨ç†éƒ¨ç½²ä¸­ï¼Œä½ éœ€è¦è€ƒè™‘ï¼š\n",
    "\n",
    "- ä¸Šæ¸¸æ•°æ®åˆ†å¸ƒæ˜¯å¦ä¼šå‘ç”Ÿæ¼‚ç§»ï¼ˆdistribution shiftï¼‰\n",
    "- æ˜¯å¦å­˜åœ¨å™ªå£°ã€å¼‚å¸¸å€¼ï¼ˆoutliersï¼‰\n",
    "- å¯¹ä¸åŒå±‚çš„æ¿€æ´»åˆ†å¸ƒè¦æœ‰å®è§‚è®¤çŸ¥ï¼š\n",
    "  - æ˜¯å¦è¿‘ä¼¼é«˜æ–¯\n",
    "  - æ˜¯å¦æœ‰é•¿å°¾\n",
    "\n",
    "æœ‰äº›æŠ€æœ¯ï¼ˆä¾‹å¦‚ robust normã€Huber æŸå¤±ï¼‰å¯ä»¥ç¼“è§£ outlier å¯¹å‚æ•°/ç»Ÿè®¡é‡çš„å½±å“ã€‚  \n",
    "åœ¨è¿™é‡Œä½ ä¸éœ€è¦æ·±å…¥æŽ¨å¯¼ï¼Œåªéœ€è¦çŸ¥é“ï¼š\n",
    "\n",
    "- è®¸å¤šå¯ä»¥â€œæŠ‘åˆ¶ outlierâ€çš„æ–¹æ³•æœ¬è´¨ä¸Šæ¥è‡ªç¨³å¥ç»Ÿè®¡ç†è®º\n",
    "- åœ¨é‡åŒ–/clip/å½’ä¸€åŒ–ä¸­ï¼Œä½¿ç”¨åˆ†ä½æ•°è€Œä¸æ˜¯ max/min ä¹Ÿæ˜¯ä¸€ç§ç¨³å¥ç»Ÿè®¡å®žè·µ\n",
    "\n",
    "---\n",
    "\n",
    "## 4.4 æœ¬ç« å°ç»“\n",
    "\n",
    "1. KLã€äº¤å‰ç†µæ˜¯è’¸é¦ä¸Žåˆ†å¸ƒå¯¹é½çš„æ•°å­¦å·¥å…·\n",
    "2. æ¸©åº¦ç¼©æ”¾ï¼ˆTï¼‰æŽ§åˆ¶è¾“å‡ºåˆ†å¸ƒçš„â€œå¹³æ»‘åº¦â€ï¼Œå½±å“å­¦ä¹ ä¿¡å·\n",
    "3. é‡åŒ–ä¸­çš„é˜ˆå€¼é€‰æ‹©é€šå¸¸åŸºäºŽç›´æ–¹å›¾ä¸Žåˆ†ä½æ•°å‰ªè£\n",
    "4. ç¨æœ‰ç»Ÿè®¡ç›´è§‰ï¼Œæœ‰åŠ©äºŽç†è§£ï¼š\n",
    "   - ä¸ºä»€ä¹ˆ outlier ä¼šæ¯æŽ‰é‡åŒ–\n",
    "   - ä¸ºä»€ä¹ˆå‰ªè£ outlier åè€Œå¯èƒ½æ›´å¥½\n",
    "   - ä¸ºä»€ä¹ˆè’¸é¦åŽçš„æ¨¡åž‹åœ¨éƒ¨ç½²ä¸­å¯èƒ½æ›´é²æ£’\n",
    "\n",
    "åŽç»­ç« èŠ‚çš„ä¿¡æ¯è®ºä¼šä»Žæ›´åŸºç¡€çš„è§’åº¦è§£é‡Šç†µä¸ŽåŽ‹ç¼©çš„å…³ç³»ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b56d6",
   "metadata": {
    "id": "6e9b56d6"
   },
   "source": [
    "# ç¬¬ 5 ç« ï¼šä¿¡æ¯è®ºï¼ˆInformation Theory for Compressionï¼‰\n",
    "\n",
    "ä¿¡æ¯è®ºå›žç­”çš„é—®é¢˜æ˜¯ï¼š\n",
    "\n",
    "> â€œè¦è¡¨ç¤ºä¸€ä¸ªéšæœºå˜é‡/ä¿¡å·æœ€å°‘éœ€è¦å¤šå°‘ bitï¼Ÿâ€\n",
    "\n",
    "åœ¨æŽ¨ç†åŽ‹ç¼©ä¸­ï¼Œä¿¡æ¯è®ºæä¾›ï¼š\n",
    "\n",
    "- ç†µï¼ˆentropyï¼‰ï¼šç†è®ºæœ€å° bit å®½\n",
    "- rateâ€“distortionï¼šåŽ‹ç¼©çŽ‡ vs å¤±çœŸåº¦\n",
    "- ä½œä¸ºæ¨¡åž‹å‰ªæž / é‡åŒ–çš„ä¸€ç§â€œä¸Šå¸è§†è§’â€\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1 ç†µï¼ˆEntropyï¼‰\n",
    "\n",
    "ç¦»æ•£éšæœºå˜é‡ $X$ å–å€¼ $\\{x_i\\}$ï¼Œæ¦‚çŽ‡ $p_i$ï¼Œå…¶ç†µå®šä¹‰ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_i p_i \\log_2 p_i\n",
    "$$\n",
    "\n",
    "\n",
    "- å•ä½æ˜¯ bits\n",
    "- åæ˜ â€œå¹³å‡éœ€è¦å¤šå°‘ bit æ¥ç¼–ç  X çš„å–å€¼â€\n",
    "\n",
    "**ä¾‹å­**ï¼šç¡¬å¸æ­£åé¢ç­‰æ¦‚çŽ‡ï¼š\n",
    "\n",
    "$$\n",
    "H(X) = - (0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) = 1 \\text{ bit}\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5.2 ä¸Žé‡åŒ– / ç¼–ç çš„å…³ç³»\n",
    "\n",
    "å¦‚æžœä½ å¯¹æƒé‡/æ¿€æ´»åšäº†é‡åŒ–å’Œç»Ÿè®¡å»ºæ¨¡ï¼š\n",
    "\n",
    "- é‡åŒ–åŽå€¼åŸŸæœ‰é™ï¼Œä¾‹å¦‚ $\\{-127,\\dots,127\\}$\n",
    "- ä½†æ¯ä¸ªå€¼å‡ºçŽ°é¢‘çŽ‡ä¸åŒ\n",
    "- ä½ å¯ä»¥ç”¨ entropy codingï¼ˆHuffman / arithmetic codingï¼‰è¿›ä¸€æ­¥åŽ‹ç¼©æ¯”ç‰¹æµ\n",
    "\n",
    "ç†è®ºä¸Šï¼Œå¹³å‡ç é•¿ä¸‹ç•ŒæŽ¥è¿‘ç†µï¼š\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\text{code length}] \\ge H(X)\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "- è¿™è§£é‡Šäº†ï¼š\n",
    "  - ä¸ºä»€ä¹ˆç¨€ç–çŸ©é˜µ / é›†ä¸­åˆ†å¸ƒçš„å€¼æ›´å¥½åŽ‹ç¼©\n",
    "  - ä¸ºä»€ä¹ˆæœ‰äº› post-training compression å·¥å…·å¯ä»¥åœ¨ä¸å½±å“ç²¾åº¦çš„å‰æä¸‹ï¼Œå¤§å¹…å‡å°‘æ¨¡åž‹æ–‡ä»¶å¤§å°ï¼ˆå¯¹éƒ¨ç½²åŒ…å¾ˆå…³é”®ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3 Rateâ€“Distortionï¼ˆçŽ‡å¤±çœŸï¼‰\n",
    "\n",
    "Rateâ€“distortion ç†è®ºç ”ç©¶ï¼š\n",
    "\n",
    "> åœ¨å¹³å‡å¤±çœŸä¸è¶…è¿‡ D çš„å‰æä¸‹ï¼Œæœ€å°çš„æ¯”ç‰¹çŽ‡ R æ˜¯å¤šå°‘ï¼Ÿ\n",
    "\n",
    "é€šä¿—ç‰ˆæœ¬ï¼š\n",
    "\n",
    "- â€œæˆ‘è¦åŽ‹å°ä¸€ç‚¹ï¼Œæ„¿æ„æŸå¤±å¤šå°‘ç²¾åº¦ï¼Ÿâ€\n",
    "- æˆ–åè¿‡æ¥ï¼šâ€œç»™æˆ‘è¿™ä¹ˆå¤š bitï¼Œæˆ‘æœ€å¤šèƒ½å®ˆä½å¤šå°‘è´¨é‡ï¼Ÿâ€\n",
    "\n",
    "è™½ç„¶åœ¨éƒ¨ç½²ç«¯ä¸ä¼šç›´æŽ¥ç”¨ä¸Šæ­£å¼çš„ rateâ€“distortion å‡½æ•°ï¼Œ  \n",
    "ä½†è¿™ä¸ªæ€è·¯åœ¨å¾ˆå¤šè®ºæ–‡/æ–¹æ³•è®ºä¸­éƒ½åå¤å‡ºçŽ°ï¼š\n",
    "\n",
    "- bit allocationï¼ˆç»™ä¸åŒå±‚/é€šé“åˆ†é…ä¸åŒ bitï¼‰\n",
    "- å‰ªæžæ¯”ä¾‹åˆ†é…ï¼ˆç»™ä¸åŒå±‚åˆ†é…ä¸åŒç¨€ç–åº¦ï¼‰\n",
    "\n",
    "å¯ä»¥ç†è§£ä¸ºï¼š\n",
    "\n",
    "> ä¸€ä¸ªå—é™èµ„æºï¼ˆbit budget / FLOPs budgetï¼‰ä¸‹çš„â€œä¼˜åŒ–åˆ†é…é—®é¢˜â€ï¼Œä¿¡æ¯è®ºæä¾›å¯¹â€œæœ€ä¼˜æƒ…å†µâ€çš„ä¸€ä¸ªç†è®ºå‚è€ƒã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 5.4 æœ¬ç« å°ç»“\n",
    "\n",
    "1. ç†µåº¦é‡äº†å¹³å‡æ‰€éœ€çš„ç¼–ç  bit æ•°\n",
    "2. ç†µè¶Šä½Ž â†’ è¶Šå®¹æ˜“åŽ‹ç¼©ï¼ˆæ›´é«˜åŽ‹ç¼©æ¯”ï¼‰\n",
    "3. é‡åŒ– + ç†µç¼–ç å¯ä»¥è¿›ä¸€æ­¥å‡å°‘æ¨¡åž‹å¤§å°\n",
    "4. Rateâ€“distortion æä¾›äº†ä¸€ç§â€œèµ„æºâ€“æŸå¤±â€çš„ç³»ç»Ÿæ€§æ€è€ƒæ–¹å¼\n",
    "\n",
    "åœ¨å…·ä½“éƒ¨ç½²ä¸­ï¼Œä½ ä¸ç”¨æŽ¨å¯¼å®šç†ï¼Œä½†å¯ä»¥ç”¨è¿™äº›æ¦‚å¿µæ¥ï¼š\n",
    "\n",
    "- è§£é‡Šâ€œä¸ºä»€ä¹ˆè¿™å±‚å¯ä»¥ aggressively åŽ‹ç¼©ï¼Œè€Œé‚£å±‚ä¸è¡Œï¼Ÿâ€\n",
    "- ç†è§£â€œä¸ºä»€ä¹ˆåŽ‹ç¼©å·¥å…·èƒ½åšåˆ°çœ‹ä¼¼â€˜ç™½å«–â€™ç©ºé—´â€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5810c",
   "metadata": {
    "id": "36d5810c"
   },
   "source": [
    "# ç¬¬ 6 ç« ï¼šä¿¡å·å¤„ç†ä¸Žå·ç§¯æ•°å­¦ï¼ˆSignal Processing & Convolutionï¼‰\n",
    "\n",
    "æœ¬ç« è¿žæŽ¥ï¼š\n",
    "\n",
    "- ä¿¡å·å¤„ç†è§†è§’ä¸‹çš„å·ç§¯\n",
    "- FFTã€Winograd ç­‰å¿«é€Ÿå·ç§¯ç®—æ³•\n",
    "- Toeplitz / Circulant ç­‰ç»“æž„åŒ–çŸ©é˜µ\n",
    "\n",
    "è¿™äº›æ•°å­¦ä¸ºå·ç§¯åŠ é€Ÿæä¾›ç†è®ºåŸºç¡€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 6.1 å·ç§¯å®šç†ï¼šæ—¶åŸŸå·ç§¯ = é¢‘åŸŸä¹˜æ³•\n",
    "\n",
    "ä¸€ç»´ç¦»æ•£å·ç§¯ï¼š\n",
    "\n",
    "$$\n",
    "y[n] = \\sum_k x[k] h[n-k]\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ç¦»æ•£æ—¶é—´å‚…é‡Œå¶å˜æ¢ï¼ˆDTFTï¼‰æ»¡è¶³ï¼š\n",
    "\n",
    "$$\n",
    "Y(\\omega) = X(\\omega) H(\\omega)\n",
    "$$\n",
    "\n",
    "\n",
    "è¿™å°±æ˜¯ **å·ç§¯å®šç†**ï¼š\n",
    "\n",
    "> å·ç§¯åœ¨é¢‘åŸŸé‡Œå˜æˆç‚¹ä¹˜ã€‚\n",
    "\n",
    "è®¡ç®—å¤æ‚åº¦ï¼š\n",
    "\n",
    "- ç›´æŽ¥å·ç§¯ï¼š$O(NK)$\n",
    "- FFT-basedï¼š\n",
    "  - $O(N \\log N)$ è®¡ç®— FFT/é€† FFT\n",
    "  - ä¸­é—´æ˜¯é€ç‚¹ä¹˜æ³•ï¼ˆ$O(N)$ï¼‰\n",
    "\n",
    "åœ¨æŸäº›å¤§æ ¸/é•¿åºåˆ—åœºæ™¯ï¼ŒFFT å·ç§¯æ›´åˆ’ç®—ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 6.2 Toeplitz ä¸Ž Circulant çŸ©é˜µ\n",
    "\n",
    "ä¸€ç»´å·ç§¯å¯ä»¥å†™æˆ Toeplitz çŸ©é˜µä¸Žå‘é‡ä¹˜æ³•ï¼š\n",
    "\n",
    "$$\n",
    "y = T x\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ Toeplitz çŸ©é˜µ T çš„æ¯æ¡å¯¹è§’çº¿å…ƒç´ ç›¸åŒã€‚  \n",
    "åœ¨å‘¨æœŸè¾¹ç•Œæ¡ä»¶ä¸‹å¯å˜æˆ Circulant çŸ©é˜µï¼Œå…¶ç‰¹å¾ï¼š\n",
    "\n",
    "- å¯ä»¥è¢«å‚…é‡Œå¶åŸºå¯¹è§’åŒ–\n",
    "- çŸ©é˜µâ€“å‘é‡ä¹˜æ³•å¯ä»¥é€šè¿‡ FFT é«˜æ•ˆå®žçŽ°\n",
    "\n",
    "$$\n",
    "C = F^\\ast \\Lambda F\n",
    "$$\n",
    "\n",
    "\n",
    "- Fï¼šç¦»æ•£å‚…é‡Œå¶å˜æ¢çŸ©é˜µ\n",
    "- $\\Lambda$ï¼šå¯¹è§’çŸ©é˜µï¼ˆé¢‘åŸŸå¢žç›Šï¼‰\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- ç†è§£ Toeplitz/Circulant ç»“æž„æœ‰åŠ©äºŽï¼š\n",
    "  - ç†è§£ FFT å·ç§¯çš„æœ¬è´¨\n",
    "  - ç†è§£æŸäº›â€œé¢‘åŸŸå‚æ•°åŒ–â€çš„å·ç§¯å±‚\n",
    "- ä¸éœ€è¦è®°ä½å¤æ‚æŽ¨å¯¼ï¼Œä½†è¦çŸ¥é“ï¼š\n",
    "  - å·ç§¯å¯ä»¥è¢«çœ‹æˆå¸¦ç‰¹æ®Šç»“æž„çš„çŸ©é˜µ\n",
    "  - ç‰¹æ®Šç»“æž„å¯ä»¥å¸¦æ¥æ›´å¿«çš„ä¹˜æ³•ç®—æ³•\n",
    "\n",
    "---\n",
    "\n",
    "## 6.3 Winograd å·ç§¯ï¼ˆæœ€å°ä¹˜æ³•ç®—æ³•ï¼‰\n",
    "\n",
    "Winograd æ€æƒ³ï¼š\n",
    "\n",
    "> ç”¨æ›´å¤šçš„åŠ æ³•/å‡æ³•å’Œå°‘é‡å˜æ¢ï¼Œæ¢å–æ›´å°‘çš„ä¹˜æ³•æ¬¡æ•°ã€‚\n",
    "\n",
    "ä¾‹å¦‚ F(2Ã—2, 3Ã—3) ç®—æ³•ï¼š  \n",
    "- è¾“å…¥ tile å¤§å°ï¼š4Ã—4\n",
    "- è¾“å‡º tile å¤§å°ï¼š2Ã—2\n",
    "- é€šè¿‡å¯¹è¾“å…¥å’Œå·ç§¯æ ¸åšçº¿æ€§å˜æ¢ï¼Œå°†å·ç§¯è½¬åŒ–ä¸ºï¼š\n",
    "  - element-wise ä¹˜æ³•\n",
    "  - å†ç»è¿‡é€†å˜æ¢\n",
    "\n",
    "å…¶ä¼˜ç‚¹ï¼š\n",
    "\n",
    "- å¯¹å°æ ¸å·ç§¯ï¼ˆå¦‚ 3Ã—3ï¼‰ä¹˜æ³•æ•°å¤§å¹…å‡å°‘\n",
    "- åœ¨ä¹˜æ³•è¿œæ¯”åŠ æ³•â€œè´µâ€çš„ç¡¬ä»¶ä¸Šæ›´æœ‰ä¼˜åŠ¿\n",
    "\n",
    "ç¼ºç‚¹ï¼š\n",
    "\n",
    "- æ•°å€¼ç¨³å®šæ€§å¯èƒ½å˜å·®ï¼ˆæ”¾å¤§è¯¯å·®ï¼‰\n",
    "- å¯¹å¤§æ ¸/stride ä¸å‹å¥½\n",
    "- å®žçŽ°å¤æ‚\n",
    "\n",
    "**ã€æŽ¨ç†åŠ é€Ÿè§†è§’ã€‘**  \n",
    "\n",
    "- ä½ éœ€è¦çŸ¥é“ï¼š\n",
    "  - è®¸å¤šé«˜æ€§èƒ½ Conv kernelï¼ˆå°¤å…¶åœ¨ç§»åŠ¨ç«¯ï¼‰ä½¿ç”¨ Winograd æˆ–å…¶å˜ä½“\n",
    "  - å®ƒä»¬éƒ½æ˜¯åœ¨çº¿æ€§ä»£æ•°/å¤šé¡¹å¼æ’å€¼åŸºç¡€ä¸Šå¾—åˆ°çš„æœ€å°ä¹˜æ³•ç®—æ³•\n",
    "\n",
    "---\n",
    "\n",
    "## 6.4 æœ¬ç« å°ç»“\n",
    "\n",
    "1. å·ç§¯å®šç†ï¼šæ—¶åŸŸå·ç§¯ â†” é¢‘åŸŸä¹˜æ³•ï¼Œä¸º FFT å·ç§¯æä¾›æ•°å­¦åŸºç¡€\n",
    "2. Toeplitz/Circulant çŸ©é˜µæä¾›äº†â€œå·ç§¯æ˜¯ç»“æž„åŒ–çŸ©é˜µä¹˜æ³•â€çš„è§†è§’\n",
    "3. Winograd ç®—æ³•é€šè¿‡å·§å¦™å˜æ¢å‡å°‘ä¹˜æ³•æ¬¡æ•°ï¼Œæ˜¯å¾ˆå¤š Conv åŠ é€Ÿæ–¹æ³•çš„æ ¸å¿ƒ\n",
    "\n",
    "åœ¨å®žé™…éƒ¨ç½²ä¸­ï¼Œä½ ä¸ä¸€å®šäº²è‡ªå®žçŽ° FFT/Winograd kernelï¼Œ  \n",
    "ä½†ç†è§£å…¶æ•°å­¦ï¼Œæœ‰åŠ©äºŽï¼š\n",
    "\n",
    "- è§£è¯»ä¸åŒç¡¬ä»¶/åº“å¯¹å·ç§¯çš„æ€§èƒ½å·®å¼‚\n",
    "- åšå‡ºâ€œæŸäº›å·ç§¯å½¢çŠ¶é€‚é…æŸäº›ç®—æ³•â€çš„åˆç†åˆ¤æ–­ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913aa00",
   "metadata": {
    "id": "b913aa00"
   },
   "source": [
    "# ç¬¬ 7 ç« ï¼šè®¡ç®—å›¾ä¸Žå›¾è®ºï¼ˆComputational Graph & Graph Theoryï¼‰\n",
    "\n",
    "æœ¬ç« å…³æ³¨ï¼š\n",
    "\n",
    "- å¦‚ä½•ç”¨ DAGï¼ˆæœ‰å‘æ— çŽ¯å›¾ï¼‰è¡¨ç¤ºæ¨¡åž‹\n",
    "- graph rewrite / fusion çš„æ•°å­¦æŠ½è±¡\n",
    "- å¦‚ä½•åŸºäºŽå›¾ç»“æž„åš scheduling / partitioning\n",
    "\n",
    "---\n",
    "\n",
    "## 7.1 æ¨¡åž‹å³è®¡ç®—å›¾ï¼ˆDAGï¼‰\n",
    "\n",
    "åœ¨æ¡†æž¶ä¸­ï¼Œä¸€ä¸ªæ¨¡åž‹é€šå¸¸è¢«è¡¨ç¤ºä¸ºï¼š\n",
    "\n",
    "- èŠ‚ç‚¹ï¼ˆnodeï¼‰ï¼šç®—å­ï¼ˆopï¼‰ï¼Œä¾‹å¦‚ MatMulã€Addã€GELUã€LayerNorm ç­‰\n",
    "- è¾¹ï¼ˆedgeï¼‰ï¼šå¼ é‡æ•°æ®æµ\n",
    "\n",
    "ç”±äºŽä¸å­˜åœ¨çŽ¯ï¼ˆæ²¡æœ‰ç®—å­ä¾èµ–æœªæ¥çš„ç»“æžœï¼‰ï¼Œè¯¥å›¾æ˜¯ä¸€ä¸ª **DAG**ã€‚\n",
    "\n",
    "æ•°å­¦ä¸Šï¼ŒDAG æ€§è´¨ä¿è¯ï¼š\n",
    "\n",
    "- å¯ä»¥è¿›è¡Œ **æ‹“æ‰‘æŽ’åºï¼ˆtopological sortï¼‰**\n",
    "- å­˜åœ¨è‡³å°‘ä¸€ç§æ‰§è¡Œé¡ºåºä½¿å¾—æ‰€æœ‰ä¾èµ–éƒ½æ»¡è¶³\n",
    "\n",
    "---\n",
    "\n",
    "## 7.2 å›¾é‡å†™ï¼ˆGraph Rewriteï¼‰\n",
    "\n",
    "å›¾é‡å†™çš„ç›®æ ‡ï¼š\n",
    "\n",
    "> åœ¨ä¸æ”¹å˜æ•´ä½“è¾“å…¥â€“è¾“å‡ºè¯­ä¹‰çš„å‰æä¸‹ï¼Œæ”¹å†™å›¾ç»“æž„ä»¥èŽ·å¾—æ›´é«˜æ•ˆçŽ‡ã€‚\n",
    "\n",
    "å¸¸è§æ“ä½œï¼š\n",
    "\n",
    "1. **ç®—å­èžåˆï¼ˆOperator Fusionï¼‰**\n",
    "\n",
    "   ä¾‹å¦‚ï¼š\n",
    "\n",
    "$$\n",
    "Y = \\text{GELU}(X W + b)\n",
    "$$\n",
    "\n",
    "\n",
    "   åœ¨å›¾ä¸­é€šå¸¸è¡¨çŽ°ä¸ºï¼š`X â†’ MatMul â†’ Add â†’ Gelu` å››ä¸ªèŠ‚ç‚¹ã€‚\n",
    "\n",
    "   é€šè¿‡å›¾é‡å†™ï¼Œå¯ä»¥è¯†åˆ«è¿™æ˜¯ä¸€ç§å¸¸è§ patternï¼Œå°†å…¶æ›¿æ¢ä¸ºï¼š\n",
    "\n",
    "   - å•ä¸ª `FusedMatMulBiasGelu` èŠ‚ç‚¹\n",
    "   - å†…éƒ¨å®žçŽ°ä¸ºä¸€ä¸ª kernelï¼Œå‡å°‘ä¸­é—´å†…å­˜è¯»å†™\n",
    "\n",
    "2. **å¸¸é‡æŠ˜å ï¼ˆConstant Foldingï¼‰**\n",
    "\n",
    "   è‹¥æŸäº›èŠ‚ç‚¹ä»…ä¾èµ–å¸¸é‡å¼ é‡ï¼Œå¯ä»¥åœ¨ç¼–è¯‘æ—¶æå‰æ‰§è¡Œï¼Œç®€åŒ–æŽ¨ç†æ—¶çš„è®¡ç®—é‡ã€‚\n",
    "\n",
    "3. **æ¶ˆé™¤å†—ä½™ç®—å­ï¼ˆEliminationï¼‰**\n",
    "\n",
    "   - è¿žç»­çš„ reshape/transpose åˆå¹¶\n",
    "   - åå‘æ“ä½œäº’ç›¸æŠµæ¶ˆï¼ˆå¦‚ transpose ä¸¤æ¬¡ï¼‰\n",
    "\n",
    "**æ•°å­¦æŠ½è±¡**ï¼š\n",
    "\n",
    "- ä¸€ç»„ rewrite ruleï¼š\n",
    "\n",
    "$$\n",
    "P \\Rightarrow R\n",
    "$$\n",
    "\n",
    "\n",
    "  å…¶ä¸­ P æ˜¯ pattern å­å›¾ï¼ŒR æ˜¯æ›¿æ¢åŽçš„å­å›¾ã€‚\n",
    "\n",
    "- åœ¨ DAG ä¸ŠéåŽ†ï¼ŒåŒ¹é… patternï¼Œè¿›è¡Œç­‰ä»·æ›¿æ¢ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 7.3 å›¾åˆ’åˆ†ä¸Žå¹¶è¡Œï¼ˆPartitioning & Parallelismï¼‰\n",
    "\n",
    "å¯¹å¤§æ¨¡åž‹ï¼Œå°¤å…¶åœ¨å¤šè®¾å¤‡/å¤šæ ¸åœºæ™¯ä¸‹ï¼Œéœ€è¦å°†è®¡ç®—å›¾åˆ’åˆ†ä¸ºå­å›¾ï¼š\n",
    "\n",
    "- pipeline parallelism\n",
    "- tensor parallelism\n",
    "- expert parallelismï¼ˆMoEï¼‰\n",
    "\n",
    "æ•°å­¦ä¸Šæ¶‰åŠï¼š\n",
    "\n",
    "- å›¾åˆ’åˆ†ï¼ˆgraph partitioningï¼‰ï¼š\n",
    "  - å¸Œæœ› cut è¾¹å°½é‡å°‘ï¼ˆå‡å°‘é€šä¿¡ï¼‰\n",
    "  - å„å­å›¾è´Ÿè½½å°½é‡å¹³è¡¡ï¼ˆé¿å…ä¸€å—æˆä¸ºç“¶é¢ˆï¼‰\n",
    "- è´Ÿè½½å‡è¡¡é—®é¢˜æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª NP-hard çš„ç»„åˆä¼˜åŒ–é—®é¢˜\n",
    "- å®žé™…ä½¿ç”¨å¯å‘å¼ç®—æ³•ï¼ˆgreedy / spectral partitioning / METIS ç­‰ï¼‰\n",
    "\n",
    "**ã€ä¸Žä½ çš„å·¥ä½œå…³ç³»ã€‘**  \n",
    "\n",
    "- åœ¨ edge device ä¸Šï¼Œå¤šæ ¸/å¤šå¼•æ“Žå¹¶è¡Œä¹Ÿéœ€è¦åˆç†åˆ‡å›¾\n",
    "- æŽ¨ç†æ¡†æž¶å¸¸ä¼šè‡ªåŠ¨åš operator placementï¼Œä½ éœ€è¦èƒ½çœ‹æ‡‚â€œä¸ºä»€ä¹ˆæŸäº› op è¢«æ”¾åœ¨æŸä¸ªå¼•æ“Žä¸Šâ€\n",
    "\n",
    "---\n",
    "\n",
    "## 7.4 Liveness åˆ†æžä¸Žå†…å­˜è§„åˆ’ï¼ˆMemory Planningï¼‰\n",
    "\n",
    "è®¡ç®—å›¾è¿˜æ‰¿è½½ï¼š\n",
    "\n",
    "- æ¯ä¸ªå¼ é‡çš„ **ç”Ÿå‘½å‘¨æœŸï¼ˆliveness intervalï¼‰**\n",
    "- å“ªäº›å¼ é‡åœ¨åŒä¸€æ—¶é—´æ®µå†…â€œåŒæ—¶æ´»è·ƒâ€\n",
    "\n",
    "åŸºäºŽæ­¤å¯åšï¼š\n",
    "\n",
    "- å†…å­˜é‡ç”¨ï¼ˆbuffer reuseï¼‰\n",
    "- in-place è®¡ç®—\n",
    "\n",
    "ä»Žæ•°å­¦ä¸Šï¼Œè¿™ç±»ä¼¼äºŽï¼š\n",
    "\n",
    "- å›¾ç€è‰² / åŒºé—´å›¾ç€è‰²ï¼ˆinterval graph coloringï¼‰\n",
    "- ç›®æ ‡æ˜¯æœ€å°‘çš„â€œé¢œè‰²â€ï¼ˆå†…å­˜å—ï¼‰è¦†ç›–æ‰€æœ‰åŒºé—´\n",
    "\n",
    "> è™½ç„¶ä½ ä¸ä¼šç›´æŽ¥å®žçŽ°å›¾ç€è‰²ç®—æ³•ï¼Œä½†è¦çŸ¥é“å†…å­˜è§„åˆ’é—®é¢˜åœ¨å›¾è®ºä¸­æ˜¯ä¸€ä¸ªç»å…¸ä¸»é¢˜ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 7.5 æœ¬ç« å°ç»“\n",
    "\n",
    "1. æ¨¡åž‹å¯ä»¥æŠ½è±¡ä¸ºä¸€ä¸ª DAGï¼›æ‹“æ‰‘æŽ’åºæä¾›æ‰§è¡Œé¡ºåº\n",
    "2. å›¾é‡å†™ï¼ˆfusion/folding/eliminationï¼‰æ˜¯æŽ¨ç†åŠ é€Ÿçš„å…³é”®æ­¥éª¤\n",
    "3. å›¾åˆ’åˆ†ä¸Žå¹¶è¡Œæ¶‰åŠå›¾åˆ’åˆ†é—®é¢˜ï¼Œéœ€è¦å¹³è¡¡é€šä¿¡ä¸Žè´Ÿè½½\n",
    "4. å†…å­˜è§„åˆ’å¯ä»¥ç”¨ liveness åˆ†æž + å›¾ç€è‰²çš„è§†è§’ç†è§£\n",
    "\n",
    "ä»Žè¿™ä¸€ç« å¼€å§‹ï¼Œæ•°å­¦ä¸å†æ˜¯â€œå…¬å¼æŽ¨å¯¼â€ï¼Œè€Œæ˜¯æ›´å¤šåœ°æä¾›äº†ä¸€ç§ **æŠ½è±¡å»ºæ¨¡å·¥å…·**ï¼Œå¸®åŠ©ä½ ä»Žæ›´é«˜å±‚ç†è§£ç¼–è¯‘å™¨ä¸ŽæŽ¨ç†æ¡†æž¶åœ¨å¹²ä»€ä¹ˆã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59e686",
   "metadata": {
    "id": "9f59e686"
   },
   "source": [
    "# ç¬¬ 8 ç« ï¼šæ•°å€¼ç¨³å®šæ€§ä¸Žå¤æ‚åº¦ï¼ˆNumerical Stability & Complexityï¼‰\n",
    "\n",
    "æœ¬ç« å…³æ³¨ï¼š\n",
    "\n",
    "- æµ®ç‚¹æ•°çš„è¯¯å·®æ¨¡åž‹\n",
    "- ç¨³å®š softmax / LayerNorm\n",
    "- ç®—æ³•å¤æ‚åº¦ï¼ˆæ—¶é—´/ç©ºé—´ï¼‰ä¸ŽæŽ¨ç†æ€§èƒ½\n",
    "\n",
    "---\n",
    "\n",
    "## 8.1 æµ®ç‚¹æ•°ä¸Žèˆå…¥è¯¯å·®\n",
    "\n",
    "ä¸€ä¸ªå…¸åž‹çš„æµ®ç‚¹è¿ç®—å¯ä»¥æŠ½è±¡ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\text{fl}(x \\circ y) = (x \\circ y)(1 + \\delta), \\quad |\\delta| \\le \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "- $\\circ$ï¼šåŸºæœ¬è¿ç®—ï¼ˆ+,-,Ã—,Ã·ï¼‰\n",
    "- $\\epsilon$ï¼šæœºå™¨ç²¾åº¦ï¼ˆmachine epsilonï¼‰\n",
    "- $\\delta$ï¼šèˆå…¥è¯¯å·®\n",
    "\n",
    "è¿žç»­å¤šæ¬¡è¿ç®—åŽï¼Œè¯¯å·®ä¼šç§¯ç´¯ï¼Œæœ‰æ—¶è¿˜ä¼šè¢«æ”¾å¤§ã€‚\n",
    "\n",
    "**ã€å·¥ç¨‹æ„ä¹‰ã€‘**  \n",
    "\n",
    "- åœ¨ FP32 â†’ FP16/FP8 é‡åŒ–æ—¶ï¼Œ$\\epsilon$ å˜å¤§  \n",
    "- åœ¨é•¿åºåˆ—ã€æ·±ç½‘ç»œä¸­ï¼Œç´¯ç§¯è¯¯å·®ä¸å®¹å¿½è§†\n",
    "- éœ€è¦è®¾è®¡æ•°å€¼ç¨³å®šçš„å®žçŽ°æ–¹å¼ï¼ˆè§ softmax ç¤ºä¾‹ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 8.2 ç¨³å®š softmax\n",
    "\n",
    "æœ´ç´ å†™æ³•ï¼š\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}\n",
    "$$\n",
    "\n",
    "\n",
    "å¯èƒ½é‡åˆ°ï¼š\n",
    "\n",
    "- å½“æŸä¸ª $x_k$ å¾ˆå¤§æ—¶ï¼Œ$e^{x_k}$ æº¢å‡º\n",
    "- å…¶å®ƒé¡¹ç›¸å¯¹å˜æˆ 0ï¼Œå¯¼è‡´æ•°å€¼é—®é¢˜\n",
    "\n",
    "ç¨³å®šå†™æ³•ï¼š\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{e^{x_i - m}}{\\sum_j e^{x_j - m}}, \\quad m = \\max_j x_j\n",
    "$$\n",
    "\n",
    "\n",
    "æŽ¨å¯¼ï¼š\n",
    "\n",
    "$$\n",
    "\\frac{e^{x_i}}{\\sum_j e^{x_j}}\n",
    "= \\frac{e^{x_i - m} e^m}{\\sum_j e^{x_j - m} e^m}\n",
    "= \\frac{e^{x_i - m}}{\\sum_j e^{x_j - m}}\n",
    "$$\n",
    "\n",
    "\n",
    "- åˆ†å­åˆ†æ¯åŒæ—¶ä¹˜ä»¥ $e^{-m}$ï¼Œæ•°å€¼ä¸Šé¿å…äº†æº¢å‡º/ä¸‹æº¢\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- åœ¨ FP16/FP8 æˆ–æ··åˆç²¾åº¦ä¸­ï¼Œè¿™ç§ç¨³å®šåŒ–å¤„ç†å°¤å…¶é‡è¦\n",
    "- FlashAttention ç­‰ç®—æ³•åœ¨å®žçŽ°æ—¶éžå¸¸å¼ºè°ƒï¼š\n",
    "  - æŒ‰ block è®¡ç®— max\n",
    "  - å¢žé‡å¼ç»´æŠ¤ç¨³å®š softmax\n",
    "\n",
    "---\n",
    "\n",
    "## 8.3 LayerNorm / RMSNorm çš„æ•°å€¼è€ƒè™‘\n",
    "\n",
    "LayerNormï¼š\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{d}\\sum_{i=1}^d x_i, \\quad\n",
    "\\sigma^2 = \\frac{1}{d}\\sum_{i=1}^d (x_i - \\mu)^2 \\\\\n",
    "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "\n",
    "æ•°å€¼ç¨³å®šæ€§æŒ‘æˆ˜ï¼š\n",
    "\n",
    "- $\\sigma^2$ å¾ˆå°æˆ–å¾ˆå¤§æ—¶ï¼Œéƒ½å¯èƒ½å‡ºçŽ°ç²¾åº¦æŸå¤±\n",
    "- FP16 ä¸­çš„ç´¯åŠ ï¼ˆsumï¼‰ä¸ç²¾ç¡®\n",
    "\n",
    "å¸¸è§å¯¹ç­–ï¼š\n",
    "\n",
    "- åœ¨é«˜ç²¾åº¦ï¼ˆFP32ï¼‰accumulator ä¸­ç´¯åŠ ï¼Œå† cast å›žä½Žç²¾åº¦\n",
    "- ä½¿ç”¨ Kahan summation æ”¹å–„æ±‚å’Œç²¾åº¦ï¼ˆè¾ƒå°‘è§äºŽå®žé™… ML kernelï¼Œä½†æ€æƒ³å€¼å¾—çŸ¥é“ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## 8.4 ç®—æ³•å¤æ‚åº¦ï¼ˆComplexityï¼‰\n",
    "\n",
    "åœ¨æŽ¨ç†åœºæ™¯ä¸­ï¼Œå…³æ³¨çš„å¤æ‚åº¦åŒ…æ‹¬ï¼š\n",
    "\n",
    "- æ—¶é—´å¤æ‚åº¦ï¼šFLOPs æ•° / ç®—æ³•é˜¶\n",
    "- ç©ºé—´å¤æ‚åº¦ï¼šå‚æ•°é‡ / activation / KV cache\n",
    "\n",
    "ä¾‹ï¼šè‡ªæ³¨æ„åŠ› $O(T^2 d)$ï¼š\n",
    "\n",
    "- QKáµ€ï¼š$O(T^2 d)$\n",
    "- A Vï¼š$O(T^2 d)$\n",
    "\n",
    "å½“ T å¾ˆå¤§æ—¶ï¼ˆä¾‹å¦‚é•¿ä¸Šä¸‹æ–‡ LLMï¼‰ï¼Œè¿™æ˜¯ä¸»è¦ç“¶é¢ˆã€‚  \n",
    "å› æ­¤ï¼š\n",
    "\n",
    "- è®¸å¤šâ€œçº¿æ€§æ³¨æ„åŠ›â€ã€â€œå±€éƒ¨æ³¨æ„åŠ›â€ã€â€œç¨€ç–æ³¨æ„åŠ›â€æ–¹æ³•è¯•å›¾å°†å¤æ‚åº¦é™åˆ° $O(T d)$ æˆ– $O(T \\log T)$\n",
    "- ä½ éœ€è¦èƒ½å¤§è‡´ä¼°ç®—ä¸åŒæ¨¡å—çš„ FLOPsï¼Œåˆ¤æ–­ç“¶é¢ˆåœ¨å“ªä¸€å±‚\n",
    "\n",
    "---\n",
    "\n",
    "## 8.5 æœ¬ç« å°ç»“\n",
    "\n",
    "1. æµ®ç‚¹è¯¯å·®æ¨¡åž‹å¸®åŠ©ä½ ç†è§£ï¼šä¸ºä»€ä¹ˆä½Žç²¾åº¦éœ€è¦æ•°å€¼ç¨³å®šæŠ€å·§\n",
    "2. ç¨³å®š softmax / LayerNorm æ˜¯ç»å…¸ä¾‹å­ï¼ŒæŽ¨ç† kernel å¿…é¡»å®žçŽ°ç¨³å®šç‰ˆæœ¬\n",
    "3. ç®—æ³•å¤æ‚åº¦å†³å®šäº†æ¨¡åž‹åœ¨å¤§è§„æ¨¡è¾“å…¥/é•¿åºåˆ—ä¸‹çš„ scalability\n",
    "4. åœ¨åš runtime acceleration æ—¶ï¼š\n",
    "   - ä¸€éƒ¨åˆ†å·¥ä½œæ˜¯ **å‡å°‘å¸¸æ•°é¡¹**ï¼ˆkernel çº§ä¼˜åŒ–ï¼‰\n",
    "   - å¦ä¸€éƒ¨åˆ†æ˜¯ **é™ä½Žå¤æ‚åº¦é˜¶æ•°**ï¼ˆæ¨¡åž‹/ç®—æ³•çº§ä¼˜åŒ–ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c237fb5",
   "metadata": {
    "id": "7c237fb5"
   },
   "source": [
    "# ç¬¬ 9 ç« ï¼šç¡¬ä»¶ç›¸å…³æ•°å­¦ï¼ˆHardware-Aware Math: Roofline, Tiling, SIMD, FMAï¼‰\n",
    "\n",
    "æœ¬ç« èšç„¦ï¼š\n",
    "\n",
    "- Roofline æ¨¡åž‹ï¼šç®—åŠ› vs å¸¦å®½\n",
    "- ç®—æœ¯å¼ºåº¦ï¼ˆarithmetic intensityï¼‰\n",
    "- åˆ†å—ï¼ˆtilingï¼‰ä¸Žæ•°æ®é‡ç”¨\n",
    "- SIMD / FMA / GEMM å†…æ ¸çš„æ•°å­¦è§†è§’\n",
    "\n",
    "---\n",
    "\n",
    "## 9.1 Roofline æ¨¡åž‹\n",
    "\n",
    "Roofline æ¨¡åž‹ç»™å‡ºåœ¨ç»™å®šç¡¬ä»¶ä¸Šï¼ŒæŸä¸ª kernel çš„ç†è®ºæ€§èƒ½ä¸Šç•Œï¼š\n",
    "\n",
    "$$\n",
    "P_{\\text{attainable}} = \\min\\left(P_{\\text{peak}},\\ I \\cdot B\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- $P_{\\text{peak}}$ï¼šå³°å€¼è®¡ç®—æ€§èƒ½ï¼ˆå¦‚ TFLOPsï¼‰\n",
    "- $B$ï¼šå†…å­˜å¸¦å®½ï¼ˆå¦‚ GB/sï¼‰\n",
    "- $I$ï¼šç®—æœ¯å¼ºåº¦ï¼ˆarithmetic intensityï¼‰\n",
    "\n",
    "ç®—æœ¯å¼ºåº¦å®šä¹‰ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "I = \\frac{\\text{FLOPs}}{\\text{Bytes moved}}\n",
    "$$\n",
    "\n",
    "\n",
    "**ä¸¤ç§ regimeï¼š**\n",
    "\n",
    "1. **memory-bound**ï¼ˆå¸¦å®½å—é™ï¼‰ï¼š\n",
    "   - è‹¥ $I \\cdot B < P_{\\text{peak}}$\n",
    "   - æ€§èƒ½ä¸»è¦å—å†…å­˜å¸¦å®½é™åˆ¶ï¼ŒFLOPs å¾ˆå……è£•\n",
    "2. **compute-bound**ï¼ˆç®—åŠ›å—é™ï¼‰ï¼š\n",
    "   - è‹¥ $I \\cdot B \\ge P_{\\text{peak}}$\n",
    "   - æ€§èƒ½ç”±ç®—åŠ›ä¸Šé™å†³å®š\n",
    "\n",
    "**ã€å·¥ç¨‹è§†è§’ã€‘**  \n",
    "\n",
    "- å¯¹ç®—å­è€Œè¨€ï¼š\n",
    "  - Conv/GEMM é€šå¸¸å…·æœ‰è¾ƒé«˜ $I$ï¼Œæ›´å®¹æ˜“æˆä¸º compute-bound\n",
    "  - ç®€å• element-wise op çš„ $I$ å¾ˆä½Žï¼Œé€šå¸¸æ˜¯ memory-bound\n",
    "- å¯¹ Embedding è€Œè¨€ï¼šå‡ ä¹Žæ²¡æœ‰ FLOPsï¼Œä½†è¯»å†™å¤§é‡æ•°æ® â†’ å…¸åž‹ memory-bound\n",
    "\n",
    "---\n",
    "\n",
    "## 9.2 åˆ†å—ï¼ˆTilingï¼‰ä¸Žæ•°æ®é‡ç”¨\n",
    "\n",
    "ä»¥ GEMM ä¸ºä¾‹ï¼š$C = A B$ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "- $A \\in \\mathbb{R}^{M \\times K}$\n",
    "- $B \\in \\mathbb{R}^{K \\times N}$\n",
    "- $C \\in \\mathbb{R}^{M \\times N}$\n",
    "\n",
    "å¦‚æžœç›´æŽ¥ä¸‰é‡å¾ªçŽ¯ï¼Œä¼šé¢‘ç¹ä»Žå†…å­˜åŠ è½½ A/B/Cï¼Œå¯¼è‡´å¸¦å®½æµªè´¹ã€‚\n",
    "\n",
    "åˆ†å—æ€æƒ³ï¼š\n",
    "\n",
    "- å°† C åˆ†æˆå°å—ï¼ˆtileï¼‰ï¼š$M_b \\times N_b$\n",
    "- å¯¹æ¯ä¸ª tileï¼š\n",
    "  - åŠ è½½å¯¹åº”çš„ A å­å—ï¼ˆ$M_b \\times K_b$ï¼‰\n",
    "  - åŠ è½½å¯¹åº”çš„ B å­å—ï¼ˆ$K_b \\times N_b$ï¼‰\n",
    "  - åœ¨å¯„å­˜å™¨æˆ–å°ç¼“å­˜ä¸­å®Œæˆæ‰€æœ‰ FMA\n",
    "\n",
    "çº¦æŸæ¡ä»¶ï¼š\n",
    "\n",
    "$$\n",
    "(M_b \\cdot K_b + K_b \\cdot N_b + M_b \\cdot N_b) \\cdot \\text{bytes} \\le \\text{cache size}\n",
    "$$\n",
    "\n",
    "\n",
    "**ã€ç›´è§‚ç†è§£ã€‘**  \n",
    "\n",
    "- é€šè¿‡åˆ†å—ï¼Œè®©åŒä¸€å—æ•°æ®è¢«å¤šæ¬¡é‡ç”¨ï¼ˆreuseï¼‰ï¼Œæœ‰æ•ˆæé«˜ç®—æœ¯å¼ºåº¦ $I$\n",
    "- å‡å°‘å¯¹ DRAM çš„è®¿é—®æ¬¡æ•°\n",
    "\n",
    "---\n",
    "\n",
    "## 9.3 SIMD / FMA / Tensor Core\n",
    "\n",
    "### 9.3.1 FMA å†å›žé¡¾\n",
    "\n",
    "$$\n",
    "\\text{FMA}(a,b,c) = a \\times b + c\n",
    "$$\n",
    "\n",
    "\n",
    "- åœ¨ç¡¬ä»¶ä¸­å¯ä»¥ä½œä¸ºä¸€ä¸ªåŸºæœ¬æŒ‡ä»¤\n",
    "- dot product ä¸Ž GEMM å†…éƒ¨éƒ½æ˜¯å¤§é‡ FMA\n",
    "\n",
    "### 9.3.2 SIMDï¼ˆSingle Instruction, Multiple Dataï¼‰\n",
    "\n",
    "SIMD æŒ‡ä»¤å¯ä»¥ï¼š\n",
    "\n",
    "- ä¸€æ¡æŒ‡ä»¤å¯¹å¤šä¸ªæ•°æ®å…ƒç´ æ‰§è¡Œç›¸åŒè¿ç®—\n",
    "- ä¾‹å¦‚ AVX2 ä¸­ 256-bit å¯„å­˜å™¨å¯åŒæ—¶å¤„ç† 8 ä¸ª float\n",
    "\n",
    "çŸ©é˜µä¹˜æ³•å†…éƒ¨ï¼š\n",
    "\n",
    "- æ¯æ¬¡ä»Žå†…å­˜åŠ è½½ä¸€ä¸ªå‘é‡ block\n",
    "- ä½¿ç”¨ SIMD/FMA å¯¹å¤šä¸ªå…ƒç´ å¹¶è¡Œä¹˜åŠ \n",
    "\n",
    "### 9.3.3 Tensor Core / Matrix Unit\n",
    "\n",
    "åœ¨çŽ°ä»£ GPU/NPU ä¸­ï¼š\n",
    "\n",
    "- æä¾›ä¸“é—¨çš„çŸ©é˜µä¹˜å•å…ƒï¼ˆå¦‚ NVIDIA Tensor Coreã€Intel AMXï¼‰\n",
    "- æ¯æ¡æŒ‡ä»¤æ‰§è¡Œä¸€ä¸ªå°çŸ©é˜µä¹˜è¿ç®—ï¼ˆå¦‚ 16Ã—16 Ã— 16Ã—16ï¼‰\n",
    "\n",
    "**ã€æ•°å­¦è§†è§’ã€‘**  \n",
    "\n",
    "- è¿™äº›ä¸“ç”¨å•å…ƒæœ¬è´¨ä¸Šå®žçŽ°äº†ä¸€ä¸ªï¼š\n",
    "\n",
    "$$\n",
    "C_{\\text{tile}} = A_{\\text{tile}} B_{\\text{tile}} + C_{\\text{tile}}\n",
    "$$\n",
    "\n",
    "\n",
    "- ä½ çš„ä»»åŠ¡æ˜¯ï¼š\n",
    "  - æŠŠå¤§çŸ©é˜µæ‹†æˆç¬¦åˆç¡¬ä»¶ tile å¤§å°çš„å°å—\n",
    "  - åšå¥½æ•°æ®å¸ƒå±€ï¼Œä½¿å¾—è¿™äº› tile åœ¨å†…å­˜ä¸­è¿žç»­ã€å¯¹é½\n",
    "\n",
    "---\n",
    "\n",
    "## 9.4 ç¡¬ä»¶æ„è¯†ä¸‹çš„é‡åŒ–ä¸Žæ‰“åŒ…ï¼ˆPackingï¼‰\n",
    "\n",
    "å¯¹ INT8 / INT4 GEMMï¼š\n",
    "\n",
    "- æƒé‡/æ¿€æ´»ä¸ä»…è¢«é‡åŒ–ï¼Œè¿˜ä¼šæŒ‰ç‰¹å®š pattern æ‰“åŒ…ï¼ˆpackï¼‰åˆ°å¯„å­˜å™¨å‹å¥½çš„æ ¼å¼\n",
    "- ä¾‹å¦‚æŠŠå¤šä¸ª int4 åŽ‹åœ¨ä¸€ä¸ª 16-bit æˆ– 32-bit å®¹å™¨ä¸­\n",
    "\n",
    "è¿™æ¶‰åŠï¼š\n",
    "\n",
    "- ä½è¿ç®—ï¼ˆbitwise opsï¼‰\n",
    "- å¯¹é½ï¼ˆalignmentï¼‰çº¦æŸ\n",
    "- å¤šä¸ªå…ƒç´ çš„â€œå¹¶è¡Œ unpackâ€æ•°å­¦\n",
    "\n",
    "è™½ç„¶è¿™é‡Œä¸å±•å¼€ç»†èŠ‚ï¼Œä½†è¦çŸ¥é“ï¼š\n",
    "\n",
    "> é«˜æ€§èƒ½é‡åŒ–æŽ¨ç†å†…æ ¸çš„æ•°å­¦æœ¬è´¨æ˜¯ï¼š  \n",
    "> **ç”¨æ•´æ•°ç®—æœ¯å’Œä½è¿ç®—å®žçŽ°â€œå‘é‡åŒ– FMAâ€çš„ç­‰ä»·è¡Œä¸ºã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "## 9.5 æœ¬ç« å°ç»“\n",
    "\n",
    "1. Roofline æ¨¡åž‹å¸®åŠ©ä½ åˆ¤æ–­ kernel æ˜¯ compute-bound è¿˜æ˜¯ memory-bound\n",
    "2. ç®—æœ¯å¼ºåº¦ $I$ æ˜¯ç†è§£â€œä¸ºä»€ä¹ˆè¦åš tiling / fusion / ç¼“å­˜é‡ç”¨â€çš„å…³é”®æŒ‡æ ‡\n",
    "3. FMAã€SIMDã€Tensor Core æ˜¯é«˜æ€§èƒ½çº¿æ€§ä»£æ•°çš„ç¡¬ä»¶æ”¯æŸ±\n",
    "4. é‡åŒ–æŽ¨ç†ä¸­è¿˜è¦è€ƒè™‘æ•´æ•°æ‰“åŒ…ä¸Žä½è¿ç®—çš„æ•°å­¦ç»“æž„\n",
    "\n",
    "> åˆ°è¿™é‡Œä¸ºæ­¢ï¼Œä½ å·²ç»æ‹¥æœ‰äº†ä¸€å¥—ï¼š  \n",
    "> **ä»Žçº¿æ€§ä»£æ•° â†’ ä¼˜åŒ– â†’ è¿‘ä¼¼ â†’ ç»Ÿè®¡ â†’ ä¿¡æ¯è®º â†’ ä¿¡å·å¤„ç† â†’ å›¾è®º â†’ æ•°å€¼åˆ†æž â†’ ç¡¬ä»¶æ•°å­¦** çš„å®Œæ•´æ€ç»´é“¾æ¡ã€‚\n",
    "\n",
    "åœ¨å®žé™…å·¥ç¨‹ä¸­ï¼Œæ¯ä¸€æ¬¡åšéƒ¨ç½²å†³ç­–ï¼Œä½ éƒ½å¯ä»¥åœ¨è„‘ä¸­å¿«é€Ÿèµ°ä¸€éè¿™æ¡é“¾ï¼š\n",
    "\n",
    "- è¿™ä¸ªç®—å­æœ¬è´¨æ˜¯ä»€ä¹ˆçº¿æ€§ä»£æ•°ï¼Ÿ\n",
    "- èƒ½ä¸èƒ½ç”¨åŽ‹ç¼©/è¿‘ä¼¼/å‰ªæžä¼˜åŒ–ï¼Ÿ\n",
    "- å¯¹åˆ†å¸ƒ/ä¿¡æ¯é‡æœ‰ä½•å½±å“ï¼Ÿ\n",
    "- ä¼šä¸ä¼šå¼•å‘æ•°å€¼é—®é¢˜ï¼Ÿ\n",
    "- åœ¨ç¡¬ä»¶ä¸Šæ˜¯ compute-bound è¿˜æ˜¯ memory-boundï¼Ÿ\n",
    "- è¯¥å¦‚ä½•åš tiling / fusion / placementï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43e51a",
   "metadata": {
    "id": "0b43e51a"
   },
   "source": [
    "# é™„å½• Aï¼šç¬¦å·è¡¨ä¸Žæœ¯è¯­é€ŸæŸ¥\n",
    "\n",
    "- $W, A, B, C$ï¼šçŸ©é˜µ\n",
    "- $x, y, z$ï¼šå‘é‡\n",
    "- $\\|\\cdot\\|_F$ï¼šFrobenius èŒƒæ•°\n",
    "- $\\|\\cdot\\|_2$ï¼šè°±èŒƒæ•° / operator norm\n",
    "- $\\|\\cdot\\|_1, \\|\\cdot\\|_0$ï¼šL1 èŒƒæ•°ã€L0 â€œèŒƒæ•°â€ï¼ˆéžé›¶ä¸ªæ•°ï¼‰\n",
    "- SVDï¼šSingular Value Decomposition\n",
    "- GEMMï¼šGeneral Matrix-Matrix Multiply\n",
    "- FMAï¼šFused Multiply-Add\n",
    "- AIï¼šArithmetic Intensityï¼ˆç®—æœ¯å¼ºåº¦ï¼‰\n",
    "- KLï¼šKullback-Leibler æ•£åº¦\n",
    "- CEï¼šCross-Entropy äº¤å‰ç†µ\n",
    "- FFTï¼šFast Fourier Transform\n",
    "- DAGï¼šDirected Acyclic Graphï¼ˆæœ‰å‘æ— çŽ¯å›¾ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "# é™„å½• Bï¼šç»ƒä¹ å»ºè®®ï¼ˆè‡ªæˆ‘æ£€æŸ¥ï¼‰\n",
    "\n",
    "ä½ å¯ä»¥æŒ‰ç…§ä¸‹é¢çš„ checklist æ£€æŸ¥è‡ªå·±æ˜¯å¦æŽŒæ¡äº†æœ¬ä¹¦æ ¸å¿ƒå†…å®¹ï¼š\n",
    "\n",
    "1. **çº¿æ€§ä»£æ•°**\n",
    "   - èƒ½å†™å‡º GEMM çš„å…ƒç´ çº§å…¬å¼ï¼Œå¹¶è§£é‡Šå…¶ FLOPs è§„æ¨¡\n",
    "   - èƒ½è§£é‡Š SVD æˆªæ–­æ˜¯æœ€ä¼˜ä½Žç§©è¿‘ä¼¼ï¼Œå¹¶ç”»å‡ºç¤ºæ„å›¾\n",
    "   - èƒ½ä»Ž Conv2d æŽ¨å¯¼å‡º im2col + GEMM å½¢å¼\n",
    "\n",
    "2. **æ•°å€¼ä¼˜åŒ–**\n",
    "   - èƒ½å†™å‡ºå¸¦ L0/L1 æ­£åˆ™çš„å‰ªæžç›®æ ‡å‡½æ•°\n",
    "   - èƒ½è§£é‡Šå¦‚ä½•é€šè¿‡æœ€å°åŒ–é‡åŒ–è¯¯å·®æ¥æ±‚ scale\n",
    "   - èƒ½è§£é‡Šè’¸é¦ä¸­ CE + KL çš„å«ä¹‰\n",
    "\n",
    "3. **è¿‘ä¼¼ç†è®º**\n",
    "   - èƒ½å†™å‡ºå‡åŒ€é‡åŒ–è¯¯å·®çš„æ–¹å·® $\\Delta^2/12$\n",
    "   - èƒ½è§£é‡Šä¸ºä»€ä¹ˆæ¿€æ´»å‡½æ•°å¯ä»¥ç”¨å¤šé¡¹å¼è¿‘ä¼¼\n",
    "\n",
    "4. **æ¦‚çŽ‡ä¸Žç»Ÿè®¡ / ä¿¡æ¯è®º**\n",
    "   - ç†è§£ KLã€äº¤å‰ç†µçš„å®šä¹‰åŠå…¶å…³ç³»\n",
    "   - èƒ½è§£é‡Šç†µä¸Žå¹³å‡ç é•¿çš„å…³ç³»\n",
    "\n",
    "5. **ä¿¡å·å¤„ç† / å›¾è®º / æ•°å€¼ç¨³å®š / ç¡¬ä»¶æ•°å­¦**\n",
    "   - ç†è§£å·ç§¯å®šç†ä¸Ž FFT å·ç§¯å¤§è‡´æ€è·¯\n",
    "   - çŸ¥é“ DAGã€graph rewrite çš„æ„ä¹‰\n",
    "   - èƒ½è§£é‡Šç¨³å®š softmax çš„æŽ¨å¯¼\n",
    "   - èƒ½ç”¨ Roofline æ¨¡åž‹è¯´æ¸…æ¥šä¸€ä¸ª kernel æ˜¯ compute-bound è¿˜æ˜¯ memory-bound\n",
    "\n",
    "---\n",
    "\n",
    "> å»ºè®®ï¼š  \n",
    "> ä½ å¯ä»¥åœ¨æœ¬ notebook çš„åŸºç¡€ä¸Šï¼š\n",
    "> - å¢žåŠ ä»£ç  cellï¼Œåšä¸€äº›æ•°å€¼å®žéªŒï¼ˆä¾‹å¦‚ SVD åŽ‹ç¼©ä¸€ä¸ªéšæœºçŸ©é˜µï¼Œè§‚å¯Ÿè¯¯å·® vs rankï¼‰  \n",
    "> - å†™ä¸€äº›å°è„šæœ¬ profiling ä¸åŒå½¢çŠ¶çš„ GEMMï¼Œæ„Ÿå— tiling çš„å½±å“  \n",
    "> - æ•´åˆä½ çš„ GM å®žé™…éƒ¨ç½²æ¡ˆä¾‹ï¼Œé€æ¸æŠŠè¿™é‡Œå˜æˆä½ è‡ªå·±çš„â€œRuntime Inference æ•°å­¦å·¥ä½œæ‰‹å†Œâ€ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
